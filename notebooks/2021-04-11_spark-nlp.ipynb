{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download Albert model \n",
    "# download data\n",
    "sys.path.insert(0, '../')\n",
    "from util import util_data_access\n",
    "import zipfile\n",
    "util_data_access.download_file('albert.zip', 'spark-nlp/albert_xxlarge_uncased_en_2.5.0_2.4_1588073588232.zip')\n",
    "# ! tar -xf en_core_web_lg.tar.gz\n",
    "# ! mv en_core_web_lg-2.3.1 en_core_web_lg\n",
    "with zipfile.ZipFile('albert.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('albert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.sql import SparkSession\n",
    "# spark = sparknlp.start()\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder \\\n",
    "      .config(\"spark.executor.instances\", \"50\") \\\n",
    "      .config(\"spark.driver.memory\", \"15g\") \\\n",
    "      .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.7.5\")\n",
    "      .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "                <div>\n",
       "                    <p><b>SparkContext</b></p>\n",
       "                    <p><a href=\"/sprk/4040/jobs/\">Spark UI</a></p>\n",
       "                    <dl>\n",
       "                      <dt>Version</dt>\n",
       "                        <dd><code>v2.4.4</code></dd>\n",
       "                      <dt>AppName</dt>\n",
       "                        <dd><code>pyspark-shell</code></dd>\n",
       "                    </dl>\n",
       "                    <br>\n",
       "                    <b>Executor Status</b>\n",
       "                    <dl>\n",
       "                      <dt>Running</dt>\n",
       "                        <dd><code>19</code></dd>\n",
       "                      <dt>Pending</dt>\n",
       "                        <dd><code>1</code></dd>\n",
       "                      <dt>Failed</dt>\n",
       "                        <dd><code>0</code></dd>\n",
       "                    </dl>\n",
       "                </div>\n",
       "                \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0d150fb358>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Spark-NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "import sparknlp.annotator as sa\n",
    "import sparknlp.base as sb\n",
    "# import sparknlp\n",
    "from sparknlp import Finisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documenter = sb.DocumentAssembler()\\\n",
    "    .setInputCol(\"summary\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "# sentencerDL = sa.SentenceDetectorDLModel\\\n",
    "#     .load(\"/Users/alex/.cache/spark-nlp/sentence_detector_dl_en_2.6.2_2.4_1600002888450\") \\\n",
    "#     .setInputCols([\"document\"]) \\\n",
    "#     .setOutputCol(\"sentences\")\n",
    "\n",
    "sentencer = (sa.SentenceDetector()\n",
    "                .setInputCols([\"document\"])\n",
    "                .setOutputCol(\"sentences\")            \n",
    "            )\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"sentences\"]) \\\n",
    "#     .setIncludeMetadata(True)\n",
    "\n",
    "sd_pipeline = PipelineModel(stages=[documenter, sentencer, finisher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Sentence Tokenizing on Our Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "# import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect('../data/diffengine-diffs/db/newssniffer-nytimes.db')\n",
    "conn = sqlite3.connect('newssniffer-nytimes.db')\n",
    "\n",
    "# df = pd.read_sql('''\n",
    "#     SELECT * from entryversion \n",
    "#     WHERE entry_id IN (SELECT distinct entry_id FROM entryversion LIMIT 50000)\n",
    "# ''', con=conn)\n",
    "\n",
    "df = pd.read_sql('''\n",
    "    SELECT * from entryversion \n",
    "''', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunksize = 40000\n",
    "unique_entryids = df['entry_id'].unique()\n",
    "num_chunks = int(unique_entryids.shape[0] / chunksize)\n",
    "\n",
    "for chunk_id in range(num_chunks):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(summary=lambda df: df['summary'].str.replace('</p><p>', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = sd_pipeline.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = annotations_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WASHINGTON — Weapons sales by the United States tripled in 2011 to a record high, driven by major arms sales to Persian Gulf allies concerned about Iran’s regional ambitions, according to a new study for Congress.',\n",
       " 'Overseas weapons sales by the United States totaled $66.3 billion last year, or nearly 78 percent of the global arms market, valued at $85.3 billion in 2011.',\n",
       " 'Russia was a distant second, with $4.8 billion in deals.',\n",
       " 'The American weapons sales total was an “extraordinary increase” over the $21.4 billion in deals for 2010, the study found, and was the largest single-year sales total in the history of United States arms exports.',\n",
       " 'The previous high was in fiscal year 2009, when American weapons sales overseas totaled nearly $31 billion.',\n",
       " 'A worldwide economic decline had suppressed arms sales over recent years.',\n",
       " 'But increasing tensions with Iran drove a set of Persian Gulf nations — Saudi Arabia, the United Arab Emirates and Oman — to purchase American weapons at record levels.',\n",
       " 'These Gulf states do not share a border with Iran, and their arms purchases focused on expensive warplanes and complex missile defense systems.',\n",
       " 'The report was prepared by the nonpartisan Congressional Research Service, a division of the Library of Congress.',\n",
       " 'The annual study, written by Richard F. Grimmett and Paul K. Kerr and delivered to Congress on Friday, is considered the most detailed collection of unclassified arms sales data available to the public.',\n",
       " 'The agreements with Saudi Arabia included the purchase of 84 advanced F-15 fighters, a variety of ammunition, missiles and logistics support, and upgrades of 70 of the F-15 fighters in the current fleet.',\n",
       " 'Sales to Saudi Arabia last year also included dozens of Apache and Black Hawk helicopters, all contributing to a total Saudi weapons deal from the United States of $33.4 billion, according to the study.',\n",
       " 'The United Arab Emirates purchased a Terminal High Altitude Area Defense, an advanced antimissile shield that includes radars and is valued at $3.49 billion, as well as 16 Chinook helicopters for $939 million.',\n",
       " 'Oman bought 18 F-16 fighters for $1.4 billion.',\n",
       " 'In keeping with recent trends, most of the weapons purchases, worth about $71.5 billion, were made by developing nations, with about $56.3 billion of that from the United States.',\n",
       " 'Other significant weapons deals by the United States last year included a $4.1 billion agreement with India for 10 C-17 transport planes and with Taiwan for Patriot antimissile batteries valued at $2 billion — an arms deal that outraged officials in Beijing.',\n",
       " 'To compare weapons sales over various years, the study used figures in 2011 dollars, with amounts for previous years adjusted for inflation to provide a consistent measurement.',\n",
       " 'A policy goal of the United States has been to work with Arab allies in the Persian Gulf to knit together a regional missile defense system to protect cities, oil refineries, pipelines and military bases from an Iranian attack.',\n",
       " 'The effort has included deploying radars to increase the range of early warning coverage across the Persian Gulf, as well as introducing command, control and communications systems that could exchange that information with new batteries of missile interceptors sold to the individual nations.',\n",
       " 'The missile shield in the Persian Gulf is being built on a country-by-country basis — with these costly arms sales negotiated bilaterally between the United States and individual nations.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df['finished_sentences'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Albert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = sb.DocumentAssembler()\\\n",
    "  .setInputCol(\"summary\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = sa.Tokenizer().setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"token\")\n",
    " \n",
    "word_embeddings = sa.AlbertEmbeddings.load('albert')\\\n",
    "  .setInputCols([\"document\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/edit-project/notebooks/albert/metadata/part-00000\n"
     ]
    }
   ],
   "source": [
    "ls /notebooks/edit-project/notebooks/albert/metadata/part-0000*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = sa.AlbertEmbeddings.load('albert')\\\n",
    "  .setInputCols([\"document\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = sa.AlbertEmbeddings.load('albert')\\\n",
    "  .setInputCols([\"document\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pipeline = Pipeline().setStages(\n",
    "  [\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    word_embeddings\n",
    "  ]\n",
    ")\n",
    "\n",
    "df_bert = bert_pipeline.fit(sdf).transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_df = df_bert.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
