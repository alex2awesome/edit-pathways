{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "import sparknlp.annotator as sa\n",
    "import sparknlp.base as sb\n",
    "import sparknlp\n",
    "from sparknlp import Finisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from util import util_data_access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: newssniffer-nytimes.db already exists; do you wish to overwrite (y or n)? ^C\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "util_data_access.download_file('newssniffer-nytimes.db.gz', 'edit-pathways/dbs/newssniffer-nytimes.db.gz')\n",
    "! gunzip newssniffer-nytimes.db.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util_data_access.download_file('glove-100d-loc.tar.gz', 'spark-nlp/glove-100d-loc.tar.gz')\n",
    "# ! tar -xzvf glove-100d-loc.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# spark = sparknlp.start()\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "      .config(\"spark.executor.instances\", \"30\")\n",
    "      .config(\"spark.driver.memory\", \"20g\")\n",
    "      .config(\"spark.executor.memory\", \"20g\")\n",
    "      .config(\"spark.executor.cores\", \"5\")\n",
    "      .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\n",
    "      .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.7.5\")\n",
    "      .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "                <div>\n",
       "                    <p><b>SparkContext</b></p>\n",
       "                    <p><a href=\"/sprk/4040/jobs/\">Spark UI</a></p>\n",
       "                    <dl>\n",
       "                      <dt>Version</dt>\n",
       "                        <dd><code>v2.4.4</code></dd>\n",
       "                      <dt>AppName</dt>\n",
       "                        <dd><code>pyspark-shell</code></dd>\n",
       "                    </dl>\n",
       "                    <br>\n",
       "                    <b>Executor Status</b>\n",
       "                    <dl>\n",
       "                      <dt>Running</dt>\n",
       "                        <dd><code>5</code></dd>\n",
       "                      <dt>Pending</dt>\n",
       "                        <dd><code>0</code></dd>\n",
       "                      <dt>Failed</dt>\n",
       "                        <dd><code>0</code></dd>\n",
       "                    </dl>\n",
       "                </div>\n",
       "                \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f22e49e6780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Our Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pyspark.sql.functions as F\n",
    "# import unidecode\n",
    "\n",
    "# conn = sqlite3.connect('../data/diffengine-diffs/db/newssniffer-nytimes.db')\n",
    "with sqlite3.connect('newssniffer-nytimes.db') as conn:\n",
    "\n",
    "    # df = pd.read_sql('''\n",
    "    #      SELECT * from entryversion \n",
    "    #      WHERE entry_id IN (SELECT distinct entry_id FROM entryversion LIMIT 2)\n",
    "    #  ''', con=conn)\n",
    "\n",
    "    df = pd.read_sql('''\n",
    "         SELECT * from entryversion \n",
    "         WHERE entry_id IN (1951413, 1952324, 1969148, 1451793, 1938021)\n",
    "     ''', con=conn)\n",
    "\n",
    "    df = df.assign(summary=lambda df: df['summary'].str.replace('</p><p>', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer, SQLTransformer\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from scipy.spatial import distance\n",
    "from pyspark.sql.types import FloatType\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documenter = (\n",
    "    sb.DocumentAssembler()\n",
    "        .setInputCol(\"summary\")\n",
    "        .setOutputCol(\"document\")\n",
    ")\n",
    "\n",
    "sentencer = (\n",
    "    sa.SentenceDetector()\n",
    "        .setInputCols([\"document\"])\n",
    "        .setOutputCol(\"sentences\")            \n",
    ")\n",
    "\n",
    "tokenizer = (\n",
    "    sa.Tokenizer()\n",
    "        .setInputCols([\"sentences\"])\n",
    "        .setOutputCol(\"token\")\n",
    ")\n",
    "\n",
    "word_embeddings = (\n",
    "    sa.BertEmbeddings\n",
    "        .load('s3://aspangher/spark-nlp/small_bert_L4_128_en_2.6.0_2.4')\n",
    "        .setInputCols([\"sentences\", \"token\"])\n",
    "        .setOutputCol(\"embeddings\")\n",
    "        .setMaxSentenceLength(512)\n",
    "        .setBatchSize(100)\n",
    ")\n",
    "\n",
    "tok_finisher = (\n",
    "    Finisher()\n",
    "    .setInputCols([\"token\"])\n",
    "    .setIncludeMetadata(True)\n",
    ")\n",
    "\n",
    "embeddings_finisher = (\n",
    "    sb.EmbeddingsFinisher()\n",
    "            .setInputCols(\"embeddings\")\n",
    "            .setOutputCols(\"embeddings_vectors\")\n",
    "            .setOutputAsVector(True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT CAST(entry_id AS int) as entry_id,\n",
    "                CAST(version AS int) as version, \n",
    "                ARRAYS_ZIP(finished_token, finished_token_metadata, embeddings_vectors) AS zipped_tokens\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "explode_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, POSEXPLODE(zipped_tokens) AS (word_idx, zipped_token)\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "rename_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, \n",
    "                 version,\n",
    "                 CAST(zipped_token.finished_token_metadata._2 AS int) AS sent_idx,\n",
    "                 COUNT(1) OVER(PARTITION BY entry_id, version, zipped_token.finished_token_metadata._2) as num_words,\n",
    "                 CAST(word_idx AS int) word_idx,\n",
    "                 zipped_token.finished_token AS token,\n",
    "                 zipped_token.embeddings_vectors as word_embedding\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "vector_normalizer = (\n",
    "    Normalizer(\n",
    "        inputCol=\"word_embedding\", \n",
    "        outputCol=\"norm_word_embedding\", \n",
    "        p=2.0\n",
    "    )\n",
    ")\n",
    "similarty_checker = (\n",
    "    BucketedRandomProjectionLSH(\n",
    "        inputCol=\"norm_word_embedding\", \n",
    "        outputCol=\"hashes\", \n",
    "        bucketLength=6.0, \n",
    "        numHashTables=6\n",
    "    )\n",
    ")\n",
    "\n",
    "def cosine_distance(x, y):\n",
    "    return float(distance.cosine(x, y))\n",
    "spark.udf.register(\"cosine_distance\", cosine_distance, \"float\")\n",
    "\n",
    "inner_join = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT word_emb.entry_id                                                    AS entry_id, \n",
    "                 word_emb.version                                                    AS version_x,\n",
    "                 word_emb_2.version                                                  AS version_y,\n",
    "                 word_emb.sent_idx                                                   AS sent_idx_x,\n",
    "                 word_emb_2.sent_idx                                                 AS sent_idx_y,\n",
    "                 word_emb.num_words                                                  AS num_words_x,\n",
    "                 word_emb.word_idx                                                   AS word_idx_x,\n",
    "                 word_emb_2.word_idx                                                 AS word_idx_y,\n",
    "                 word_emb.token                                                      AS token_x,\n",
    "                 word_emb_2.token                                                    AS token_y,\n",
    "                 cosine_distance(word_emb.word_embedding, word_emb_2.word_embedding) AS cosine_distance\n",
    "         FROM __THIS__ word_emb\n",
    "         JOIN __THIS__ word_emb_2\n",
    "         ON word_emb.entry_id = word_emb_2.entry_id and\n",
    "         word_emb.version + 1 = word_emb_2.version\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_word_pair_min_distance = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_x,\n",
    "                sent_idx_y,\n",
    "                word_idx_x,\n",
    "                MIN(num_words) as num_words_total_list,\n",
    "                MIN(distance) as min_word_distance\n",
    "        FROM __THIS__ \n",
    "        GROUP BY entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_x,\n",
    "                sent_idx_y,\n",
    "                word_idx_x\n",
    "      \"\"\")\n",
    ")\n",
    "\n",
    "get_sentence_min_distance = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_x,\n",
    "                sent_idx_y,\n",
    "                (sum_min_word_distance + 1 * ( num_words_total - num_matched_words )) / num_matched_words AS avg_sentence_distance\n",
    "        FROM (SELECT  entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_x,\n",
    "                sent_idx_y, \n",
    "        SUM(min_word_distance) AS sum_min_word_distance,\n",
    "        COUNT(1) AS num_matched_words,\n",
    "        MIN(num_words_total_list) AS num_words_total\n",
    "        FROM __THIS__\n",
    "        GROUP BY entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_x,\n",
    "                sent_idx_y\n",
    "          )\n",
    "      \"\"\")\n",
    ")\n",
    "\n",
    "get_min_sentence_rn = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT * FROM (\n",
    "             SELECT *, ROW_NUMBER() OVER (\n",
    "                         PARTITION BY entry_id, \n",
    "                                      version_x, \n",
    "                                      version_y, \n",
    "                                      sent_idx_x\n",
    "                                      ORDER BY avg_sentence_distance ASC\n",
    "         ) AS rn FROM __THIS__)\n",
    "         where rn = 1\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_pipeline = sb.RecursivePipeline(stages=[\n",
    "    documenter,\n",
    "    sentencer,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    embeddings_finisher,\n",
    "    tok_finisher,\n",
    "    # \n",
    "    zip_tok,\n",
    "    explode_tok,\n",
    "    rename_tok,\n",
    "    vector_normalizer,\n",
    "    similarty_checker\n",
    "    # \n",
    "#     inner_join,\n",
    "    # get_max_word_min, ### too slow!!\n",
    "    \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_emb_sdf = similarity_pipeline.fit(sdf).transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Approximate Join\n",
    "similarity_model = similarity_pipeline.fit(sdf)\n",
    "sim_sdf = similarity_model.transform(sdf)\n",
    "joined_df = (\n",
    "    similarity_model\n",
    "    .stages[10]\n",
    "    .approxSimilarityJoin(sim_sdf, sim_sdf, .5, distCol=\"distance\")\n",
    "    .where((F.col(\"datasetA.entry_id\") == F.col(\"datasetB.entry_id\")) & (F.col(\"datasetA.version\") + 1 == F.col(\"datasetB.version\")))\n",
    "    .select(\n",
    "         F.col(\"datasetA.entry_id\").alias(\"entry_id\"),\n",
    "         F.col(\"datasetA.version\").alias(\"version_x\"),\n",
    "         F.col(\"datasetB.version\").alias(\"version_y\"),\n",
    "         F.col(\"datasetA.sent_idx\").alias(\"sent_idx_x\"),\n",
    "         F.col(\"datasetB.sent_idx\").alias(\"sent_idx_y\"),        \n",
    "         F.col(\"datasetA.word_idx\").alias(\"word_idx_x\"),\n",
    "         F.col(\"datasetB.word_idx\").alias(\"word_idx_y\"),\n",
    "         F.col(\"datasetA.num_words\").alias(\"num_words\"),\n",
    "         F.col(\"datasetA.token\").alias(\"token_x\"),\n",
    "         F.col(\"datasetB.token\").alias(\"token_y\"),\n",
    "         F.col(\"distance\")\n",
    "    )\n",
    ")\n",
    "\n",
    "## get top sentences\n",
    "top_sentence_pipeline = sb.PipelineModel(stages=[\n",
    "    get_word_pair_min_distance,\n",
    "    get_sentence_min_distance,\n",
    "    get_max_word_rn,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sent_df = top_sentence_pipeline.transform(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_words_dfp = min_words_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sent_dfp = min_sent_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sent_dfp = min_sent_dfp.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sentences for Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "normer = (\n",
    "    sa.DocumentNormalizer()\n",
    "    .setInputCols([\"document\"])\n",
    "    .setOutputCol(\"normed_document\")\n",
    "#     .setPatterns([\"[^\\w\\d\\s.,\\\"\\']\"])\n",
    "#     .setPolicy('pretty_all')\n",
    ")\n",
    "\n",
    "sentencer = (\n",
    "    sa.SentenceDetector()\n",
    "        .setInputCols([\"normed_document\"])\n",
    "        .setOutputCol(\"sentences\")            \n",
    ")\n",
    "\n",
    "sentencer_dl = (\n",
    "    sa.SentenceDetectorDLModel\n",
    "        .load('s3://aspangher/spark-nlp/sentence_detector_dl_en')\n",
    "        .setInputCols([\"normed_document\"])\n",
    "        .setOutputCol(\"sentences\")            \n",
    ")\n",
    "\n",
    "sent_finisher = (\n",
    "    Finisher()\n",
    "    .setInputCols([\"sentences\"])\n",
    ")\n",
    "\n",
    "explode_sent = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, POSEXPLODE(finished_sentences) AS (sent_idx, sentence)\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "sentence_splitter_pipeline = sb.RecursivePipeline(stages=[\n",
    "    documenter,\n",
    "    normer,\n",
    "    sentencer,\n",
    "    sent_finisher,\n",
    "    explode_sent\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dfp_nondl = sentence_splitter_pipeline.fit(sdf).transform(sdf).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dfp_dl = sentence_splitter_pipeline.fit(sdf).transform(sdf).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9988, 4)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dfp_dl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The storm’s eye wall was on track to hit the Lower Keys between 7 and 8 a.m., the National Hurricane Center said in its 5 a.m.'"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dfp_nondl.head()['sentence'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eastern advisory.'"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dfp_nondl.head()['sentence'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 4)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sent_dfp_dl\n",
    " .loc[lambda df: df['entry_id'] == 1451793]\n",
    " .loc[lambda df: df['version'] == 0].shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unp.split_sents(df.loc[0]['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b10668a04747ddbc715e505b1df8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_sents = []\n",
    "for entry_id, version, text in tqdm(df[['entry_id', 'version', 'summary']].itertuples(index=False), total=len(df)):\n",
    "    num_sents.append({\n",
    "        'entry_id': entry_id,\n",
    "        'version': version,\n",
    "        'num_sents': len(unp.split_sents(text))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dl</th>\n",
       "      <th>nondl</th>\n",
       "      <th>spacy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry_id</th>\n",
       "      <th>version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1451793</th>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>100</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dl  nondl  spacy\n",
       "entry_id version                  \n",
       "1451793  0        76     83     84\n",
       "         1        76     83     84\n",
       "         2        75     83     84\n",
       "         3        74     82     85\n",
       "         4        86    100    103"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    sent_dfp_dl.groupby(['entry_id', 'version']).apply(lambda df: len(df)).to_frame('dl'),\n",
    "    sent_dfp_nondl.groupby(['entry_id', 'version']).apply(lambda df: len(df)).to_frame('nondl'),\n",
    "    pd.DataFrame(num_sents).set_index(['entry_id', 'version'])['num_sents'].to_frame('spacy')\n",
    "], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>547989</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Overseas weapons sales by the United States to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Overseas weapons sales by the United States to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     entry_id  version  sent_idx  \\\n",
       "153    547989        1         1   \n",
       "173    547989        2         1   \n",
       "\n",
       "                                              sentence  \n",
       "153  Overseas weapons sales by the United States to...  \n",
       "173  Overseas weapons sales by the United States to...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sent_dfp\n",
    " .loc[lambda df: df['entry_id'] == 547989]\n",
    " .loc[lambda df: df['version'].isin([1, 2])]\n",
    " .loc[lambda df: df['sent_idx'] == 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_sents = (min_sent_dfp\n",
    " .loc[lambda df: df['entry_id'] == 547989]\n",
    " .loc[lambda df: df['version_x'] == 0]\n",
    " .loc[lambda df: df['version_y'] == 1]\n",
    " .merge(\n",
    "    sent_dfp, \n",
    "    left_on=['entry_id', 'version_x', 'sent_idx_x'],\n",
    "    right_on=['entry_id', 'version', 'sent_idx']\n",
    " ).drop(['rn', 'version', 'sent_idx',], axis=1)\n",
    " .merge(\n",
    "    sent_dfp, \n",
    "    left_on=['entry_id', 'version_y', 'sent_idx_y'],\n",
    "    right_on=['entry_id', 'version', 'sent_idx']\n",
    " )\n",
    " .drop(['version', 'sent_idx',], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "## download spacy model \n",
    "# download data\n",
    "from util import util_data_access\n",
    "util_data_access.download_file('en_core_web_lg.tar.gz', 'edit-pathways/spacy/en_core_web_lg.tar.gz')\n",
    "! tar -xf en_core_web_lg.tar.gz\n",
    "! mv en_core_web_lg-2.3.1 en_core_web_lg\n",
    "import util.util_newssniffer_parsing as unp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = [\n",
    "    '<table>',\n",
    "    '<tr><th>Sentence idx</th><th>Old Version</th><th>New Version</th><th>Distance</th></tr>',\n",
    "]\n",
    "for s_idx, s1, s2, d in comp_sents[['sentence_x', 'sentence_y', 'avg_sentence_distance']].itertuples():\n",
    "    one_row = '<tr><td>%s</td><td>%s</td><td>%s</td><td>%s</td></tr>'\n",
    "    w1, w2 = unp.get_words(s1), unp.get_words(s2)\n",
    "    hs1, hs2 = unp.html_compare_sentences(*unp.get_list_diff(w1, w2))\n",
    "    html.append(one_row % (s_idx, hs1, hs2, d))\n",
    "    \n",
    "html_output = ''.join(html).replace('$', r'\\$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Sentence idx</th><th>Old Version</th><th>New Version</th><th>Distance</th></tr><tr><td>0</td><td>WASHINGTON — Weapons sales by the United States tripled in 2011 to a record high , driven by major arms sales to Persian Gulf allies concerned about Iran ’s regional ambitions , according to a new study for Congress .</td><td>WASHINGTON — Weapons sales by the United States tripled in 2011 to a record high , driven by major arms sales to Persian Gulf allies concerned about Iran ’s regional ambitions , according to a new study for Congress .</td><td>0.0</td></tr><tr><td>1</td><td>Overseas weapons sales by the United States totaled \\$ 66.3 billion last year , or nearly 78 percent of the global arms market  valued at \\$ 85.3 billion in 2011 .</td><td>Overseas weapons sales by the United States totaled \\$ 66.3 billion last year , or nearly 78 percent of the global arms market <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> valued at \\$ 85.3 billion in 2011 .</td><td>0.08589556865218667</td></tr><tr><td>2</td><td>Russia was a distant second , with \\$ 4.8 billion in deals .</td><td>Russia was a distant second , with \\$ 4.8 billion in deals .</td><td>0.0</td></tr><tr><td>3</td><td>The American weapons sales total was an “ extraordinary increase ” over the \\$ 21.4 billion in deals for 2010 , the study found , and was the largest single - year sales total in the history of United States arms exports .</td><td>The American weapons sales total was an “ extraordinary increase ” over the \\$ 21.4 billion in deals for 2010 , the study found , and was the largest single - year sales total in the history of United States arms exports .</td><td>0.0</td></tr><tr><td>4</td><td>The previous high was in fiscal year 2009 , when American weapons sales overseas totaled nearly \\$ 31 billion .</td><td>The previous high was in fiscal year 2009 , when American weapons sales overseas totaled nearly \\$ 31 billion .</td><td>0.0</td></tr><tr><td>5</td><td>A worldwide economic decline had suppressed arms sales over recent years .</td><td>A worldwide economic decline had suppressed arms sales over recent years .</td><td>0.0</td></tr><tr><td>6</td><td>But increasing tensions with Iran drove a set of Persian Gulf nations — Saudi Arabia , the United Arab Emirates and Oman — to purchase American weapons at record levels .</td><td>But increasing tensions with Iran drove a set of Persian Gulf nations — Saudi Arabia , the United Arab Emirates and Oman — to purchase American weapons at record levels .</td><td>0.0</td></tr><tr><td>7</td><td>These <span style=\"background-color:rgba(255,0,0,0.3)\">gulf</span> states do not share a border with Iran , and their arms purchases focused on expensive warplanes and complex missile defense systems .</td><td>These <span style=\"background-color:rgba(0,255,0,0.3)\">Gulf </span> states do not share a border with Iran , and their arms purchases focused on expensive warplanes and complex missile defense systems .</td><td>0.0</td></tr><tr><td>8</td><td>The report was prepared by the nonpartisan Congressional Research Service , a division of the Library of Congress .</td><td>The report was prepared by the nonpartisan Congressional Research Service , a division of the Library of Congress .</td><td>0.0</td></tr><tr><td>9</td><td>The annual study , written by Richard F. Grimmett and Paul K. Kerr and delivered to Congress on Friday , is considered the most detailed collection of unclassified arms sales data available to the public .</td><td>The annual study , written by Richard F. Grimmett and Paul K. Kerr and delivered to Congress on Friday , is considered the most detailed collection of unclassified arms sales data available to the public .</td><td>0.0</td></tr><tr><td>10</td><td>The agreements with Saudi Arabia included  <span style=\"background-color:rgba(255,0,0,0.3)\">purchasing</span>  84 advanced F-15 fighters , <span style=\"background-color:rgba(255,0,0,0.3)\">upgrading</span>              70 of the F-15 fighters in the current fleet <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">procuring</span> <span style=\"background-color:rgba(255,0,0,0.3)\">a</span> <span style=\"background-color:rgba(255,0,0,0.3)\">variety</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">ammunition</span> <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> <span style=\"background-color:rgba(255,0,0,0.3)\">missiles</span> <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">logistics</span> <span style=\"background-color:rgba(255,0,0,0.3)\">support</span> .</td><td>The agreements with Saudi Arabia included <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">purchase </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> 84 advanced F-15 fighters ,  <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">variety </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> <span style=\"background-color:rgba(0,255,0,0.3)\">ammunition </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">missiles </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">logistics </span> <span style=\"background-color:rgba(0,255,0,0.3)\">support </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">upgrades </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> 70 of the F-15 fighters in the current fleet            .</td><td>0.4023753878866901</td></tr><tr><td>11</td><td>Sales to Saudi Arabia last year also included dozens of Apache and Black Hawk helicopters , all contributing to a total Saudi weapons deal from the United States of \\$ 33.4 billion , according to the study .</td><td>Sales to Saudi Arabia last year also included dozens of Apache and Black Hawk helicopters , all contributing to a total Saudi weapons deal from the United States of \\$ 33.4 billion , according to the study .</td><td>0.0</td></tr><tr><td>12</td><td>The United Arab Emirates purchased a Terminal High Altitude Area Defense , an advanced antimissile shield that includes radars and  valued at \\$ 3.49 billion , as well as 16 Chinook helicopters for \\$ 939 million .</td><td>The United Arab Emirates purchased a Terminal High Altitude Area Defense , an advanced antimissile shield that includes radars and <span style=\"background-color:rgba(0,255,0,0.3)\">is </span> valued at \\$ 3.49 billion , as well as 16 Chinook helicopters for \\$ 939 million .</td><td>0.10670958682484048</td></tr><tr><td>13</td><td>Oman bought 18 F-16 <span style=\"background-color:rgba(255,0,0,0.3)\">fighter</span> <span style=\"background-color:rgba(255,0,0,0.3)\">aircraft</span> for \\$ 1.4 billion .</td><td>Oman bought 18 F-16 <span style=\"background-color:rgba(0,255,0,0.3)\">fighters </span>  for \\$ 1.4 billion .</td><td>0.4781365265741597</td></tr><tr><td>14</td><td>In keeping with recent trends , most of the weapons purchases , worth about \\$ 71.5 billion , were made by developing nations , with about \\$ 56.3 billion of that from the United States .</td><td>In keeping with recent trends , most of the weapons purchases , worth about \\$ 71.5 billion , were made by developing nations , with about \\$ 56.3 billion of that from the United States .</td><td>0.0</td></tr><tr><td>15</td><td>Other significant weapons deals by the United States last year included a \\$ 4.1 billion agreement with India for 10 C-17 transport planes and with Taiwan for Patriot antimissile batteries valued at \\$ 2 billion — an arms deal that outraged officials in Beijing .</td><td>Other significant weapons deals by the United States last year included a \\$ 4.1 billion agreement with India for 10 C-17 transport planes and with Taiwan for Patriot antimissile batteries valued at \\$ 2 billion — an arms deal that outraged officials in Beijing .</td><td>0.0</td></tr><tr><td>16</td><td>To compare weapons sales over various years , the study used figures in 2011 dollars , with amounts for previous years adjusted for inflation to provide a consistent measurement .</td><td>To compare weapons sales over various years , the study used figures in 2011 dollars , with amounts for previous years adjusted for inflation to provide a consistent measurement .</td><td>0.0</td></tr><tr><td>17</td><td>A policy goal of the United States has been to work with Arab allies in the Persian Gulf to knit together a regional missile defense system to protect cities , oil refineries , pipelines and military bases from an Iranian attack .</td><td>A policy goal of the United States has been to work with Arab allies in the Persian Gulf to knit together a regional missile defense system to protect cities , oil refineries , pipelines and military bases from an Iranian attack .</td><td>0.0</td></tr><tr><td>18</td><td>The effort has included deploying radars to increase the range of early warning coverage across the Persian Gulf , as well as introducing command , control and communications systems that could exchange that information with new batteries of missile interceptors sold to the individual nations .</td><td>The effort has included deploying radars to increase the range of early warning coverage across the Persian Gulf , as well as introducing command , control and communications systems that could exchange that information with new batteries of missile interceptors sold to the individual nations .</td><td>0.0</td></tr><tr><td>19</td><td>The missile shield in the Persian Gulf is being built on a country - by - country basis — with these costly arms sales negotiated bilaterally between the United States and individual nations .</td><td>The missile shield in the Persian Gulf is being built on a country - by - country basis — with these costly arms sales negotiated bilaterally between the United States and individual nations .</td><td>0.0</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+----------+----------+----------+-------------------+\n",
      "|entry_id|version_x|version_y|sent_idx_x|sent_idx_y|word_idx_x|      min(distance)|\n",
      "+--------+---------+---------+----------+----------+----------+-------------------+\n",
      "|  547990|        0|        1|        31|        54|       625|0.27467247689876834|\n",
      "|  547990|        0|        1|       110|        69|      2392| 0.3241328806506398|\n",
      "|  547991|        0|        1|        23|        23|       641|0.25599765822360915|\n",
      "|  547991|        2|        3|        44|        44|      1069|                0.0|\n",
      "|  547991|        2|        3|        52|        53|      1328|                0.0|\n",
      "|  547991|        2|        3|        39|        40|       927|0.34708298864380505|\n",
      "|  547990|        0|        1|       113|       113|      2503|                0.0|\n",
      "|  547990|        0|        1|         9|         9|       212|                0.0|\n",
      "|  547988|        0|        1|         3|         3|       106|                0.0|\n",
      "|  547990|        0|        1|         6|        38|       123|0.22111277626924106|\n",
      "|  547990|        0|        1|       104|       104|      2280|                0.0|\n",
      "|  547990|        0|        1|        27|        27|       512|                0.0|\n",
      "|  547991|        1|        2|        46|        46|      1139|                0.0|\n",
      "|  547991|        1|        2|         0|         0|        41|                0.0|\n",
      "|  547991|        1|        2|        21|        21|       589|                0.0|\n",
      "|  547991|        2|        3|        22|        22|       616| 0.2819465760917395|\n",
      "|  547990|        0|        1|        88|        67|      1912|0.29905399528682847|\n",
      "|  547991|        0|        1|         0|         0|        20|0.02387604603129036|\n",
      "|  547991|        2|        3|        55|        56|      1392|                0.0|\n",
      "|  547988|        0|        1|        64|        64|      1565|                0.0|\n",
      "+--------+---------+---------+----------+----------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_word_pair_min_distance.transform(joined_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if the approximation is the same as the full inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist_inner_join = word_emb_sdfp.groupby([\n",
    "    'entry_id',\n",
    "    'version_x',\n",
    "    'version_y',\n",
    "    'sent_idx_x',\n",
    "    'sent_idx_y',\n",
    "    'word_idx_x',\n",
    "    'token_x',\n",
    "])['cosine_distance'].min()\n",
    "\n",
    "min_dist_inner_join.shape\n",
    "\n",
    "min_dist_approx = joined_dfp.groupby([\n",
    "    'entry_id',\n",
    "    'version_x',\n",
    "    'version_y',\n",
    "    'sent_idx_x',\n",
    "    'sent_idx_y',\n",
    "    'word_idx_x',\n",
    "    'num_words',\n",
    "    'token_x',\n",
    "])['distance'].min()\n",
    "\n",
    "joined_dfp[['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y', 'num_words']].drop_duplicates()['num_words'].sum()\n",
    "\n",
    "min_full = (word_emb_sdfp\n",
    " ## get max words\n",
    " .loc[lambda df: df.groupby(['entry_id', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['cosine_distance'].idxmin()]#[des_col_list]\n",
    " ## get mean of sentence\n",
    " .groupby(['entry_id', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'])['cosine_distance'].mean().reset_index()\n",
    " ## get max sentence\n",
    " .loc[lambda df: df.groupby(['entry_id', 'version_x', 'sent_idx_x', 'version_y'])['cosine_distance'].idxmin()]\n",
    ")\n",
    "\n",
    "min_approx = (joined_dfp\n",
    " ## get max words\n",
    " .loc[lambda df: df.groupby(['entry_id', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['distance'].idxmin()]#[des_col_list]\n",
    " ## get mean of sentence\n",
    " .groupby(['entry_id', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'])['distance'].mean().reset_index()\n",
    " ## get max sentence\n",
    " .loc[lambda df: df.groupby(['entry_id', 'version_x', 'sent_idx_x', 'version_y'])['distance'].idxmin()]\n",
    ")\n",
    "\n",
    "(min_full.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['sent_idx_x'].values\n",
    "== min_approx.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['sent_idx_x'].values)\n",
    "\n",
    "(min_full.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['sent_idx_y'].values\n",
    "== min_approx.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['sent_idx_y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf = word_emb_sdf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf = word_emb_sdf.repartition('entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y')#, 'word_idx_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf = get_max_word_min.transform(word_emb_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import spark_partition_id, asc, desc\n",
    "partitions = (\n",
    "    word_emb_sdf\n",
    "        .withColumn(\"partitionId\", spark_partition_id())\n",
    "        .groupBy(\"partitionId\")\n",
    "        .count()\n",
    "        .orderBy(asc(\"count\"))\n",
    "        .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755380"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+----------+----------+----------+--------------------+\n",
      "|entry_id|version_x|version_y|sent_idx_x|sent_idx_y|word_idx_x|min(cosine_distance)|\n",
      "+--------+---------+---------+----------+----------+----------+--------------------+\n",
      "|  547991|        2|        3|         0|        23|         0|          0.45366806|\n",
      "|  547991|        2|        3|         0|        23|         1|          0.31662515|\n",
      "|  547991|        2|        3|         0|        23|         2|          0.32143697|\n",
      "|  547991|        2|        3|         0|        23|         3|          0.32374802|\n",
      "|  547991|        2|        3|         0|        23|         4|          0.34763005|\n",
      "|  547991|        2|        3|         0|        23|         5|           0.3871965|\n",
      "|  547991|        2|        3|         0|        23|         6|          0.33349082|\n",
      "|  547991|        2|        3|         0|        23|         7|          0.40576532|\n",
      "|  547991|        2|        3|         0|        23|         8|           0.3442957|\n",
      "|  547991|        2|        3|         0|        23|         9|          0.39317727|\n",
      "|  547991|        2|        3|         0|        23|        10|          0.42770043|\n",
      "|  547991|        2|        3|         0|        23|        11|           0.5083151|\n",
      "|  547991|        2|        3|         0|        23|        12|          0.42195985|\n",
      "|  547991|        2|        3|         0|        23|        13|          0.31820232|\n",
      "|  547991|        2|        3|         0|        23|        14|           0.4619458|\n",
      "|  547991|        2|        3|         0|        23|        15|          0.36894196|\n",
      "|  547991|        2|        3|         0|        23|        16|          0.35431597|\n",
      "|  547991|        2|        3|         0|        23|        17|            0.537521|\n",
      "|  547991|        2|        3|         0|        23|        18|          0.38610688|\n",
      "|  547991|        2|        3|         0|        23|        19|           0.3644004|\n",
      "+--------+---------+---------+----------+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_emb_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: calculate num words per sentence.\n",
    "## set a filter threshold to filter out any cosine distances that as > .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_emb_sdf.write.mode(\"overwrite\").parquet(\"s3://aspangher/tmp/tmp_bert_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_word_rn = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT *\n",
    "         FROM (SELECT *, ROW_NUMBER() OVER (\n",
    "                         PARTITION BY entry_id, \n",
    "                                      version_x, \n",
    "                                      version_y, \n",
    "                                      sent_idx_x, \n",
    "                                      sent_idx_y, \n",
    "                                      word_idx_x, \n",
    "                                      token_x \n",
    "                                      ORDER BY cosine_distance ASC\n",
    "                                      ) AS rn FROM __THIS__)\n",
    "         where rn = 1\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "get_max_word_cross = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT t1.token_x FROM __THIS__ AS t1\n",
    "         CROSS APPLY\n",
    "             (select TOP 1 cosine_distance\n",
    "              from __THIS__ t2\n",
    "              WHERE t1.entry_id = t2.entry_id\n",
    "              AND t1.version_x = t2.version_x\n",
    "              AND t1.version_y = t2.version_y\n",
    "              AND t1.sent_idx_x = t2.sent_idx_x\n",
    "              AND t1.sent_idx_y = t2.sent_idx_y\n",
    "              AND t1.word_idx_x = t2.word_idx_x\n",
    "              AND t1.token_x = t2.token_x\n",
    "              order by cosine_distance ASC) as t2\n",
    "      \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(inner_join_df\n",
    " ## get max words\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['dot_product'].idxmax()][des_col_list]\n",
    " ## get mean of sentence\n",
    " .groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'])['dot_product'].mean().reset_index()\n",
    " ## get max sentence\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y'])['dot_product'].idxmax()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, b = np.histogram(inner_join_df['dot_product'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_plot = pd.Series({b_i:c_i for c_i, b_i in zip(c, b[:-1])})\n",
    "hist_plot.plot(kind='bar')\n",
    "plt.xticks(range(len(hist_plot))[::2], list(map(lambda x: round(x, 4), hist_plot.index))[::2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entry_id_x  version_x  sent_idx_x  sent_idx_y  word_idx_x  token_x   \n",
       "547989      0          0           0           0           WASHINGTON       0\n",
       "                                               1           —              608\n",
       "                                               2           Weapons       1216\n",
       "Name: dot_product, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inner_join_df\n",
    " .groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])\n",
    " ['dot_product'].idxmax()\n",
    " .head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = (inner_join_df\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['dot_product'].idxmax()]\n",
    " [des_col_list]\n",
    " .groupby([\n",
    "     'entry_id_x', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'\n",
    " ])['dot_product']\n",
    " .mean()\n",
    " .reset_index()\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y'])['dot_product'].idxmax()]\n",
    " .sort_values('sent_idx_x')\n",
    "#  .loc[lambda df: df['sent_idx_x'] != df['sent_idx_y']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                  CONCAT(word_emb.entry_id, '-', \n",
    "#                         word_emb.version, '-',\n",
    "#                         word_emb_2.version, '-',\n",
    "#                         word_emb.sent_idx, '-',\n",
    "#                         word_emb_2.sent_idx, '-',\n",
    "#                         word_emb.word_idx, '-',\n",
    "#                         word_emb_2.word_idx, '-',\n",
    "#                         word_emb.token, '-'\n",
    "#                         )                                                            AS partition_key,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
