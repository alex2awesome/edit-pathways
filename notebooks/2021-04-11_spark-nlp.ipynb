{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "import sparknlp.annotator as sa\n",
    "import sparknlp.base as sb\n",
    "import sparknlp\n",
    "from sparknlp import Finisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from util import util_data_access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "util_data_access.download_file('newssniffer-nytimes.db.gz', 'edit-pathways/dbs/newssniffer-nytimes.db.gz')\n",
    "! gunzip newssniffer-nytimes.db.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util_data_access.download_file('glove-100d-loc.tar.gz', 'spark-nlp/glove-100d-loc.tar.gz')\n",
    "# ! tar -xzvf glove-100d-loc.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# spark = sparknlp.start()\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "      .config(\"spark.executor.instances\", \"30\")\n",
    "      .config(\"spark.driver.memory\", \"20g\")\n",
    "      .config(\"spark.executor.memory\", \"20g\")\n",
    "      .config(\"spark.executor.cores\", \"5\")\n",
    "      .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\n",
    "      .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.7.5\")\n",
    "      .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa.WordEmbeddingsModel.read().load(\"s3://aspangher/spark-nlp/glove-100d.tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "                <div>\n",
       "                    <p><b>SparkContext</b></p>\n",
       "                    <p><a href=\"/sprk/4040/jobs/\">Spark UI</a></p>\n",
       "                    <dl>\n",
       "                      <dt>Version</dt>\n",
       "                        <dd><code>v2.4.4</code></dd>\n",
       "                      <dt>AppName</dt>\n",
       "                        <dd><code>pyspark-shell</code></dd>\n",
       "                    </dl>\n",
       "                    <br>\n",
       "                    <b>Executor Status</b>\n",
       "                    <dl>\n",
       "                      <dt>Running</dt>\n",
       "                        <dd><code>6</code></dd>\n",
       "                      <dt>Pending</dt>\n",
       "                        <dd><code>0</code></dd>\n",
       "                      <dt>Failed</dt>\n",
       "                        <dd><code>0</code></dd>\n",
       "                    </dl>\n",
       "                </div>\n",
       "                \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5ffc312dd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Our Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pyspark.sql.functions as F\n",
    "# import unidecode\n",
    "\n",
    "# conn = sqlite3.connect('../data/diffengine-diffs/db/newssniffer-nytimes.db')\n",
    "conn = sqlite3.connect('newssniffer-nytimes.db')\n",
    "\n",
    "df = pd.read_sql('''\n",
    "     SELECT * from entryversion \n",
    "     WHERE entry_id IN (SELECT distinct entry_id FROM entryversion LIMIT 5)\n",
    " ''', con=conn)\n",
    "\n",
    "# df = pd.read_sql('''\n",
    "#     SELECT entry_id, summary, version from entryversion \n",
    "# ''', con=conn)\n",
    "\n",
    "df = df.assign(summary=lambda df: df['summary'].str.replace('</p><p>', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Sentence Tokenizing on Our Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "documenter = (\n",
    "    sb.DocumentAssembler()\n",
    "    .setInputCol(\"summary\")\n",
    "    .setOutputCol(\"document\")\n",
    "            )\n",
    "\n",
    "sentencer = (sa.SentenceDetector()\n",
    "                .setInputCols([\"document\"])\n",
    "                .setOutputCol(\"sentences\")            \n",
    "            )\n",
    "\n",
    "tokenizer = (\n",
    "    sa.Tokenizer()\n",
    "        .setInputCols([\"sentences\"])\n",
    "        .setOutputCol(\"token\")\n",
    ")\n",
    "\n",
    "sent_finisher = (\n",
    "    Finisher()\n",
    "    .setInputCols([\"sentences\"])\n",
    "    .setIncludeMetadata(True)\n",
    ")\n",
    "\n",
    "tok_finisher = (\n",
    "    Finisher()\n",
    "    .setInputCols([\"token\"])\n",
    "    .setIncludeMetadata(True)\n",
    ")\n",
    "\n",
    "zip_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, ARRAYS_ZIP(finished_token, finished_token_metadata) AS zipped_tokens\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "explode_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, POSEXPLODE(zipped_tokens) AS (word_idx, zipped_token)\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "rename_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, \n",
    "                 version,\n",
    "                 zipped_token.finished_token AS token,\n",
    "                 zipped_token.finished_token_metadata._2 AS sent_idx,\n",
    "                 word_idx\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "sd_pipeline = Pipeline(stages=[\n",
    "    documenter, \n",
    "    sentencer, \n",
    "    tokenizer, \n",
    "    tok_finisher,\n",
    "    zip_tok,\n",
    "    explode_tok,\n",
    "    rename_tok\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = sd_pipeline.fit(sdf).transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_dfp = annotations_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version</th>\n",
       "      <th>token</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>word_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>In</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>Silicon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>Valley</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>just</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>won</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>big</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>against</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>patent</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>lawsuit</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>year</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>after</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>trading</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>claims</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>counterclaims</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>pilfered</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>product</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>ideas</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>Across</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>The</td>\n",
       "      <td>19</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>missile</td>\n",
       "      <td>19</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>shield</td>\n",
       "      <td>19</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>in</td>\n",
       "      <td>19</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "      <td>19</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>Persian</td>\n",
       "      <td>19</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>Gulf</td>\n",
       "      <td>19</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>is</td>\n",
       "      <td>19</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>being</td>\n",
       "      <td>19</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>built</td>\n",
       "      <td>19</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>on</td>\n",
       "      <td>19</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>19</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4939</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>country-by-country</td>\n",
       "      <td>19</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>basis</td>\n",
       "      <td>19</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>—</td>\n",
       "      <td>19</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>with</td>\n",
       "      <td>19</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>these</td>\n",
       "      <td>19</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>costly</td>\n",
       "      <td>19</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>arms</td>\n",
       "      <td>19</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>sales</td>\n",
       "      <td>19</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>negotiated</td>\n",
       "      <td>19</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>bilaterally</td>\n",
       "      <td>19</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>between</td>\n",
       "      <td>19</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "      <td>19</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>United</td>\n",
       "      <td>19</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>States</td>\n",
       "      <td>19</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>19</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>individual</td>\n",
       "      <td>19</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>nations</td>\n",
       "      <td>19</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>547989</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>19</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_id  version               token sent_idx  word_idx\n",
       "0       547988        0                  In        0         0\n",
       "1       547988        0             Silicon        0         1\n",
       "2       547988        0              Valley        0         2\n",
       "3       547988        0                   ,        0         3\n",
       "4       547988        0               Apple        0         4\n",
       "5       547988        0                just        0         5\n",
       "6       547988        0                 won        0         6\n",
       "7       547988        0                 big        0         7\n",
       "8       547988        0             against        0         8\n",
       "9       547988        0             Samsung        0         9\n",
       "10      547988        0                  in        0        10\n",
       "11      547988        0                 the        0        11\n",
       "12      547988        0              patent        0        12\n",
       "13      547988        0             lawsuit        0        13\n",
       "14      547988        0                  of        0        14\n",
       "15      547988        0                 the        0        15\n",
       "16      547988        0                year        0        16\n",
       "17      547988        0                   ,        0        17\n",
       "18      547988        0               after        0        18\n",
       "19      547988        0             trading        0        19\n",
       "20      547988        0              claims        0        20\n",
       "21      547988        0                 and        0        21\n",
       "22      547988        0       counterclaims        0        22\n",
       "23      547988        0                  of        0        23\n",
       "24      547988        0            pilfered        0        24\n",
       "25      547988        0             product        0        25\n",
       "26      547988        0               ideas        0        26\n",
       "27      547988        0                   .        0        27\n",
       "28      547988        0              Across        1        28\n",
       "29      547988        0                 the        1        29\n",
       "...        ...      ...                 ...      ...       ...\n",
       "4927    547989        2                 The       19       577\n",
       "4928    547989        2             missile       19       578\n",
       "4929    547989        2              shield       19       579\n",
       "4930    547989        2                  in       19       580\n",
       "4931    547989        2                 the       19       581\n",
       "4932    547989        2             Persian       19       582\n",
       "4933    547989        2                Gulf       19       583\n",
       "4934    547989        2                  is       19       584\n",
       "4935    547989        2               being       19       585\n",
       "4936    547989        2               built       19       586\n",
       "4937    547989        2                  on       19       587\n",
       "4938    547989        2                   a       19       588\n",
       "4939    547989        2  country-by-country       19       589\n",
       "4940    547989        2               basis       19       590\n",
       "4941    547989        2                   —       19       591\n",
       "4942    547989        2                with       19       592\n",
       "4943    547989        2               these       19       593\n",
       "4944    547989        2              costly       19       594\n",
       "4945    547989        2                arms       19       595\n",
       "4946    547989        2               sales       19       596\n",
       "4947    547989        2          negotiated       19       597\n",
       "4948    547989        2         bilaterally       19       598\n",
       "4949    547989        2             between       19       599\n",
       "4950    547989        2                 the       19       600\n",
       "4951    547989        2              United       19       601\n",
       "4952    547989        2              States       19       602\n",
       "4953    547989        2                 and       19       603\n",
       "4954    547989        2          individual       19       604\n",
       "4955    547989        2             nations       19       605\n",
       "4956    547989        2                   .       19       606\n",
       "\n",
       "[4957 rows x 5 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (annotations_df\n",
    "       .withColumn(\"new\", F.arrays_zip('finished_token', 'finished_token_metadata'))\n",
    "       .withColumn(\"new\", F.explode(\"new\"))\n",
    "       .select(F.col(\"new.finished_token\").alias(\"token\"), F.col(\"new.finished_token_metadata._2\").alias(\"sentence\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = t.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list_df = (annotations_df\n",
    "                .select(\"entry_id\", \"version\", F.posexplode(\"finished_sentences\"))\n",
    "                .withColumnRenamed('col', 'sentence')\n",
    "                .withColumnRenamed('pos', 'sent_idx')\n",
    "               )\n",
    "# tdf = sent_list_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_sent_df = (sent_list_df\n",
    " .alias(\"sent_list_df\")\n",
    " .join(\n",
    "     sent_list_df.alias(\"sent_list_df_2\"),\n",
    "     [F.col(\"sent_list_df.entry_id\") == F.col(\"sent_list_df_2.entry_id\"), \n",
    "      F.col(\"sent_list_df.version\") == F.col(\"sent_list_df_2.version\"), \n",
    "     ], \n",
    "     \"inner\"\n",
    " )\n",
    " .select(\n",
    "     F.col(\"sent_list_df.entry_id\"),\n",
    "     F.col(\"sent_list_df.version\"),\n",
    "     F.col(\"sent_list_df.sent_idx\").alias(\"sent_idx_x\"),\n",
    "     F.col(\"sent_list_df_2.sent_idx\").alias(\"sent_idx_y\"),\n",
    "     F.col(\"sent_list_df.sentence\").alias(\"sentence_x\"),\n",
    "     F.col(\"sent_list_df_2.sentence\").alias(\"sentence_y\"),\n",
    "#    .show(truncate=False)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------+----------+-------------------+--------------------+\n",
      "|entry_id|version|sent_idx_x|sent_idx_y|         sentence_x|          sentence_y|\n",
      "+--------+-------+----------+----------+-------------------+--------------------+\n",
      "|  548743|      1|         0|         0|FORT COLLINS, Colo.| FORT COLLINS, Colo.|\n",
      "|  548743|      1|         0|         1|FORT COLLINS, Colo.|— Annie Hartnett ...|\n",
      "|  548743|      1|         0|         2|FORT COLLINS, Colo.|Now 21 and a lead...|\n",
      "|  548743|      1|         0|         3|FORT COLLINS, Colo.|“I would still sa...|\n",
      "|  548743|      1|         0|         4|FORT COLLINS, Colo.|“When you’re voti...|\n",
      "|  548743|      1|         0|         5|FORT COLLINS, Colo.|” So on Saturday ...|\n",
      "|  548743|      1|         0|         6|FORT COLLINS, Colo.|Each party used t...|\n",
      "|  548743|      1|         0|         7|FORT COLLINS, Colo.|But Mr. Obama, tr...|\n",
      "|  548743|      1|         0|         8|FORT COLLINS, Colo.|“I’m counting on ...|\n",
      "|  548743|      1|         0|         9|FORT COLLINS, Colo.|“Those who oppose...|\n",
      "|  548743|      1|         0|        10|FORT COLLINS, Colo.|But throughout Am...|\n",
      "|  548743|      1|         0|        11|FORT COLLINS, Colo.|And they’re going...|\n",
      "|  548743|      1|         0|        12|FORT COLLINS, Colo.|” “I’m asking you...|\n",
      "|  548743|      1|         0|        13|FORT COLLINS, Colo.|From Iowa State, ...|\n",
      "|  548743|      1|         0|        14|FORT COLLINS, Colo.|That itinerary of...|\n",
      "|  548743|      1|         0|        15|FORT COLLINS, Colo.|“I do think that ...|\n",
      "|  548743|      1|         0|        16|FORT COLLINS, Colo.|“What’s driving t...|\n",
      "|  548743|      1|         0|        17|FORT COLLINS, Colo.|” While Gallup’s ...|\n",
      "|  548743|      1|         0|        18|FORT COLLINS, Colo.|Then, 18 percent ...|\n",
      "|  548743|      1|         0|        19|FORT COLLINS, Colo.|But they voted ov...|\n",
      "+--------+-------+----------+----------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_sent_df.show()\n",
    "\n",
    "\n",
    "## todo: \n",
    "## 0. do this same procedure for diffed sequential versions\n",
    "\n",
    "## 1a. use tokenize and Albert or BERT or Word2Vec to generate vectors of embeddings for each sentence.\n",
    "## 1b. lemmatize each sentence\n",
    "\n",
    "## 2. take Sim_asym along each row, two times using:\n",
    "## a. phi(x, y) = vec(x) \\cdot vec(y)\n",
    "## b. phi(x ,y) = lemmatization\n",
    "\n",
    "## 3. for each sentence, select the argmax in both directions.\n",
    "## 4. choose some reasonable threshold.\n",
    "\n",
    "## 5. For scores above this threshold, co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10000\n",
    "unique_entryids = df['entry_id'].unique()\n",
    "num_chunks = int(unique_entryids.shape[0] / chunksize)\n",
    "\n",
    "output_dfs = []\n",
    "for chunk_id in tqdm(range(num_chunks)):\n",
    "    batch_ids = unique_entryids[chunk_id * chunksize: (chunk_id + 1) * chunksize]\n",
    "    small_df = df.loc[lambda df: df['entry_id'].isin(batch_ids)]\n",
    "    #\n",
    "    sdf = spark.createDataFrame(small_df)\n",
    "    #\n",
    "    annotations_df = sd_pipeline.transform(sdf)\n",
    "    t_df = annotations_df.toPandas()\n",
    "    output_dfs.append(t_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Albert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = (\n",
    "      sb.DocumentAssembler()\n",
    "        .setInputCol(\"summary\")\n",
    "        .setOutputCol(\"document\")\n",
    ")\n",
    "\n",
    "tokenizer = (\n",
    "    sa.Tokenizer()\n",
    "        .setInputCols([\"document\"])\n",
    "        .setOutputCol(\"token\")\n",
    ")\n",
    " \n",
    "word_embeddings = (\n",
    "    sa.AlbertEmbeddings\n",
    "        .load('s3://aspangher/spark-nlp/albert_xxlarge_uncased_en')\n",
    "        .setInputCols([\"document\", \"token\"])\n",
    "        .setOutputCol(\"embeddings\")\n",
    ")\n",
    "\n",
    "embeddings_finisher = (\n",
    "    sb.EmbeddingsFinisher()\n",
    "            .setInputCols(\"embeddings\")\n",
    "            .setOutputCols(\"embeddings_vectors\")\n",
    "            .setOutputAsVector(True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = (\n",
    "    sa.Tokenizer()\n",
    "        .setInputCols([\"document\"])\n",
    "        .setOutputCol(\"token\")\n",
    ")\n",
    "\n",
    "bert_pipeline = Pipeline(stages=\n",
    "  [\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    embeddings_finisher\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = bert_pipeline.fit(sdf).transform(sdf)\n",
    "# df_bert = bert_pipeline_model.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_bert.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_df = (df_bert\n",
    "         .select('entry_id', 'version', 'embeddings_vectors')\n",
    "         .toPandas()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embeddings = (\n",
    "#     sa.WordEmbeddingsModel\n",
    "#         .load('s3://aspangher/spark-nlp/glove-100d.tmp')\n",
    "#         .setInputCols(\"document\", \"token\")\n",
    "#         .setOutputCol(\"embeddings\")    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer, SQLTransformer\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "documenter = (\n",
    "    sb.DocumentAssembler()\n",
    "        .setInputCol(\"summary\")\n",
    "        .setOutputCol(\"document\")\n",
    ")\n",
    "\n",
    "sentencer = (\n",
    "    sa.SentenceDetector()\n",
    "        .setInputCols([\"document\"])\n",
    "        .setOutputCol(\"sentences\")            \n",
    ")\n",
    "\n",
    "tokenizer = (\n",
    "    sa.Tokenizer()\n",
    "        .setInputCols([\"sentences\"])\n",
    "        .setOutputCol(\"token\")\n",
    ")\n",
    " \n",
    "# word_embeddings = (\n",
    "#     sa.AlbertEmbeddings\n",
    "#         .load('s3://aspangher/spark-nlp/albert_large_uncased_en')\n",
    "#         .setInputCols([\"document\", \"token\"])\n",
    "#         .setOutputCol(\"embeddings\")\n",
    "# )\n",
    "\n",
    "# word_embeddings = (\n",
    "#     sa.WordEmbeddings\n",
    "#         .load('s3://aspangher/spark-nlp/glove_100d_en_2.4.0')\n",
    "#         .setInputCols(\"document\", \"token\")\n",
    "#         .setOutputCol(\"embeddings\")    \n",
    "# )\n",
    "\n",
    "word_embeddings = (\n",
    "    sa.BertEmbeddings\n",
    "        .load('s3://aspangher/spark-nlp/small_bert_L4_128_en_2.6.0_2.4')\n",
    "        .setInputCols([\"sentences\", \"token\"])\n",
    "        .setOutputCol(\"embeddings\")\n",
    "        .setMaxSentenceLength(512)\n",
    "        .setBatchSize(100)\n",
    ")\n",
    "\n",
    "tok_finisher = (\n",
    "    Finisher()\n",
    "    .setInputCols([\"token\"])\n",
    "    .setIncludeMetadata(True)\n",
    ")\n",
    "\n",
    "embeddings_finisher = (\n",
    "    sb.EmbeddingsFinisher()\n",
    "            .setInputCols(\"embeddings\")\n",
    "            .setOutputCols(\"embeddings_vectors\")\n",
    "            .setOutputAsVector(True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, ARRAYS_ZIP(finished_token, finished_token_metadata, embeddings_vectors) AS zipped_tokens\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "explode_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, POSEXPLODE(zipped_tokens) AS (word_idx, zipped_token)\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "rename_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, \n",
    "                 version,\n",
    "                 zipped_token.finished_token_metadata._2 AS sent_idx,\n",
    "                 word_idx,\n",
    "                 zipped_token.finished_token AS token,\n",
    "                 zipped_token.embeddings_vectors as word_embedding\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "inner_join = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT word_emb.entry_id as entry_id, \n",
    "                 word_emb.version as version,\n",
    "                 word_emb.sent_idx as sent_idx_x,\n",
    "                 word_emb_2.sent_idx as sent_idx_y,\n",
    "                 word_emb.word_idx as word_idx_x,\n",
    "                 word_emb_2.word_idx as word_idx_y,\n",
    "                 word_emb.token as token_x,\n",
    "                 word_emb_2.token as token_y,\n",
    "                 cosine_distance(word_emb.norm_word_embedding, word_emb_2.norm_word_embedding) as cosine_distance\n",
    "         FROM __THIS__ word_emb\n",
    "         JOIN __THIS__ word_emb_2\n",
    "         ON word_emb.entry_id = word_emb_2.entry_id and\n",
    "         word_emb.version + 1 = word_emb_2.version\n",
    "    \"\"\")\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.cosine_distance(x, y)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "def cosine_distance(x, y):\n",
    "    return float(distance.cosine(x, y))\n",
    "\n",
    "spark.udf.register(\"cosine_distance\", cosine_distance, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=\n",
    "  [\n",
    "    documenter,\n",
    "    sentencer,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    embeddings_finisher,\n",
    "    tok_finisher,\n",
    "    # \n",
    "    zip_tok,\n",
    "    explode_tok,\n",
    "    rename_tok,\n",
    "#     vector_normalizer,\n",
    "    # \n",
    "    inner_join,\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf = pipeline.fit(sdf).transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------+----------+----------+----------+-------+-----------+--------------------+--------------------+\n",
      "|entry_id|version|sent_idx_x|sent_idx_y|word_idx_x|word_idx_y|token_x|    token_y|    word_embedding_x|    word_embedding_y|\n",
      "+--------+-------+----------+----------+----------+----------+-------+-----------+--------------------+--------------------+\n",
      "|  548743|      0|         0|         0|         0|         0|   FORT|       FORT|[0.01180024570675...|[0.01180024570675...|\n",
      "|  548743|      0|         0|         0|         0|         1|   FORT|    COLLINS|[0.01180024570675...|[0.00280006408839...|\n",
      "|  548743|      0|         0|         0|         0|         2|   FORT|          ,|[0.01180024570675...|[0.00304367913983...|\n",
      "|  548743|      0|         0|         0|         0|         3|   FORT|       Colo|[0.01180024570675...|[0.01396648277347...|\n",
      "|  548743|      0|         0|         0|         0|         4|   FORT|          .|[0.01180024570675...|[0.00498540722685...|\n",
      "|  548743|      0|         0|         1|         0|         5|   FORT|          —|[0.01180024570675...|[-0.0026269631203...|\n",
      "|  548743|      0|         0|         1|         0|         6|   FORT|      Annie|[0.01180024570675...|[0.00233846160065...|\n",
      "|  548743|      0|         0|         1|         0|         7|   FORT|   Hartnett|[0.01180024570675...|[0.00485285172300...|\n",
      "|  548743|      0|         0|         1|         0|         8|   FORT|        was|[0.01180024570675...|[0.00517135894255...|\n",
      "|  548743|      0|         0|         1|         0|         9|   FORT|        not|[0.01180024570675...|[-0.0090213867596...|\n",
      "|  548743|      0|         0|         1|         0|        10|   FORT|        old|[0.01180024570675...|[-0.0010356317776...|\n",
      "|  548743|      0|         0|         1|         0|        11|   FORT|     enough|[0.01180024570675...|[-0.0041996955431...|\n",
      "|  548743|      0|         0|         1|         0|        12|   FORT|         to|[0.01180024570675...|[-0.0076805514260...|\n",
      "|  548743|      0|         0|         1|         0|        13|   FORT|       vote|[0.01180024570675...|[-0.0088522340671...|\n",
      "|  548743|      0|         0|         1|         0|        14|   FORT|         in|[0.01180024570675...|[6.81471337112661...|\n",
      "|  548743|      0|         0|         1|         0|        15|   FORT|       2008|[0.01180024570675...|[-0.0203346173227...|\n",
      "|  548743|      0|         0|         1|         0|        16|   FORT|       when|[0.01180024570675...|[-0.0049342992702...|\n",
      "|  548743|      0|         0|         1|         0|        17|   FORT|        she|[0.01180024570675...|[-0.0088841575759...|\n",
      "|  548743|      0|         0|         1|         0|        18|   FORT|volunteered|[0.01180024570675...|[-0.0073374333063...|\n",
      "|  548743|      0|         0|         1|         0|        19|   FORT|        for|[0.01180024570675...|[-0.0149863271175...|\n",
      "+--------+-------+----------+----------+----------+----------+-------+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_emb_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003976158888005288"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(cosine_distance([1,2,3], [2,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|dot_product|\n",
      "+-----------+\n",
      "|        0.0|\n",
      "| 0.41501433|\n",
      "| 0.43567613|\n",
      "| 0.47552684|\n",
      "| 0.41407928|\n",
      "|  0.5067087|\n",
      "|  0.5096954|\n",
      "| 0.42636427|\n",
      "| 0.41374612|\n",
      "|  0.4917009|\n",
      "|  0.6402761|\n",
      "| 0.52566934|\n",
      "| 0.53079957|\n",
      "| 0.58241206|\n",
      "|  0.5745416|\n",
      "| 0.49474263|\n",
      "|  0.5996309|\n",
      "| 0.47629565|\n",
      "|  0.5378158|\n",
      "|  0.5213344|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dot_transformer.transform(word_emb_sdf).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = vector_normalizer.transform(word_emb_sdf).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdfp = word_emb_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdfp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdfp['join_version'] = word_emb_sdfp['version'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000748996976120793"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb_sdfp.iloc[0]['norm_word_embedding'].dot(word_emb_sdfp.iloc[3]['norm_word_embedding'])\n",
    "#.loc[lambda df: df['entry_id'] == 547988].loc[lambda df: df['version'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>word_idx</th>\n",
       "      <th>token</th>\n",
       "      <th>word_embedding</th>\n",
       "      <th>norm_word_embedding</th>\n",
       "      <th>join_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In</td>\n",
       "      <td>[0.5449216365814209, -0.21076048910617828, 0.2...</td>\n",
       "      <td>[0.001921739898593366, -0.0007432753881885494,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Silicon</td>\n",
       "      <td>[0.20658107101917267, 0.47391843795776367, 0.0...</td>\n",
       "      <td>[0.0008927514927824579, 0.002048064669510099, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Valley</td>\n",
       "      <td>[0.4342455267906189, -0.05810766667127609, -0....</td>\n",
       "      <td>[0.0016800237503699555, -0.0002248089020232907...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>[0.2694229483604431, 0.19991809129714966, 0.16...</td>\n",
       "      <td>[0.0011497108088225016, 0.0008531121489176127,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>[0.26225370168685913, -0.34194186329841614, -0...</td>\n",
       "      <td>[0.0012283968796150233, -0.0016016563929651042...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  version sent_idx  word_idx    token  \\\n",
       "0    547988        0        0         0       In   \n",
       "1    547988        0        0         1  Silicon   \n",
       "2    547988        0        0         2   Valley   \n",
       "3    547988        0        0         3        ,   \n",
       "4    547988        0        0         4    Apple   \n",
       "\n",
       "                                      word_embedding  \\\n",
       "0  [0.5449216365814209, -0.21076048910617828, 0.2...   \n",
       "1  [0.20658107101917267, 0.47391843795776367, 0.0...   \n",
       "2  [0.4342455267906189, -0.05810766667127609, -0....   \n",
       "3  [0.2694229483604431, 0.19991809129714966, 0.16...   \n",
       "4  [0.26225370168685913, -0.34194186329841614, -0...   \n",
       "\n",
       "                                 norm_word_embedding  join_version  \n",
       "0  [0.001921739898593366, -0.0007432753881885494,...             1  \n",
       "1  [0.0008927514927824579, 0.002048064669510099, ...             1  \n",
       "2  [0.0016800237503699555, -0.0002248089020232907...             1  \n",
       "3  [0.0011497108088225016, 0.0008531121489176127,...             1  \n",
       "4  [0.0012283968796150233, -0.0016016563929651042...             1  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb_sdfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join_df = (word_emb_sdfp\n",
    " .loc[lambda df: df['entry_id'] == 547989]\n",
    " .loc[lambda df: df['version'].isin([0, 1])]\n",
    " .pipe(lambda df: df.merge(df, \n",
    "                           left_on='join_version',\n",
    "                           right_on='version'\n",
    "                          ))\n",
    ")#.apply(lambda x: x['norm_word_embedding_x'].dot(x['norm_word_embedding_y'], axis=1))\n",
    "\n",
    "#.loc[lambda df: df['version'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeceaf95b44b40f9b1dbe1d0e15dca40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "inner_join_df['dot_product'] = inner_join_df.progress_apply(lambda x: x['norm_word_embedding_x'].dot(x['norm_word_embedding_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, b = np.histogram(inner_join_df['dot_product'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_plot = pd.Series({b_i:c_i for c_i, b_i in zip(c, b[:-1])})\n",
    "hist_plot.plot(kind='bar')\n",
    "plt.xticks(range(len(hist_plot))[::2], list(map(lambda x: round(x, 4), hist_plot.index))[::2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id_x</th>\n",
       "      <th>version_x</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>word_idx_x</th>\n",
       "      <th>token_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>word_idx_y</th>\n",
       "      <th>token_y</th>\n",
       "      <th>dot_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>0.003068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>—</td>\n",
       "      <td>0.002038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id_x  version_x sent_idx_x  word_idx_x     token_x  version_y  \\\n",
       "0      547989          0          0           0  WASHINGTON          1   \n",
       "1      547989          0          0           0  WASHINGTON          1   \n",
       "\n",
       "  sent_idx_y  word_idx_y     token_y  dot_product  \n",
       "0          0           0  WASHINGTON     0.003068  \n",
       "1          0           1           —     0.002038  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_col_list = [\n",
    "    'entry_id_x',\n",
    "    'version_x',\n",
    "    'sent_idx_x',\n",
    "    'word_idx_x',\n",
    "    'token_x',\n",
    "    'version_y',\n",
    "    'sent_idx_y',\n",
    "    'word_idx_y',\n",
    "    'token_y',\n",
    "    'dot_product',\n",
    "]\n",
    "inner_join_df.head(2)[des_col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entry_id_x  version_x  sent_idx_x  sent_idx_y  word_idx_x  token_x   \n",
       "547989      0          0           0           0           WASHINGTON       0\n",
       "                                               1           —              608\n",
       "                                               2           Weapons       1216\n",
       "Name: dot_product, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inner_join_df\n",
    " .groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])\n",
    " ['dot_product'].idxmax()\n",
    " .head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = (inner_join_df\n",
    " .loc[lambda df: \n",
    "     df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['dot_product'].idxmax()\n",
    "  ]\n",
    " [des_col_list]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id_x</th>\n",
       "      <th>version_x</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>dot_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.003246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.003423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.002980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.003206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.003237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.003250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.003365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>547989</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.003153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     entry_id_x  version_x sent_idx_x  version_y sent_idx_y  dot_product\n",
       "0        547989          0          0          1          0     0.003158\n",
       "21       547989          0          1          1          1     0.003044\n",
       "42       547989          0         10          1         10     0.003244\n",
       "63       547989          0         11          1         11     0.003246\n",
       "84       547989          0         12          1         12     0.003280\n",
       "105      547989          0         13          1         13     0.003423\n",
       "126      547989          0         14          1         14     0.002980\n",
       "147      547989          0         15          1         15     0.003206\n",
       "168      547989          0         16          1         16     0.003226\n",
       "189      547989          0         17          1         17     0.003237\n",
       "210      547989          0         18          1         18     0.003250\n",
       "231      547989          0         19          1         19     0.003365\n",
       "252      547989          0          2          1          2     0.003059\n",
       "273      547989          0          3          1          3     0.003155\n",
       "294      547989          0          4          1          4     0.003291\n",
       "315      547989          0          5          1          5     0.003189\n",
       "336      547989          0          6          1          6     0.003455\n",
       "357      547989          0          7          1          7     0.003358\n",
       "378      547989          0          8          1          8     0.003004\n",
       "399      547989          0          9          1          9     0.003153"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(max_words.groupby([\n",
    "     'entry_id_x', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'\n",
    " ])['dot_product']\n",
    " .mean()\n",
    " .reset_index()\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y'])['dot_product'].idxmax()]\n",
    " .sort_values('sent_idx_x')\n",
    "#  .loc[lambda df: df['sent_idx_x'] != df['sent_idx_y']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = (\n",
    "    sa.WordEmbeddings()\n",
    "    .setStoragePath(\"/tmp/glove.6B.100d.txt\", \"TEXT\")\\\n",
    "    .setDimension(100)\\\n",
    "    .setStorageRef(\"glove_100d\") \\\n",
    "    .setInputCols(\"document\", \"token\") \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WordEmbeddings' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-99c1da36fb6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'WordEmbeddings' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "embeddings.fit().transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_emb_sdfp['token'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1570"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_emb_sdfp['embeddings'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "from scipy.spatial import distance\n",
    "\n",
    "distance_udf = F.udf(lambda x: float(distance.euclidean(x, fixed_entry)), FloatType())\n",
    "df = df.withColumn('distances', distance_udf(F.col('features')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     4404\n",
       "False     553\n",
       "Name: word_embedding, dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wor_emb_sdfp['word_embedding'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT word_emb.entry_id, \n",
    "                 word_emb.version,\n",
    "                 word_emb.sentence as sent_idx_x,\n",
    "                 word_emb_2.sentence as sent_idx_y,\n",
    "                 word_emb.token as token_x,\n",
    "                 word_emb_2.token as token_y,\n",
    "                 word_emb.norm_word_embedding as word_embedding_x,\n",
    "                 word_emb_2.norm_word_embedding as word_embedding_y\n",
    "         FROM __THIS__ word_emb\n",
    "         JOIN __THIS__ word_emb_2\n",
    "         ON word_emb.entry_id = word_emb_2.entry_id and\n",
    "         word_emb.version = word_emb_2.version\n",
    "    \"\"\")\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[entry_id: bigint, version: bigint, sent_idx_x: string, sent_idx_y: string, token_x: string, token_y: string, word_embedding_x: vector, word_embedding_y: vector]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_join.transform(word_emb_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------------------+--------------------+--------------------+-------+--------+--------------------+------------+--------------------+---------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|index|version|               title|             created|                 url| source|entry_id|         archive_url|num_versions|             summary|joint_key|      id|            document|           sentences|               token|          embeddings|  embeddings_vectors|\n",
      "+-----+-------+--------------------+--------------------+--------------------+-------+--------+--------------------+------------+--------------------+---------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|68763|      0|Activist Challeng...|2012-08-26 22:55:...|http://www.nytime...|nytimes|  547988|https://www.newss...|           2|In Silicon Valley...| 547988-0|547988-0|[[document, 0, 84...|[[document, 0, 15...|[[token, 0, 1, In...|[[word_embeddings...|[[-0.893178820610...|\n",
      "|68764|      1|Inventor Challeng...|2012-08-27 02:55:...|http://www.nytime...|nytimes|  547988|https://www.newss...|           2|In Silicon Valley...| 547988-1|547988-1|[[document, 0, 84...|[[document, 0, 15...|[[token, 0, 1, In...|[[word_embeddings...|[[-0.893178820610...|\n",
      "|68765|      0|U.S. Foreign Arms...|2012-08-26 22:55:...|http://www.nytime...|nytimes|  547989|https://www.newss...|           3|WASHINGTON — Weap...| 547989-0|547989-0|[[document, 0, 34...|[[document, 0, 21...|[[token, 0, 9, WA...|[[word_embeddings...|[[0.6029991507530...|\n",
      "|68766|      1|U.S. Foreign Arms...|2012-08-27 00:10:...|http://www.nytime...|nytimes|  547989|https://www.newss...|           3|WASHINGTON — Weap...| 547989-1|547989-1|[[document, 0, 34...|[[document, 0, 21...|[[token, 0, 9, WA...|[[word_embeddings...|[[0.6029991507530...|\n",
      "|68767|      2|U.S. Arms Sales M...|2012-08-27 01:20:...|http://www.nytime...|nytimes|  547989|https://www.newss...|           3|WASHINGTON — Weap...| 547989-2|547989-2|[[document, 0, 34...|[[document, 0, 21...|[[token, 0, 9, WA...|[[word_embeddings...|[[0.6029991507530...|\n",
      "+-----+-------+--------------------+--------------------+--------------------+-------+--------+--------------------+------------+--------------------+---------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bert.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df_bert.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dfp['embeddings'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[-0.8931788206100464, -0.3664441406726837, -0...\n",
       "1    [[-0.8931788206100464, -0.3664441406726837, -0...\n",
       "2    [[0.6029991507530212, -0.002772439271211624, -...\n",
       "3    [[0.6029991507530212, -0.002772439271211624, -...\n",
       "4    [[0.6029991507530212, -0.002772439271211624, -...\n",
       "Name: embeddings_vectors, dtype: object"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp['embeddings_vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1570"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfp['embeddings_vectors'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>embeddings_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(token, 0, 1, In, {'sentence': '0'}, []), (to...</td>\n",
       "      <td>[[-0.8931788206100464, -0.3664441406726837, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(token, 0, 1, In, {'sentence': '0'}, []), (to...</td>\n",
       "      <td>[[-0.8931788206100464, -0.3664441406726837, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...</td>\n",
       "      <td>[[0.6029991507530212, -0.002772439271211624, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...</td>\n",
       "      <td>[[0.6029991507530212, -0.002772439271211624, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...</td>\n",
       "      <td>[[0.6029991507530212, -0.002772439271211624, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               token  \\\n",
       "0  [(token, 0, 1, In, {'sentence': '0'}, []), (to...   \n",
       "1  [(token, 0, 1, In, {'sentence': '0'}, []), (to...   \n",
       "2  [(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...   \n",
       "3  [(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...   \n",
       "4  [(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...   \n",
       "\n",
       "                                  embeddings_vectors  \n",
       "0  [[-0.8931788206100464, -0.3664441406726837, -0...  \n",
       "1  [[-0.8931788206100464, -0.3664441406726837, -0...  \n",
       "2  [[0.6029991507530212, -0.002772439271211624, -...  \n",
       "3  [[0.6029991507530212, -0.002772439271211624, -...  \n",
       "4  [[0.6029991507530212, -0.002772439271211624, -...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp[['token', 'embeddings_vectors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(annotatorType='token', begin=0, end=1, result='In', metadata={'sentence': '0'}, embeddings=[])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp['token'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(annotatorType='token', begin=529, end=535, result='himself', metadata={'sentence': '2'}, embeddings=[])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp['token'][0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1570"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfp['embeddings_vectors'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dfp['embeddings_vectors'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = (\n",
    "    sa.Tokenizer()\n",
    "        .setInputCols([\"sentences\"])\n",
    "        .setOutputCol(\"token\")\n",
    ")\n",
    "\n",
    "word_embeddings = (\n",
    "    sa.AlbertEmbeddings\n",
    "        .load('s3://aspangher/spark-nlp/albert_large_uncased_en')\n",
    "        .setInputCols([\"sentences\", \"token\"])\n",
    "        .setOutputCol(\"embeddings\")\n",
    "        .setBatchSize(100)\n",
    ")\n",
    "\n",
    "embeddings_finisher = (\n",
    "    sb.EmbeddingsFinisher()\n",
    "            .setInputCols(\"embeddings\")\n",
    "            .setOutputCols(\"embeddings_vectors\")\n",
    "            .setOutputAsVector(True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_bert\n",
    " .select('entry_id', 'version', 'sentences', 'embeddings_vectors')\n",
    " .write.mode(\"overwrite\").parquet(\"s3://aspangher/tmp/tmp_albert_embeddings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert.select('entry_id', 'version', 'embeddings_vectors').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = bert_pipeline_from_sentences.fit(spark.createDataFrame([[\"\"]]).toDF(\"summary\"))\n",
    "result = pipeline_model.transform(spark.createDataFrame(pd.DataFrame({\"summary\": [\"I love NLP\"]})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_df = (df_bert\n",
    "         .select('entry_id', 'version', 'sent_idx', 'sentence', 'embeddings_vectors')\n",
    "         .toPandas()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = CoNLL().readDataset(spark, 's3://aspangher/spark-nlp/conll/eng.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "training_data = CoNLL().readDataset(spark, 's3://aspangher/spark-nlp/conll/eng.train')\n",
    "\n",
    "get_embeddings = (sa.AlbertEmbeddings\n",
    "        .load('s3://aspangher/spark-nlp/albert_large_uncased_en')\n",
    "        .setInputCols(\"sentence\", \"token\")\n",
    "        .setOutputCol(\"embeddings\")\n",
    "        .setMaxSentenceLength(100)\n",
    "        .setBatchSize(8)\n",
    ")\n",
    "\n",
    "embeddings_finisher = (\n",
    "    sb.EmbeddingsFinisher()\n",
    "        .setInputCols(\"embeddings\")\n",
    "        .setOutputCols(\"embeddings_vectors\")\n",
    "        .setOutputAsVector(True)\n",
    ")\n",
    "\n",
    "sentence_finisher = (\n",
    "    Finisher()\n",
    "       .setInputCols([\"sentence\"]) \n",
    ")\n",
    "\n",
    "pipeline =  Pipeline(stages=[\n",
    "    get_embeddings, \n",
    "    embeddings_finisher, \n",
    "    sentence_finisher\n",
    "])\n",
    "\n",
    "pipelineDF = pipeline.fit(training_data).transform(training_data)\n",
    "\n",
    "(pipelineDF\n",
    " .select('finished_sentence', 'embeddings_vectors')\n",
    " .write\n",
    " .mode(\"overwrite\").parquet('s3://aspangher/tmp/tmp_conll_albert_embeddings.pq')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparknlp.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineDF.select('finished_sentence', 'embeddings_vectors').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline = RecursivePipeline(stages=[\n",
    "    DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\"), \n",
    "    SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentence\"), \n",
    "    Tokenizer().setInputCols([\"sentence\"]).setOutputCol(\"token\").setMaxLength(100).setSplitChars([\"-\", \"\\xa0\", \"—\"]), \n",
    "    BertEmbeddings.pretrained(name = \"bert_large_cased\", lang='en').setInputCols(['sentence', 'token']).setOutputCol('embeddings'), \n",
    "#     NerDLModel.pretrained('onto_bert_large_cased', 'en').setInputCols(['sentence', 'token', 'embeddings']).setOutputCol('ner'), \n",
    "#     NerConverter().setInputCols(['sentence', 'token', 'ner']).setOutputCol('ner_chunk') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT word_emb.entry_id as entry_id, \n",
    "                 word_emb.version as version,\n",
    "                 word_emb.sent_idx as sent_idx_x,\n",
    "                 word_emb_2.sent_idx as sent_idx_y,\n",
    "                 word_emb.word_idx as word_idx_x,\n",
    "                 word_emb_2.word_idx as word_idx_y,\n",
    "                 word_emb.token as token_x,\n",
    "                 word_emb_2.token as token_y,\n",
    "                 word_emb.norm_word_embedding as word_embedding_x,\n",
    "                 word_emb_2.norm_word_embedding as word_embedding_y\n",
    "         FROM __THIS__ word_emb\n",
    "         JOIN __THIS__ word_emb_2\n",
    "         ON word_emb.entry_id = word_emb_2.entry_id and\n",
    "         word_emb.version + 1 = word_emb_2.version\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "cosine_transformer = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT cosine_distance(word_embedding_x, word_embedding_y) as dot_product FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "# vector_normalizer = (\n",
    "#     Normalizer()\n",
    "#     .setInputCol(\"word_embedding\")\n",
    "#     .setOutputCol(\"norm_word_embedding\")\n",
    "#     .setP(1.0)\n",
    "# )\n",
    "\n",
    "# brp = BucketedRandomProjectionLSH(inputCol=\"norm_word_embedding\", outputCol=\"hashes\", bucketLength=1.0)\n",
    "# inner_join_df.progress_apply(lambda x: x['norm_word_embedding_x'].dot(x['norm_word_embedding_y']), axis=1)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
