{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "import sparknlp.annotator as sa\n",
    "import sparknlp.base as sb\n",
    "import sparknlp\n",
    "from sparknlp import Finisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from util import util_data_access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "util_data_access.download_file('newssniffer-nytimes.db.gz', 'edit-pathways/dbs/newssniffer-nytimes.db.gz')\n",
    "! gunzip newssniffer-nytimes.db.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util_data_access.download_file('glove-100d-loc.tar.gz', 'spark-nlp/glove-100d-loc.tar.gz')\n",
    "# ! tar -xzvf glove-100d-loc.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# spark = sparknlp.start()\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "      .config(\"spark.executor.instances\", \"30\")\n",
    "      .config(\"spark.driver.memory\", \"20g\")\n",
    "      .config(\"spark.executor.memory\", \"20g\")\n",
    "      .config(\"spark.executor.cores\", \"5\")\n",
    "      .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\n",
    "      .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.7.5\")\n",
    "      .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa.WordEmbeddingsModel.read().load(\"s3://aspangher/spark-nlp/glove-100d.tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "                <div>\n",
       "                    <p><b>SparkContext</b></p>\n",
       "                    <p><a href=\"/sprk/4040/jobs/\">Spark UI</a></p>\n",
       "                    <dl>\n",
       "                      <dt>Version</dt>\n",
       "                        <dd><code>v2.4.4</code></dd>\n",
       "                      <dt>AppName</dt>\n",
       "                        <dd><code>pyspark-shell</code></dd>\n",
       "                    </dl>\n",
       "                    <br>\n",
       "                    <b>Executor Status</b>\n",
       "                    <dl>\n",
       "                      <dt>Running</dt>\n",
       "                        <dd><code>6</code></dd>\n",
       "                      <dt>Pending</dt>\n",
       "                        <dd><code>0</code></dd>\n",
       "                      <dt>Failed</dt>\n",
       "                        <dd><code>0</code></dd>\n",
       "                    </dl>\n",
       "                </div>\n",
       "                \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5ffc312dd8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Our Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pyspark.sql.functions as F\n",
    "# import unidecode\n",
    "\n",
    "# conn = sqlite3.connect('../data/diffengine-diffs/db/newssniffer-nytimes.db')\n",
    "conn = sqlite3.connect('newssniffer-nytimes.db')\n",
    "\n",
    "df = pd.read_sql('''\n",
    "     SELECT * from entryversion \n",
    "     WHERE entry_id IN (SELECT distinct entry_id FROM entryversion LIMIT 5)\n",
    " ''', con=conn)\n",
    "\n",
    "# df = pd.read_sql('''\n",
    "#     SELECT entry_id, summary, version from entryversion \n",
    "# ''', con=conn)\n",
    "\n",
    "df = df.assign(summary=lambda df: df['summary'].str.replace('</p><p>', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embeddings = (\n",
    "#     sa.WordEmbeddingsModel\n",
    "#         .load('s3://aspangher/spark-nlp/glove-100d.tmp')\n",
    "#         .setInputCols(\"document\", \"token\")\n",
    "#         .setOutputCol(\"embeddings\")    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer, SQLTransformer\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from scipy.spatial import distance\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "documenter = (\n",
    "    sb.DocumentAssembler()\n",
    "        .setInputCol(\"summary\")\n",
    "        .setOutputCol(\"document\")\n",
    ")\n",
    "\n",
    "sentencer = (\n",
    "    sa.SentenceDetector()\n",
    "        .setInputCols([\"document\"])\n",
    "        .setOutputCol(\"sentences\")            \n",
    ")\n",
    "\n",
    "tokenizer = (\n",
    "    sa.Tokenizer()\n",
    "        .setInputCols([\"sentences\"])\n",
    "        .setOutputCol(\"token\")\n",
    ")\n",
    " \n",
    "# word_embeddings = (\n",
    "#     sa.AlbertEmbeddings\n",
    "#         .load('s3://aspangher/spark-nlp/albert_large_uncased_en')\n",
    "#         .setInputCols([\"document\", \"token\"])\n",
    "#         .setOutputCol(\"embeddings\")\n",
    "# )\n",
    "\n",
    "# word_embeddings = (\n",
    "#     sa.WordEmbeddings\n",
    "#         .load('s3://aspangher/spark-nlp/glove_100d_en_2.4.0')\n",
    "#         .setInputCols(\"document\", \"token\")\n",
    "#         .setOutputCol(\"embeddings\")    \n",
    "# )\n",
    "\n",
    "word_embeddings = (\n",
    "    sa.BertEmbeddings\n",
    "        .load('s3://aspangher/spark-nlp/small_bert_L4_128_en_2.6.0_2.4')\n",
    "        .setInputCols([\"sentences\", \"token\"])\n",
    "        .setOutputCol(\"embeddings\")\n",
    "        .setMaxSentenceLength(512)\n",
    "        .setBatchSize(100)\n",
    ")\n",
    "\n",
    "tok_finisher = (\n",
    "    Finisher()\n",
    "    .setInputCols([\"token\"])\n",
    "    .setIncludeMetadata(True)\n",
    ")\n",
    "\n",
    "embeddings_finisher = (\n",
    "    sb.EmbeddingsFinisher()\n",
    "            .setInputCols(\"embeddings\")\n",
    "            .setOutputCols(\"embeddings_vectors\")\n",
    "            .setOutputAsVector(True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, ARRAYS_ZIP(finished_token, finished_token_metadata, embeddings_vectors) AS zipped_tokens\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "explode_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, POSEXPLODE(zipped_tokens) AS (word_idx, zipped_token)\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "rename_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, \n",
    "                 version,\n",
    "                 zipped_token.finished_token_metadata._2 AS sent_idx,\n",
    "                 word_idx,\n",
    "                 zipped_token.finished_token AS token,\n",
    "                 zipped_token.embeddings_vectors as word_embedding\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "inner_join = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT word_emb.entry_id                                                    AS entry_id, \n",
    "                 word_emb.version                                                    AS version_x,\n",
    "                 word_emb_2.version                                                  AS version_y,\n",
    "                 word_emb.sent_idx                                                   AS sent_idx_x,\n",
    "                 word_emb_2.sent_idx                                                 AS sent_idx_y,\n",
    "                 word_emb.word_idx                                                   AS word_idx_x,\n",
    "                 word_emb_2.word_idx                                                 AS word_idx_y,\n",
    "                 word_emb.token                                                      AS token_x,\n",
    "                 word_emb_2.token                                                    AS token_y,\n",
    "                 cosine_distance(word_emb.word_embedding, word_emb_2.word_embedding) AS cosine_distance\n",
    "         FROM __THIS__ word_emb\n",
    "         JOIN __THIS__ word_emb_2\n",
    "         ON word_emb.entry_id = word_emb_2.entry_id and\n",
    "         word_emb.version + 1 = word_emb_2.version\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "#                  CONCAT(word_emb.entry_id, '-', \n",
    "#                         word_emb.version, '-',\n",
    "#                         word_emb_2.version, '-',\n",
    "#                         word_emb.sent_idx, '-',\n",
    "#                         word_emb_2.sent_idx, '-',\n",
    "#                         word_emb.word_idx, '-',\n",
    "#                         word_emb_2.word_idx, '-',\n",
    "#                         word_emb.token, '-'\n",
    "#                         )                                                            AS partition_key,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.cosine_distance(x, y)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "def cosine_distance(x, y):\n",
    "    return float(distance.cosine(x, y))\n",
    "\n",
    "spark.udf.register(\"cosine_distance\", cosine_distance, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=\n",
    "  [\n",
    "    documenter,\n",
    "    sentencer,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    embeddings_finisher,\n",
    "    tok_finisher,\n",
    "    # \n",
    "    zip_tok,\n",
    "    explode_tok,\n",
    "    rename_tok,\n",
    "    # vector_normalizer,\n",
    "    # \n",
    "    inner_join,\n",
    "    # get_max_word_min, ### too slow!!\n",
    "    \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf = pipeline.fit(sdf).transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+----------+----------+----------+----------+-------+--------+---------------+\n",
      "|entry_id|version_x|version_y|sent_idx_x|sent_idx_y|word_idx_x|word_idx_y|token_x| token_y|cosine_distance|\n",
      "+--------+---------+---------+----------+----------+----------+----------+-------+--------+---------------+\n",
      "|  547991|        1|        2|         0|         0|         0|         0| DARAYA|  DARAYA|            0.0|\n",
      "|  547991|        1|        2|         0|         0|         0|         1| DARAYA|       ,|     0.41501433|\n",
      "|  547991|        1|        2|         0|         0|         0|         2| DARAYA|   Syria|     0.43567613|\n",
      "|  547991|        1|        2|         0|         0|         0|         3| DARAYA|       —|     0.47552684|\n",
      "|  547991|        1|        2|         0|         0|         0|         4| DARAYA|    Mass|     0.41407928|\n",
      "|  547991|        1|        2|         0|         0|         0|         5| DARAYA| burials|      0.5067087|\n",
      "|  547991|        1|        2|         0|         0|         0|         6| DARAYA|      in|      0.5096954|\n",
      "|  547991|        1|        2|         0|         0|         0|         7| DARAYA|    this|     0.42636427|\n",
      "|  547991|        1|        2|         0|         0|         0|         8| DARAYA|Damascus|     0.41374612|\n",
      "|  547991|        1|        2|         0|         0|         0|         9| DARAYA|  suburb|      0.4917009|\n",
      "|  547991|        1|        2|         0|         0|         0|        10| DARAYA|      on|      0.6402761|\n",
      "|  547991|        1|        2|         0|         0|         0|        11| DARAYA|  Sunday|     0.52566934|\n",
      "|  547991|        1|        2|         0|         0|         0|        12| DARAYA|  showed|     0.53079957|\n",
      "|  547991|        1|        2|         0|         0|         0|        13| DARAYA|     the|     0.58241206|\n",
      "|  547991|        1|        2|         0|         0|         0|        14| DARAYA| carnage|      0.5745416|\n",
      "|  547991|        1|        2|         0|         0|         0|        15| DARAYA|      of|     0.49474263|\n",
      "|  547991|        1|        2|         0|         0|         0|        16| DARAYA|     the|      0.5996309|\n",
      "|  547991|        1|        2|         0|         0|         0|        17| DARAYA|    past|     0.47629565|\n",
      "|  547991|        1|        2|         0|         0|         0|        18| DARAYA|     few|      0.5378158|\n",
      "|  547991|        1|        2|         0|         0|         0|        19| DARAYA|    days|      0.5213344|\n",
      "+--------+---------+---------+----------+----------+----------+----------+-------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_emb_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdfp = word_emb_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: calculate num words per sentence.\n",
    "## set a filter threshold to filter out any cosine distances that as > .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_emb_sdf.write.mode(\"overwrite\").parquet(\"s3://aspangher/tmp/tmp_bert_embeddings\")\n",
    "# word_emb_sdf = word_emb_sdf.repartition('entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'word_idx_y', 'token_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_word_rn = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT *\n",
    "         FROM (SELECT *, ROW_NUMBER() OVER (\n",
    "                         PARTITION BY entry_id, \n",
    "                                      version_x, \n",
    "                                      version_y, \n",
    "                                      sent_idx_x, \n",
    "                                      sent_idx_y, \n",
    "                                      word_idx_x, \n",
    "                                      token_x \n",
    "                                      ORDER BY cosine_distance ASC\n",
    "                                      ) AS rn FROM __THIS__) \n",
    "         where rn = 1\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "get_max_word_min = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_x,\n",
    "                sent_idx_y,\n",
    "                word_idx_x,\n",
    "                MIN(cosine_distance)\n",
    "        FROM __THIS__ \n",
    "        GROUP BY entry_id,\n",
    "                    version_x,\n",
    "                    version_y,\n",
    "                    sent_idx_x,\n",
    "                    sent_idx_y,\n",
    "                    word_idx_x\n",
    "      \"\"\")\n",
    ")\n",
    "\n",
    "get_max_word_cross = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT t1.token_x FROM __THIS__ AS t1\n",
    "         CROSS APPLY\n",
    "             (select TOP 1 cosine_distance\n",
    "              from __THIS__ t2\n",
    "              WHERE t1.entry_id = t2.entry_id\n",
    "              AND t1.version_x = t2.version_x\n",
    "              AND t1.version_y = t2.version_y\n",
    "              AND t1.sent_idx_x = t2.sent_idx_x\n",
    "              AND t1.sent_idx_y = t2.sent_idx_y\n",
    "              AND t1.word_idx_x = t2.word_idx_x\n",
    "              AND t1.token_x = t2.token_x\n",
    "              order by cosine_distance ASC) as t2\n",
    "      \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(inner_join_df\n",
    " ## get max words\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['dot_product'].idxmax()][des_col_list]\n",
    " ## get mean of sentence\n",
    " .groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'])['dot_product'].mean().reset_index()\n",
    " ## get max sentence\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y'])['dot_product'].idxmax()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = vector_normalizer.transform(word_emb_sdf).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-cb588489cab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_emb_sdfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_emb_sdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/python3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/python3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/python3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/python3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/python3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/python3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_emb_sdfp = word_emb_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdfp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdfp['join_version'] = word_emb_sdfp['version'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000748996976120793"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb_sdfp.iloc[0]['norm_word_embedding'].dot(word_emb_sdfp.iloc[3]['norm_word_embedding'])\n",
    "#.loc[lambda df: df['entry_id'] == 547988].loc[lambda df: df['version'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>word_idx</th>\n",
       "      <th>token</th>\n",
       "      <th>word_embedding</th>\n",
       "      <th>norm_word_embedding</th>\n",
       "      <th>join_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In</td>\n",
       "      <td>[0.5449216365814209, -0.21076048910617828, 0.2...</td>\n",
       "      <td>[0.001921739898593366, -0.0007432753881885494,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Silicon</td>\n",
       "      <td>[0.20658107101917267, 0.47391843795776367, 0.0...</td>\n",
       "      <td>[0.0008927514927824579, 0.002048064669510099, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Valley</td>\n",
       "      <td>[0.4342455267906189, -0.05810766667127609, -0....</td>\n",
       "      <td>[0.0016800237503699555, -0.0002248089020232907...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>[0.2694229483604431, 0.19991809129714966, 0.16...</td>\n",
       "      <td>[0.0011497108088225016, 0.0008531121489176127,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>547988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>[0.26225370168685913, -0.34194186329841614, -0...</td>\n",
       "      <td>[0.0012283968796150233, -0.0016016563929651042...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  version sent_idx  word_idx    token  \\\n",
       "0    547988        0        0         0       In   \n",
       "1    547988        0        0         1  Silicon   \n",
       "2    547988        0        0         2   Valley   \n",
       "3    547988        0        0         3        ,   \n",
       "4    547988        0        0         4    Apple   \n",
       "\n",
       "                                      word_embedding  \\\n",
       "0  [0.5449216365814209, -0.21076048910617828, 0.2...   \n",
       "1  [0.20658107101917267, 0.47391843795776367, 0.0...   \n",
       "2  [0.4342455267906189, -0.05810766667127609, -0....   \n",
       "3  [0.2694229483604431, 0.19991809129714966, 0.16...   \n",
       "4  [0.26225370168685913, -0.34194186329841614, -0...   \n",
       "\n",
       "                                 norm_word_embedding  join_version  \n",
       "0  [0.001921739898593366, -0.0007432753881885494,...             1  \n",
       "1  [0.0008927514927824579, 0.002048064669510099, ...             1  \n",
       "2  [0.0016800237503699555, -0.0002248089020232907...             1  \n",
       "3  [0.0011497108088225016, 0.0008531121489176127,...             1  \n",
       "4  [0.0012283968796150233, -0.0016016563929651042...             1  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb_sdfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join_df = (word_emb_sdfp\n",
    " .loc[lambda df: df['entry_id'] == 547989]\n",
    " .loc[lambda df: df['version'].isin([0, 1])]\n",
    " .pipe(lambda df: df.merge(df, \n",
    "                           left_on='join_version',\n",
    "                           right_on='version'\n",
    "                          ))\n",
    ")#.apply(lambda x: x['norm_word_embedding_x'].dot(x['norm_word_embedding_y'], axis=1))\n",
    "\n",
    "#.loc[lambda df: df['version'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeceaf95b44b40f9b1dbe1d0e15dca40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "inner_join_df['dot_product'] = inner_join_df.progress_apply(lambda x: x['norm_word_embedding_x'].dot(x['norm_word_embedding_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, b = np.histogram(inner_join_df['dot_product'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_plot = pd.Series({b_i:c_i for c_i, b_i in zip(c, b[:-1])})\n",
    "hist_plot.plot(kind='bar')\n",
    "plt.xticks(range(len(hist_plot))[::2], list(map(lambda x: round(x, 4), hist_plot.index))[::2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_col_list = [\n",
    "    'entry_id_x',\n",
    "    'version_x',\n",
    "    'sent_idx_x',\n",
    "    'word_idx_x',\n",
    "    'token_x',\n",
    "    'version_y',\n",
    "    'sent_idx_y',\n",
    "    'word_idx_y',\n",
    "    'token_y',\n",
    "    'dot_product',\n",
    "]\n",
    "inner_join_df.head(2)[des_col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entry_id_x  version_x  sent_idx_x  sent_idx_y  word_idx_x  token_x   \n",
       "547989      0          0           0           0           WASHINGTON       0\n",
       "                                               1           —              608\n",
       "                                               2           Weapons       1216\n",
       "Name: dot_product, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inner_join_df\n",
    " .groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])\n",
    " ['dot_product'].idxmax()\n",
    " .head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = (inner_join_df\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['dot_product'].idxmax()]\n",
    " [des_col_list]\n",
    " .groupby([\n",
    "     'entry_id_x', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'\n",
    " ])['dot_product']\n",
    " .mean()\n",
    " .reset_index()\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y'])['dot_product'].idxmax()]\n",
    " .sort_values('sent_idx_x')\n",
    "#  .loc[lambda df: df['sent_idx_x'] != df['sent_idx_y']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = (\n",
    "    sa.WordEmbeddings()\n",
    "    .setStoragePath(\"/tmp/glove.6B.100d.txt\", \"TEXT\")\\\n",
    "    .setDimension(100)\\\n",
    "    .setStorageRef(\"glove_100d\") \\\n",
    "    .setInputCols(\"document\", \"token\") \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WordEmbeddings' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-99c1da36fb6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'WordEmbeddings' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "embeddings.fit().transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_emb_sdfp['token'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1570"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_emb_sdfp['embeddings'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "from scipy.spatial import distance\n",
    "\n",
    "distance_udf = F.udf(lambda x: float(distance.euclidean(x, fixed_entry)), FloatType())\n",
    "df = df.withColumn('distances', distance_udf(F.col('features')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     4404\n",
       "False     553\n",
       "Name: word_embedding, dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wor_emb_sdfp['word_embedding'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT word_emb.entry_id, \n",
    "                 word_emb.version,\n",
    "                 word_emb.sentence as sent_idx_x,\n",
    "                 word_emb_2.sentence as sent_idx_y,\n",
    "                 word_emb.token as token_x,\n",
    "                 word_emb_2.token as token_y,\n",
    "                 word_emb.norm_word_embedding as word_embedding_x,\n",
    "                 word_emb_2.norm_word_embedding as word_embedding_y\n",
    "         FROM __THIS__ word_emb\n",
    "         JOIN __THIS__ word_emb_2\n",
    "         ON word_emb.entry_id = word_emb_2.entry_id and\n",
    "         word_emb.version = word_emb_2.version\n",
    "    \"\"\")\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[entry_id: bigint, version: bigint, sent_idx_x: string, sent_idx_y: string, token_x: string, token_y: string, word_embedding_x: vector, word_embedding_y: vector]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_join.transform(word_emb_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------------------+--------------------+--------------------+-------+--------+--------------------+------------+--------------------+---------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|index|version|               title|             created|                 url| source|entry_id|         archive_url|num_versions|             summary|joint_key|      id|            document|           sentences|               token|          embeddings|  embeddings_vectors|\n",
      "+-----+-------+--------------------+--------------------+--------------------+-------+--------+--------------------+------------+--------------------+---------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|68763|      0|Activist Challeng...|2012-08-26 22:55:...|http://www.nytime...|nytimes|  547988|https://www.newss...|           2|In Silicon Valley...| 547988-0|547988-0|[[document, 0, 84...|[[document, 0, 15...|[[token, 0, 1, In...|[[word_embeddings...|[[-0.893178820610...|\n",
      "|68764|      1|Inventor Challeng...|2012-08-27 02:55:...|http://www.nytime...|nytimes|  547988|https://www.newss...|           2|In Silicon Valley...| 547988-1|547988-1|[[document, 0, 84...|[[document, 0, 15...|[[token, 0, 1, In...|[[word_embeddings...|[[-0.893178820610...|\n",
      "|68765|      0|U.S. Foreign Arms...|2012-08-26 22:55:...|http://www.nytime...|nytimes|  547989|https://www.newss...|           3|WASHINGTON — Weap...| 547989-0|547989-0|[[document, 0, 34...|[[document, 0, 21...|[[token, 0, 9, WA...|[[word_embeddings...|[[0.6029991507530...|\n",
      "|68766|      1|U.S. Foreign Arms...|2012-08-27 00:10:...|http://www.nytime...|nytimes|  547989|https://www.newss...|           3|WASHINGTON — Weap...| 547989-1|547989-1|[[document, 0, 34...|[[document, 0, 21...|[[token, 0, 9, WA...|[[word_embeddings...|[[0.6029991507530...|\n",
      "|68767|      2|U.S. Arms Sales M...|2012-08-27 01:20:...|http://www.nytime...|nytimes|  547989|https://www.newss...|           3|WASHINGTON — Weap...| 547989-2|547989-2|[[document, 0, 34...|[[document, 0, 21...|[[token, 0, 9, WA...|[[word_embeddings...|[[0.6029991507530...|\n",
      "+-----+-------+--------------------+--------------------+--------------------+-------+--------+--------------------+------------+--------------------+---------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bert.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df_bert.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dfp['embeddings'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[-0.8931788206100464, -0.3664441406726837, -0...\n",
       "1    [[-0.8931788206100464, -0.3664441406726837, -0...\n",
       "2    [[0.6029991507530212, -0.002772439271211624, -...\n",
       "3    [[0.6029991507530212, -0.002772439271211624, -...\n",
       "4    [[0.6029991507530212, -0.002772439271211624, -...\n",
       "Name: embeddings_vectors, dtype: object"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp['embeddings_vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1570"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfp['embeddings_vectors'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>embeddings_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(token, 0, 1, In, {'sentence': '0'}, []), (to...</td>\n",
       "      <td>[[-0.8931788206100464, -0.3664441406726837, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(token, 0, 1, In, {'sentence': '0'}, []), (to...</td>\n",
       "      <td>[[-0.8931788206100464, -0.3664441406726837, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...</td>\n",
       "      <td>[[0.6029991507530212, -0.002772439271211624, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...</td>\n",
       "      <td>[[0.6029991507530212, -0.002772439271211624, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...</td>\n",
       "      <td>[[0.6029991507530212, -0.002772439271211624, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               token  \\\n",
       "0  [(token, 0, 1, In, {'sentence': '0'}, []), (to...   \n",
       "1  [(token, 0, 1, In, {'sentence': '0'}, []), (to...   \n",
       "2  [(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...   \n",
       "3  [(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...   \n",
       "4  [(token, 0, 9, WASHINGTON, {'sentence': '0'}, ...   \n",
       "\n",
       "                                  embeddings_vectors  \n",
       "0  [[-0.8931788206100464, -0.3664441406726837, -0...  \n",
       "1  [[-0.8931788206100464, -0.3664441406726837, -0...  \n",
       "2  [[0.6029991507530212, -0.002772439271211624, -...  \n",
       "3  [[0.6029991507530212, -0.002772439271211624, -...  \n",
       "4  [[0.6029991507530212, -0.002772439271211624, -...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp[['token', 'embeddings_vectors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(annotatorType='token', begin=0, end=1, result='In', metadata={'sentence': '0'}, embeddings=[])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp['token'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(annotatorType='token', begin=529, end=535, result='himself', metadata={'sentence': '2'}, embeddings=[])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp['token'][0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1570"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfp['embeddings_vectors'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dfp['embeddings_vectors'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = (\n",
    "    sa.Tokenizer()\n",
    "        .setInputCols([\"sentences\"])\n",
    "        .setOutputCol(\"token\")\n",
    ")\n",
    "\n",
    "word_embeddings = (\n",
    "    sa.AlbertEmbeddings\n",
    "        .load('s3://aspangher/spark-nlp/albert_large_uncased_en')\n",
    "        .setInputCols([\"sentences\", \"token\"])\n",
    "        .setOutputCol(\"embeddings\")\n",
    "        .setBatchSize(100)\n",
    ")\n",
    "\n",
    "embeddings_finisher = (\n",
    "    sb.EmbeddingsFinisher()\n",
    "            .setInputCols(\"embeddings\")\n",
    "            .setOutputCols(\"embeddings_vectors\")\n",
    "            .setOutputAsVector(True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_bert\n",
    " .select('entry_id', 'version', 'sentences', 'embeddings_vectors')\n",
    " .write.mode(\"overwrite\").parquet(\"s3://aspangher/tmp/tmp_albert_embeddings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert.select('entry_id', 'version', 'embeddings_vectors').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = bert_pipeline_from_sentences.fit(spark.createDataFrame([[\"\"]]).toDF(\"summary\"))\n",
    "result = pipeline_model.transform(spark.createDataFrame(pd.DataFrame({\"summary\": [\"I love NLP\"]})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_df = (df_bert\n",
    "         .select('entry_id', 'version', 'sent_idx', 'sentence', 'embeddings_vectors')\n",
    "         .toPandas()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = CoNLL().readDataset(spark, 's3://aspangher/spark-nlp/conll/eng.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "training_data = CoNLL().readDataset(spark, 's3://aspangher/spark-nlp/conll/eng.train')\n",
    "\n",
    "get_embeddings = (sa.AlbertEmbeddings\n",
    "        .load('s3://aspangher/spark-nlp/albert_large_uncased_en')\n",
    "        .setInputCols(\"sentence\", \"token\")\n",
    "        .setOutputCol(\"embeddings\")\n",
    "        .setMaxSentenceLength(100)\n",
    "        .setBatchSize(8)\n",
    ")\n",
    "\n",
    "embeddings_finisher = (\n",
    "    sb.EmbeddingsFinisher()\n",
    "        .setInputCols(\"embeddings\")\n",
    "        .setOutputCols(\"embeddings_vectors\")\n",
    "        .setOutputAsVector(True)\n",
    ")\n",
    "\n",
    "sentence_finisher = (\n",
    "    Finisher()\n",
    "       .setInputCols([\"sentence\"]) \n",
    ")\n",
    "\n",
    "pipeline =  Pipeline(stages=[\n",
    "    get_embeddings, \n",
    "    embeddings_finisher, \n",
    "    sentence_finisher\n",
    "])\n",
    "\n",
    "pipelineDF = pipeline.fit(training_data).transform(training_data)\n",
    "\n",
    "(pipelineDF\n",
    " .select('finished_sentence', 'embeddings_vectors')\n",
    " .write\n",
    " .mode(\"overwrite\").parquet('s3://aspangher/tmp/tmp_conll_albert_embeddings.pq')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparknlp.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineDF.select('finished_sentence', 'embeddings_vectors').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline = RecursivePipeline(stages=[\n",
    "    DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\"), \n",
    "    SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentence\"), \n",
    "    Tokenizer().setInputCols([\"sentence\"]).setOutputCol(\"token\").setMaxLength(100).setSplitChars([\"-\", \"\\xa0\", \"—\"]), \n",
    "    BertEmbeddings.pretrained(name = \"bert_large_cased\", lang='en').setInputCols(['sentence', 'token']).setOutputCol('embeddings'), \n",
    "#     NerDLModel.pretrained('onto_bert_large_cased', 'en').setInputCols(['sentence', 'token', 'embeddings']).setOutputCol('ner'), \n",
    "#     NerConverter().setInputCols(['sentence', 'token', 'ner']).setOutputCol('ner_chunk') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT word_emb.entry_id as entry_id, \n",
    "                 word_emb.version as version,\n",
    "                 word_emb.sent_idx as sent_idx_x,\n",
    "                 word_emb_2.sent_idx as sent_idx_y,\n",
    "                 word_emb.word_idx as word_idx_x,\n",
    "                 word_emb_2.word_idx as word_idx_y,\n",
    "                 word_emb.token as token_x,\n",
    "                 word_emb_2.token as token_y,\n",
    "                 word_emb.norm_word_embedding as word_embedding_x,\n",
    "                 word_emb_2.norm_word_embedding as word_embedding_y\n",
    "         FROM __THIS__ word_emb\n",
    "         JOIN __THIS__ word_emb_2\n",
    "         ON word_emb.entry_id = word_emb_2.entry_id and\n",
    "         word_emb.version + 1 = word_emb_2.version\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "cosine_transformer = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT cosine_distance(word_embedding_x, word_embedding_y) as dot_product FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "# vector_normalizer = (\n",
    "#     Normalizer()\n",
    "#     .setInputCol(\"word_embedding\")\n",
    "#     .setOutputCol(\"norm_word_embedding\")\n",
    "#     .setP(1.0)\n",
    "# )\n",
    "\n",
    "# brp = BucketedRandomProjectionLSH(inputCol=\"norm_word_embedding\", outputCol=\"hashes\", bucketLength=1.0)\n",
    "# inner_join_df.progress_apply(lambda x: x['norm_word_embedding_x'].dot(x['norm_word_embedding_y']), axis=1)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
