{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sqlite3\n",
    "import sys\n",
    "sys.path.insert(0, '../util')\n",
    "import util_refactorings as ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util_refactorings' from '../util/util_refactorings.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(ur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob('../data/diffengine-diffs/spark-output/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_count_versions = pd.read_sql('''\n",
    "    with c1 as \n",
    "        (SELECT entry_id, \n",
    "            CAST(version as INT) as version, \n",
    "            COUNT(1) as c from split_sentences \n",
    "            GROUP BY entry_id, version)\n",
    "    SELECT entry_id, version from c1\n",
    "    WHERE c < 20 and c > 3\n",
    "''', con=conn)\n",
    "\n",
    "# get join keys\n",
    "low_count_entry_ids = ', '.join(list(map(str, low_count_versions['entry_id'].unique())))\n",
    "joint_keys = low_count_versions.pipe(lambda df: df['entry_id'].astype(str) + '-' + df['version'].astype(str))\n",
    "joint_keys = \"'%s'\" % \"', '\".join(joint_keys.tolist())\n",
    "\n",
    "# matched sentences\n",
    "matched_sentences = pd.read_sql('''\n",
    "    WITH c1 as ( \n",
    "    SELECT *, \n",
    "    entry_id || '-' || version_x as key_x,\n",
    "    entry_id || '-' || version_y as key_y \n",
    "    FROM matched_sentences \n",
    "    )\n",
    "    SELECT *\n",
    "    FROM c1\n",
    "    WHERE key_x in (%s) AND key_y  in (%s)\n",
    "    ''' % (joint_keys, joint_keys)\n",
    ", con=conn)\n",
    "\n",
    "# get split sentences\n",
    "split_sentences = pd.read_sql('''\n",
    "    with c1 AS (\n",
    "        SELECT *, entry_id || '-' || CAST(version AS INT) as key FROM split_sentences\n",
    "    )\n",
    "    SELECT entry_id, CAST(version AS INT) as version, sent_idx, sentence \n",
    "    FROM c1\n",
    "    WHERE key IN (%s)\n",
    "''' % joint_keys, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "      <th>key_x</th>\n",
       "      <th>key_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1135398</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1135398-0</td>\n",
       "      <td>1135398-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1136793</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.026512e-07</td>\n",
       "      <td>6.026512e-07</td>\n",
       "      <td>1136793-1</td>\n",
       "      <td>1136793-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1136865</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.060372e-01</td>\n",
       "      <td>3.060372e-01</td>\n",
       "      <td>1136865-0</td>\n",
       "      <td>1136865-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1135569</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.855780e-01</td>\n",
       "      <td>1.855780e-01</td>\n",
       "      <td>1135569-0</td>\n",
       "      <td>1135569-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1136062</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.791577e-01</td>\n",
       "      <td>1.791577e-01</td>\n",
       "      <td>1136062-0</td>\n",
       "      <td>1136062-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  version_x  version_y  sent_idx_x  sent_idx_y  \\\n",
       "0   1135398          0          1         7.0         8.0   \n",
       "1   1136793          1          2        11.0        15.0   \n",
       "2   1136865          0          1         1.0        11.0   \n",
       "3   1135569          0          1         6.0         8.0   \n",
       "4   1136062          0          1         1.0         1.0   \n",
       "\n",
       "   avg_sentence_distance_x  avg_sentence_distance_y      key_x      key_y  \n",
       "0             0.000000e+00             0.000000e+00  1135398-0  1135398-1  \n",
       "1             6.026512e-07             6.026512e-07  1136793-1  1136793-2  \n",
       "2             3.060372e-01             3.060372e-01  1136865-0  1136865-1  \n",
       "3             1.855780e-01             1.855780e-01  1135569-0  1135569-1  \n",
       "4             1.791577e-01             1.791577e-01  1136062-0  1136062-1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edit_statistics = (matched_sentences\n",
    " .groupby(['entry_id', 'version_x', 'version_y'])\n",
    " .apply(lambda df: pd.Series({\n",
    "     'mean x dist': df['avg_sentence_distance_x'].mean(),\n",
    "     'mean y dist': df['avg_sentence_distance_y'].mean(),\n",
    "     'num_deleted' : df['sent_idx_y'].isnull().sum(),\n",
    "     'num_added' : df['sent_idx_x'].isnull().sum(),\n",
    "     'refactors': ur.find_refactors_for_doc(\n",
    "         df[['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y']].dropna().astype(int)\n",
    "     ),\n",
    " }))\n",
    " .assign(num_refactors=lambda df: df['refactors'].str.len())\n",
    " .assign(overall_mean=lambda df: df[['mean x dist', 'mean y dist']].mean(axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5167\n",
       "1      78\n",
       "2       8\n",
       "3       3\n",
       "6       1\n",
       "Name: num_refactors, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_statistics['num_refactors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean x dist</th>\n",
       "      <th>mean y dist</th>\n",
       "      <th>num_deleted</th>\n",
       "      <th>num_added</th>\n",
       "      <th>refactors</th>\n",
       "      <th>num_refactors</th>\n",
       "      <th>overall_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743901</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.127152</td>\n",
       "      <td>0.097867</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>[(13, 7)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748239</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(13, 12)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749079</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <td>0.165933</td>\n",
       "      <td>0.151510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(16, 6)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753327</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.035911</td>\n",
       "      <td>0.009719</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(11, 10)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762189</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.050644</td>\n",
       "      <td>0.050644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(10, 10)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880778</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <td>0.141510</td>\n",
       "      <td>0.112455</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[(8, 5)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882121</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <td>0.037494</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(10, 9)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882924</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.170068</td>\n",
       "      <td>0.170922</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[(7, 8)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.170495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884356</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.232532</td>\n",
       "      <td>0.212893</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>[(4, 6)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943599</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.114182</td>\n",
       "      <td>0.091824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(6, 5)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean x dist  mean y dist  num_deleted  \\\n",
       "entry_id version_x version_y                                          \n",
       "743901   0         1             0.127152     0.097867            8   \n",
       "748239   2         3             0.000000     0.000000            0   \n",
       "749079   2         3             0.165933     0.151510            0   \n",
       "753327   0         1             0.035911     0.009719            0   \n",
       "762189   0         1             0.050644     0.050644            0   \n",
       "...                                   ...          ...          ...   \n",
       "1880778  2         3             0.141510     0.112455            1   \n",
       "1882121  2         3             0.037494     0.039123            0   \n",
       "1882924  0         1             0.170068     0.170922            1   \n",
       "1884356  0         1             0.232532     0.212893            7   \n",
       "1943599  0         1             0.114182     0.091824            0   \n",
       "\n",
       "                              num_added   refactors  num_refactors  \\\n",
       "entry_id version_x version_y                                         \n",
       "743901   0         1                  3   [(13, 7)]              1   \n",
       "748239   2         3                  0  [(13, 12)]              1   \n",
       "749079   2         3                  0   [(16, 6)]              1   \n",
       "753327   0         1                  0  [(11, 10)]              1   \n",
       "762189   0         1                  0  [(10, 10)]              1   \n",
       "...                                 ...         ...            ...   \n",
       "1880778  2         3                  1    [(8, 5)]              1   \n",
       "1882121  2         3                  0   [(10, 9)]              1   \n",
       "1882924  0         1                  3    [(7, 8)]              1   \n",
       "1884356  0         1                  4    [(4, 6)]              1   \n",
       "1943599  0         1                  0    [(6, 5)]              1   \n",
       "\n",
       "                              overall_mean  \n",
       "entry_id version_x version_y                \n",
       "743901   0         1              0.112510  \n",
       "748239   2         3              0.000000  \n",
       "749079   2         3              0.158721  \n",
       "753327   0         1              0.022815  \n",
       "762189   0         1              0.050644  \n",
       "...                                    ...  \n",
       "1880778  2         3              0.126982  \n",
       "1882121  2         3              0.038309  \n",
       "1882924  0         1              0.170495  \n",
       "1884356  0         1              0.222712  \n",
       "1943599  0         1              0.103003  \n",
       "\n",
       "[90 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_statistics.loc[lambda df: df['num_refactors'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = (matched_sentences\n",
    " .loc[lambda df: (df['entry_id'] == 743901) & (df['version_x'] == 0) & (df['version_y'] == 1)]\n",
    " .sort_values(['sent_idx_x', 'sent_idx_y'])\n",
    ")\n",
    "\n",
    "doc_sentences = (split_sentences\n",
    " .loc[lambda df: (df['entry_id'] == 743901) & (df['version'] == 0) ]\n",
    "                 .sort_values('sent_idx')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences_add(doc):\n",
    "    doc = doc.copy()\n",
    "    sent_idxs = doc['sent_idx_y'].dropna().sort_values().tolist()\n",
    "    additions = doc.loc[lambda df: df['sent_idx_x'].isnull()]['sent_idx_y'].tolist()\n",
    "    \n",
    "    add_aboves = []\n",
    "    add_belows = []\n",
    "    idx_in_add_l = 0\n",
    "    while idx_in_add_l < len(additions):\n",
    "        a = additions[idx_in_add_l]\n",
    "        idx_in_sent_l = sent_idxs.index(a)\n",
    "        cluster_size = 1\n",
    "        if idx_in_sent_l < len(sent_idxs) - cluster_size:\n",
    "            add_above = sent_idxs[idx_in_sent_l + cluster_size]\n",
    "            while add_above in additions:\n",
    "                cluster_size += 1\n",
    "                add_above = sent_idxs[idx_in_sent_l + cluster_size]\n",
    "            add_aboves.append({\n",
    "                'add_above': add_above,\n",
    "                'cluster_size': cluster_size\n",
    "            })\n",
    "        if idx_in_sent_l > 0:\n",
    "            add_below = sent_idxs[idx_in_sent_l - 1]\n",
    "            add_belows.append({\n",
    "                'add_below': add_below,\n",
    "                'cluster_size': cluster_size\n",
    "            })\n",
    "        idx_in_add_l += cluster_size\n",
    "    \n",
    "    return add_aboves, add_belows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "## label each sentence in the old version as:\n",
    "# 1. Deleted in the new version\n",
    "# 2. Sentence added above/sentence added below  \n",
    "# 3. Sentence edited\n",
    "# 4. Sentence refactored\n",
    "\n",
    "# 5. Sentence split (?)\n",
    "# 6. Sentence merge (?)\n",
    "\n",
    "def get_sentence_and_doc_labels(doc, doc_sentences):\n",
    "    # 1. Detect deletions:\n",
    "    deleted_labeled_sentences = pd.concat([\n",
    "        (doc_sentences\n",
    "         .loc[lambda df: ~df['sent_idx'].isin(doc['sent_idx_x'].dropna())]\n",
    "         .assign(deleted_label=True)\n",
    "         .rename(columns={'version':'version_x', 'sent_idx':'sent_idx_x'})\n",
    "         [['entry_id', 'version_x', 'sent_idx_x', 'deleted_label']]\n",
    "        )\n",
    "        ,\n",
    "        (doc\n",
    "         .loc[lambda df: df['sent_idx_y'].isnull()]\n",
    "          .assign(deleted_label=True)\n",
    "          [['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'deleted_label']]\n",
    "        )\n",
    "    ]).drop_duplicates()\n",
    "\n",
    "    # 2. Sentence additions above/below\n",
    "    add_aboves, add_belows = label_sentences_add(doc)\n",
    "    if len(add_aboves) > 0:\n",
    "        add_above_labeled_sentences = (pd.DataFrame(add_aboves)\n",
    "        #  .assign(add_above_label=lambda df: df['cluster_size'].apply(lambda x: 'add above ' + str(x)))\n",
    "         .rename(columns={'cluster_size': 'add_above_label'})\n",
    "         .merge(doc, how='inner', right_on='sent_idx_y', left_on='add_above')\n",
    "         [['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'add_above_label']]\n",
    "        )\n",
    "    else:\n",
    "        add_above_labeled_sentences = pd.DataFrame()\n",
    "        \n",
    "    if len(add_belows) > 0:\n",
    "        add_below_labeled_sentences = (pd.DataFrame(add_belows)\n",
    "        #  .assign(add_below_label=lambda df: df['cluster_size'].apply(lambda x: 'add below ' + str(x))) \n",
    "         .rename(columns={'cluster_size': 'add_below_label'})\n",
    "         .merge(doc, how='inner', right_on='sent_idx_y', left_on='add_below')\n",
    "         [['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'add_below_label']]\n",
    "        )\n",
    "    else:\n",
    "        add_below_labeled_sentences = pd.DataFrame()\n",
    "#         doc['add_below_label'] = 0 \n",
    "\n",
    "    # 3. Sentence edits:\n",
    "    edited_sentences = (doc\n",
    "     .loc[lambda df: df['sent_idx_y'].notnull() & df['sent_idx_x'].notnull() & (df['avg_sentence_distance_x'] > .01)]\n",
    "     .assign(edited_label=True)\n",
    "      [['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'edited_label']]\n",
    "    )\n",
    "    unchanged_sentences = (doc\n",
    "     .loc[lambda df: df['sent_idx_y'].notnull() & df['sent_idx_x'].notnull() & (df['avg_sentence_distance_x'] <= .01)]\n",
    "     .assign(unchanged_label=True)\n",
    "      [['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'unchanged_label']]\n",
    "    )\n",
    "\n",
    "    \n",
    "    # 4. Sentence Refactors\n",
    "    refactors = ur.find_refactors_for_doc(doc)\n",
    "    refactored_sentences = (doc\n",
    "     .loc[lambda df: df.apply(lambda x: (x['sent_idx_x'], x['sent_idx_y']) in refactors, axis=1)]\n",
    "     .assign(refactored_label=lambda df: \n",
    "             df\n",
    "             .pipe(lambda df: df['sent_idx_y'] - df['sent_idx_x'])\n",
    "    #          .apply(lambda x: 'move %(direction)s %(num_steps)s' % ({\n",
    "    #              'direction': 'up' if x < 0 else 'down',\n",
    "    #              'num_steps': abs(int(x))\n",
    "    #              }))\n",
    "            )\n",
    "       [['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'refactored_label']]\n",
    "    )\n",
    "\n",
    "    ## Concat to make Sentence-Level DF \n",
    "    sentence_label_df = (pd.concat([\n",
    "        deleted_labeled_sentences,\n",
    "        add_above_labeled_sentences,\n",
    "        add_below_labeled_sentences,\n",
    "        edited_sentences,\n",
    "        unchanged_sentences,\n",
    "        refactored_sentences,\n",
    "    ])\n",
    "     .assign(version_y=lambda df: df['version_y'].fillna(method='bfill'))\n",
    "     .fillna(False)\n",
    "     .astype(int)\n",
    "    )\n",
    "    if 'add_below_label' not in sentence_label_df:\n",
    "        sentence_label_df['add_below_label'] = 0\n",
    "    if 'add_above_label' not in sentence_label_df:\n",
    "        sentence_label_df['add_above_label'] = 0\n",
    "    \n",
    "    sentence_label_df = (sentence_label_df\n",
    "         .groupby(['entry_id', 'version_x', 'sent_idx_x'])\n",
    "         .agg({\n",
    "             'deleted_label': lambda s: max(s),\n",
    "             'add_above_label': lambda s: max(s),\n",
    "             'add_below_label': lambda s: max(s),\n",
    "             'edited_label': lambda s: max(s),\n",
    "             'unchanged_label': lambda s: max(s),\n",
    "             'refactored_label': lambda s: min(s)\n",
    "         })\n",
    "         .reset_index()\n",
    "        )\n",
    "    \n",
    "    sentence_label_df = doc_sentences.merge(\n",
    "            sentence_label_df,\n",
    "            how='left',\n",
    "            left_on=['entry_id', 'version', 'sent_idx'],\n",
    "            right_on=['entry_id', 'version_x', 'sent_idx_x']\n",
    "        ).drop(['version_x', 'sent_idx_x'], axis=1).fillna(0)\n",
    "        \n",
    "    ## Make Doc-Label DF\n",
    "    doc_label_df = (sentence_label_df\n",
    "     .assign(refactored_label=lambda df: (df['refactored_label'] != 0).astype(int))\n",
    "     .groupby(['entry_id', 'version'])\n",
    "     .aggregate({\n",
    "         'deleted_label':'sum',\n",
    "         'add_above_label':'sum',\n",
    "         'edited_label': 'sum',\n",
    "         'refactored_label': 'sum',\n",
    "         'sentence': lambda s: '<SENT>'.join(s)\n",
    "     })\n",
    "     .rename(columns={\n",
    "         'deleted_label': 'num_deleted',\n",
    "         'add_above_label': 'num_added',\n",
    "         'edited_label': 'num_edited',\n",
    "         'refactored_label': 'num_refactored',\n",
    "         'sentence': 'sentences'\n",
    "     })\n",
    "    )   \n",
    "    \n",
    "    return sentence_label_df, doc_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_sentence_labels = []\n",
    "all_doc_labels = []\n",
    "# for sanity checking\n",
    "all_matched_sentences = []\n",
    "all_split_sentences = []\n",
    "\n",
    "for _, entry_id, v_x, v_y in (\n",
    "    matched_sentences[['entry_id', 'version_x', 'version_y']]\n",
    "    .drop_duplicates()\n",
    "    .head()\n",
    "    .itertuples()\n",
    "):\n",
    "    doc = (matched_sentences\n",
    "     .loc[lambda df: (df['entry_id'] == entry_id) & (df['version_x'] == v_x) & (df['version_y'] == v_y)]\n",
    "     .sort_values(['sent_idx_x', 'sent_idx_y'])\n",
    "    )\n",
    "\n",
    "    doc_sentences = (split_sentences\n",
    "     .loc[lambda df: (df['entry_id'] == entry_id) & (df['version'] == v_x) ]\n",
    "                     .sort_values('sent_idx')\n",
    "    )\n",
    "    \n",
    "    all_matched_sentences.append(doc)\n",
    "    all_split_sentences.append(doc_sentences)\n",
    "    sentence_label_df, doc_label_df = get_sentence_and_doc_labels(doc, doc_sentences)\n",
    "    all_sentence_labels.append(sentence_label_df)\n",
    "    all_doc_labels.append(doc_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc_labels_df = pd.concat(all_doc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc_labels_df.to_csv('../modeling/data/doc-data-small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence_labels_df = pd.concat(all_sentence_labels)\n",
    "## check \n",
    "assert (all_sentence_labels_df[['edited_label', 'unchanged_label', 'refactored_label']]\n",
    "        .sum(axis=1)\n",
    "        .pipe(lambda s: s == 1)\n",
    "        .all()\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence_labels_df.to_csv('../modeling/data/sentence-data-small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list(map(mul, torch.tensor([1,2,3]), [2,3,4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add, mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
