{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Data for Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'nyt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap-matched-sentences.db           independent-matched-sentences.db\r\n",
      "bbc-2-matched-sentences.db        nyt-matched-sentences.db\r\n",
      "guardian-matched-sentences.db     reuters-matched-sentences.db\r\n",
      "guardian-matched-sentences.db.gz  wp-matched-sentences.db.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/diffengine-diffs/spark-output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matched_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>split_sentences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name\n",
       "0  matched_sentences\n",
       "1    split_sentences"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from util import util_refactorings as ur\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "import os \n",
    "\n",
    "db_filename = '../data/diffengine-diffs/spark-output/%s-matched-sentences.db' % source\n",
    "\n",
    "if not os.path.exists(db_filename):\n",
    "    db_zip = db_filename + '.gz'\n",
    "    ! gunzip $db_zip\n",
    "\n",
    "conn = sqlite3.connect(db_filename)\n",
    "pd.read_sql('''SELECT \n",
    "                    name\n",
    "                FROM \n",
    "                    sqlite_master \n",
    "                WHERE \n",
    "                    type ='table' AND \n",
    "                    name NOT LIKE 'sqlite_%';\n",
    "''', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_count_versions = pd.read_sql('''\n",
    "    with c1 as \n",
    "        (SELECT entry_id, version, COUNT(1) as c from split_sentences GROUP BY entry_id, version)\n",
    "    SELECT entry_id, version from c1\n",
    "    WHERE c < 10 and c > 5\n",
    "''', con=conn)\n",
    "\n",
    "# get join keys\n",
    "low_count_entry_ids = ', '.join(list(map(str, low_count_versions['entry_id'].unique())))\n",
    "joint_keys = low_count_versions.pipe(lambda df: df['entry_id'].astype(str) + '-' + df['version'].astype(str))\n",
    "joint_keys = \"'%s'\" % \"', '\".join(joint_keys.tolist())\n",
    "\n",
    "# matched sentences\n",
    "matched_sentences = pd.read_sql('''\n",
    "    WITH c1 as ( \n",
    "    SELECT *, \n",
    "    entry_id || '-' || version_x as key_x,\n",
    "    entry_id || '-' || version_y as key_y \n",
    "    FROM matched_sentences \n",
    "    )\n",
    "    SELECT *\n",
    "    FROM c1\n",
    "    WHERE key_x in (%s) AND key_y  in (%s)\n",
    "    ''' % (joint_keys, joint_keys)\n",
    ", con=conn)\n",
    "\n",
    "# get split sentences\n",
    "split_sentences = pd.read_sql('''\n",
    "    with c1 AS (\n",
    "        SELECT *, entry_id || '-' || version as key FROM split_sentences\n",
    "    )\n",
    "    SELECT * from c1\n",
    "    WHERE key IN (%s)\n",
    "''' % joint_keys, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sentences = matched_sentences.assign(source=source)\n",
    "split_sentences = split_sentences.assign(source=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_arcs_dict = matched_sentences.to_dict(orient='rows')\n",
    "\n",
    "# get HTML diffs\n",
    "doc_arcs = (matched_sentences\n",
    " .merge(split_sentences, how='outer', \n",
    "              right_on=['source', 'entry_id', 'version', 'sent_idx'],\n",
    "              left_on=['source', 'entry_id', 'version_x', 'sent_idx_x'] ,\n",
    "  ).drop(['version', 'sent_idx'], axis=1)\n",
    " .merge(split_sentences, how='outer', \n",
    "              right_on=['source', 'entry_id', 'version', 'sent_idx'],\n",
    "              left_on=['source', 'entry_id', 'version_y', 'sent_idx_y'] ,\n",
    "  ).drop(['version', 'sent_idx'], axis=1) \n",
    ")\n",
    "\n",
    "grouped_arcs = (matched_sentences\n",
    " .groupby(['source', 'entry_id', 'version_x', 'version_y'])\n",
    " .apply(lambda df: \n",
    "    df[['version_x', 'version_y', 'sent_idx_x', 'sent_idx_y',\n",
    "        'avg_sentence_distance_x', 'avg_sentence_distance_y'\n",
    "       ]].to_dict(orient='rows')\n",
    " )\n",
    " .to_frame('arcs')\n",
    ")\n",
    "\n",
    "grouped_nodes = (split_sentences\n",
    " .groupby(['source', 'entry_id', 'version'])\n",
    " .apply(lambda df: df[['version', 'sent_idx', 'sentence']].to_dict(orient='rows'))\n",
    ").to_frame('nodes').reset_index()\n",
    "\n",
    "matched_grouped_nodes = (grouped_nodes\n",
    " .merge(\n",
    "     grouped_nodes.assign(next_vers=lambda df: df['version'] - 1), \n",
    "     left_on=['source', 'entry_id', 'version'], \n",
    "     right_on=['source', 'entry_id', 'next_vers']\n",
    " )\n",
    " .assign(nodes=lambda df: df['nodes_x'] + df['nodes_y'])\n",
    " [['source', 'entry_id', 'version_x', 'version_y', 'nodes']]\n",
    " .set_index(['source', 'entry_id', 'version_x', 'version_y'])\n",
    ")\n",
    "\n",
    "output = (\n",
    "    pd.concat([matched_grouped_nodes, grouped_arcs], axis=1)\n",
    "    .to_dict(orient='index')\n",
    ")\n",
    "\n",
    "output = {str(k): v for k, v in output.items()}\n",
    "\n",
    "import json\n",
    "with open('../evaluation/data/sample_datum_small.json', 'w') as f:\n",
    "    json.dump(output, f )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_sents = (\n",
    "    matched_sentences\n",
    "     .groupby(['entry_id', 'version_x', 'version_y'])\n",
    "     [['sent_idx_x','sent_idx_y']].apply(lambda df: df.isnull().sum())\n",
    "    #  .sort_values(ascending=False).loc[lambda s: s <4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_sents.loc[lambda df: df['sent_idx_y'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_sents = (\n",
    "    matched_sentences\n",
    "     .groupby(['entry_id', 'version_x', 'version_y'])\n",
    "     [['avg_sentence_distance_x', 'avg_sentence_distance_y']]\n",
    "     .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_level_stats = pd.concat([\n",
    "    null_sents, \n",
    "    non_zero_sents\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604236</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.979898e-01</td>\n",
       "      <td>2.947833e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692496</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9.875585e-02</td>\n",
       "      <td>9.875585e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852870</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.193558e-01</td>\n",
       "      <td>1.188369e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870103</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.529579e-01</td>\n",
       "      <td>2.527408e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927805</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.149481e-01</td>\n",
       "      <td>1.650758e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968656</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.309153e-02</td>\n",
       "      <td>3.309153e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039526</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.560334e-01</td>\n",
       "      <td>3.406636e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249462</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.066311e-01</td>\n",
       "      <td>1.066311e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461204</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.842804e-01</td>\n",
       "      <td>1.842804e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537365</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.002909e-01</td>\n",
       "      <td>1.001699e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786689</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.557489e-01</td>\n",
       "      <td>1.574476e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853390</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.103538e-01</td>\n",
       "      <td>2.089036e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862395</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.612274e-07</td>\n",
       "      <td>1.612274e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945539</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.438302e-01</td>\n",
       "      <td>1.421970e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976079</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.312448e-02</td>\n",
       "      <td>1.312448e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sent_idx_x  sent_idx_y  avg_sentence_distance_x  \\\n",
       "entry_id version_x version_y                                                    \n",
       "604236   1         2                   3           2             2.979898e-01   \n",
       "692496   0         1                   3           3             9.875585e-02   \n",
       "852870   0         1                   3           3             1.193558e-01   \n",
       "870103   0         1                   3           1             2.529579e-01   \n",
       "927805   2         3                   3           1             2.149481e-01   \n",
       "968656   0         1                   3           0             3.309153e-02   \n",
       "1039526  3         4                   3           2             3.560334e-01   \n",
       "1249462  0         1                   3           1             1.066311e-01   \n",
       "1461204  0         1                   3           0             1.842804e-01   \n",
       "1537365  0         1                   3           1             1.002909e-01   \n",
       "1786689  0         1                   3           2             1.557489e-01   \n",
       "1853390  1         2                   3           1             2.103538e-01   \n",
       "1862395  0         1                   3           0             1.612274e-07   \n",
       "1945539  0         1                   3           1             1.438302e-01   \n",
       "1976079  7         8                   3           5             1.312448e-02   \n",
       "\n",
       "                              avg_sentence_distance_y  \n",
       "entry_id version_x version_y                           \n",
       "604236   1         2                     2.947833e-01  \n",
       "692496   0         1                     9.875585e-02  \n",
       "852870   0         1                     1.188369e-01  \n",
       "870103   0         1                     2.527408e-01  \n",
       "927805   2         3                     1.650758e-01  \n",
       "968656   0         1                     3.309153e-02  \n",
       "1039526  3         4                     3.406636e-01  \n",
       "1249462  0         1                     1.066311e-01  \n",
       "1461204  0         1                     1.842804e-01  \n",
       "1537365  0         1                     1.001699e-01  \n",
       "1786689  0         1                     1.574476e-01  \n",
       "1853390  1         2                     2.089036e-01  \n",
       "1862395  0         1                     1.612274e-07  \n",
       "1945539  0         1                     1.421970e-01  \n",
       "1976079  7         8                     1.312448e-02  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_level_stats.loc[lambda df: df['sent_idx_x'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_index = doc_level_stats.loc[lambda df: df['sent_idx_x'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([( 604236, 1, 2),\n",
       "            ( 692496, 0, 1),\n",
       "            ( 852870, 0, 1),\n",
       "            ( 870103, 0, 1),\n",
       "            ( 927805, 2, 3),\n",
       "            ( 968656, 0, 1),\n",
       "            (1039526, 3, 4),\n",
       "            (1249462, 0, 1),\n",
       "            (1461204, 0, 1),\n",
       "            (1537365, 0, 1),\n",
       "            (1786689, 0, 1),\n",
       "            (1853390, 1, 2),\n",
       "            (1862395, 0, 1),\n",
       "            (1945539, 0, 1),\n",
       "            (1976079, 7, 8)],\n",
       "           names=['entry_id', 'version_x', 'version_y'])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_index.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge both\n",
    "merged_matched_sentences = (matched_sentences\n",
    " .merge(\n",
    "    split_sentences, left_on=['entry_id', 'version_x', 'sent_idx_x'], right_on=['entry_id', 'version', 'sent_idx'],\n",
    "    how='left'\n",
    " ).drop(['version', 'sent_idx', 'key', 'key_x', 'key_y'], axis=1)\n",
    " .merge(\n",
    "    split_sentences, left_on=['entry_id', 'version_y', 'sent_idx_y'], right_on=['entry_id', 'version', 'sent_idx'],\n",
    "    how='left'\n",
    " ).drop(['version', 'sent_idx', 'key',], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "      <th>sentence_x</th>\n",
       "      <th>sentence_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1651691</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There has not been a proclamation about Mr. Mc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1650749</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A 55-year-old woman came forward to the police...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1165597</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There was no immediate claim of responsibility...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1322807</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The whale stranding was the largest in the cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1598136</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In each newsletter, our gender writer, Maya Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9672</th>\n",
       "      <td>1450768</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhaira Franco, 35, who works for Facebook in s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9676</th>\n",
       "      <td>1450768</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An aftershock with a magnitude of 5.7 and an e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9698</th>\n",
       "      <td>1223039</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Schlafly’s obituary will be posted soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9709</th>\n",
       "      <td>1223039</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>” A full version of Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>1883246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The 27-year-old driver, who failed a breath-al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_id  version_x  version_y  sent_idx_x  sent_idx_y  \\\n",
       "24     1651691          0          1         NaN         6.0   \n",
       "42     1650749          0          1         NaN         1.0   \n",
       "155    1165597          0          1         NaN         3.0   \n",
       "245    1322807          1          2         NaN         7.0   \n",
       "307    1598136          3          4         NaN         1.0   \n",
       "...        ...        ...        ...         ...         ...   \n",
       "9672   1450768          0          1         NaN         4.0   \n",
       "9676   1450768          0          1         NaN         6.0   \n",
       "9698   1223039          0          1         NaN         7.0   \n",
       "9709   1223039          0          1         NaN         6.0   \n",
       "9731   1883246          0          1         NaN         5.0   \n",
       "\n",
       "      avg_sentence_distance_x  avg_sentence_distance_y sentence_x  \\\n",
       "24                        NaN                      NaN        NaN   \n",
       "42                        NaN                      NaN        NaN   \n",
       "155                       NaN                      NaN        NaN   \n",
       "245                       NaN                      NaN        NaN   \n",
       "307                       NaN                      NaN        NaN   \n",
       "...                       ...                      ...        ...   \n",
       "9672                      NaN                      NaN        NaN   \n",
       "9676                      NaN                      NaN        NaN   \n",
       "9698                      NaN                      NaN        NaN   \n",
       "9709                      NaN                      NaN        NaN   \n",
       "9731                      NaN                      NaN        NaN   \n",
       "\n",
       "                                             sentence_y  \n",
       "24    There has not been a proclamation about Mr. Mc...  \n",
       "42    A 55-year-old woman came forward to the police...  \n",
       "155   There was no immediate claim of responsibility...  \n",
       "245   The whale stranding was the largest in the cou...  \n",
       "307   In each newsletter, our gender writer, Maya Sa...  \n",
       "...                                                 ...  \n",
       "9672  Zhaira Franco, 35, who works for Facebook in s...  \n",
       "9676  An aftershock with a magnitude of 5.7 and an e...  \n",
       "9698           Schlafly’s obituary will be posted soon.  \n",
       "9709                           ” A full version of Mrs.  \n",
       "9731  The 27-year-old driver, who failed a breath-al...  \n",
       "\n",
       "[327 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many additions there are\n",
    "merged_matched_sentences.loc[lambda df: df['sent_idx_x'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch to MTurk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mturk' (namespace)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import boto3\n",
    "import os\n",
    "from boto.mturk.connection import MTurkConnection\n",
    "from boto.mturk.question import HTMLQuestion\n",
    "import pandas as pd \n",
    "from boto.mturk.question import ExternalQuestion\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "from importlib import reload\n",
    "from boto.mturk.qualification import (\n",
    "    Qualifications,\n",
    "    PercentAssignmentsApprovedRequirement, \n",
    "    NumberHitsApprovedRequirement\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../evaluation/')\n",
    "\n",
    "import mturk as mturk\n",
    "import mturk.utils_mturk as um\n",
    "\n",
    "from importlib import reload\n",
    "reload(um)\n",
    "reload(mturk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ['AWS_ACCESS_KEY_ID'])\n",
    "print(os.environ['AWS_SECRET_ACCESS_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(um)\n",
    "\n",
    "env = 'sandbox'\n",
    "# env = 'production'\n",
    "mturk = um.MTurkHandler(environment=env) #=production/sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_QUALIFICATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_requirements = [\n",
    "    ### number of hits approved\n",
    "    {\n",
    "        'QualificationTypeId': '000000000000000000L0',\n",
    "        'Comparator': 'GreaterThanOrEqualTo',\n",
    "        'IntegerValues': [80],\n",
    "    },\n",
    "    ## worker local\n",
    "    {\n",
    "        'QualificationTypeId': '00000000000000000071',\n",
    "        'Comparator': 'EqualTo',\n",
    "        'LocaleValues': [{\n",
    "            \"Country\":\"US\",\n",
    "        }],\n",
    "        'RequiredToPreview': True,\n",
    "    },\n",
    "    ## percent assignments approved\n",
    "    {\n",
    "        'QualificationTypeId': '000000000000000000L0',\n",
    "        'Comparator': 'GreaterThanOrEqualTo',\n",
    "        'IntegerValues': [90],\n",
    "    },\n",
    "]\n",
    "\n",
    "worker_requirements = []\n",
    "\n",
    "## custom qualification\n",
    "if CUSTOM_QUALIFICATION:\n",
    "    if env == 'production':\n",
    "        worker_requirements.append({\n",
    "            'QualificationTypeId': '3WZ6PU0JYXSTA4EIPF2M6S1CMZ7KL8',\n",
    "            'Comparator': 'GreaterThanOrEqualTo',\n",
    "            'IntegerValues': [90],      \n",
    "        })\n",
    "    else:\n",
    "        worker_requirements.append({\n",
    "            'QualificationTypeId': '381R35RGJFFV6VLBBDX2MLZFNSH414',  ## UCLA students\n",
    "            #'3FQWXCP5BDC6A66PD20NE8FM4G3H44' other workers\n",
    "            'Comparator': 'GreaterThanOrEqualTo',\n",
    "            'IntegerValues': [90],      \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template, Environment, FileSystemLoader\n",
    "import datetime\n",
    "from IPython.display import display, HTML\n",
    "env = Environment(loader=FileSystemLoader('../evaluation/templates'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = env.get_template('match-sentences-from-scratch.html')\n",
    "created_hits = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in enumerate(desired_index.index):\n",
    "    sample_key = str(tuple(['nyt'] + list(idx)))\n",
    "\n",
    "    ## make the HTML \n",
    "    data = output[sample_key]\n",
    "    html = template.render(\n",
    "        data=data,\n",
    "        doc_id=sample_key,\n",
    "        do_mturk=True,\n",
    "        start_time=datetime.datetime.now()\n",
    "    )\n",
    "\n",
    "    ## dump to disk for inspection\n",
    "    with open('../evaluation/mturk/templated-question-example-%s.html' % i, 'w') as f:\n",
    "        f.write(html)\n",
    "\n",
    "        \n",
    "    if False:\n",
    "        ## HTMLQuestion HIT\n",
    "        description = '''\n",
    "            We\\'d like to match sentences from two edited versions of the same article. \n",
    "            Help us by drawing lines to connect blocks of text.\n",
    "        '''\n",
    "        title = 'Annotate some news article edits v3'\n",
    "        new_hit = mturk.client.create_hit(\n",
    "            Title = title,\n",
    "            Description = description,\n",
    "            Keywords = 'text, highlighting',\n",
    "            Reward = '0.6',\n",
    "            MaxAssignments = 1,\n",
    "            LifetimeInSeconds = 17280000,\n",
    "            AssignmentDurationInSeconds = 600000,\n",
    "            AutoApprovalDelayInSeconds = 28800,\n",
    "            Question = html,\n",
    "            QualificationRequirements=worker_requirements #if env == 'production' else []\n",
    "        )\n",
    "        created_hits.append(new_hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data from MTurk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_ids = list(map(lambda x: x['HIT']['HITId'], created_hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9b4a8ab36a436d96e69cf07116ce00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-74f4ac05a14f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmturk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_answer_df_for_hit_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/usc-research/edit-pathways/evaluation/mturk/utils_mturk.py\u001b[0m in \u001b[0;36mget_answer_df_for_hit_list\u001b[0;34m(self, hit_list)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0manswer_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxmltodict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QuestionFormAnswers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FreeText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0manswer_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0manswer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'worker_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massignment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WorkerId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0manswer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'assignment_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massignment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AssignmentId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    433\u001b[0m             )\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         ]\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "mturk.get_answer_df_for_hit_list(hit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
