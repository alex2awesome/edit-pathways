{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from util import util_data_access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/edit-pathways/dbs/newssniffer-washpo.db.gz to ./newssniffer-washpo.db.gz\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp s3://aspangher/edit-pathways/dbs/newssniffer-washpo.db.gz . --endpoint http://s3.dev.obdc.bcs.bloomberg.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "! gunzip newssniffer-washpo.db.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util_data_access.download_file('glove-100d-loc.tar.gz', 'spark-nlp/glove-100d-loc.tar.gz')\n",
    "# ! tar -xzvf glove-100d-loc.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/en_core_web_lg-2.3.1/ner/moves to en_core_web_lg/ner/moves\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/accuracy.json to en_core_web_lg/accuracy.json\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/ner/cfg to en_core_web_lg/ner/cfg       \n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/meta.json to en_core_web_lg/meta.json   \n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/parser/moves to en_core_web_lg/parser/moves\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/parser/cfg to en_core_web_lg/parser/cfg\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/tagger/cfg to en_core_web_lg/tagger/cfg\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/tokenizer to en_core_web_lg/tokenizer\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/tagger/tag_map to en_core_web_lg/tagger/tag_map\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/vocab/lookups_extra.bin to en_core_web_lg/vocab/lookups_extra.bin\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/ner/model to en_core_web_lg/ner/model\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/vocab/lookups.bin to en_core_web_lg/vocab/lookups.bin\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/parser/model to en_core_web_lg/parser/model\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/tagger/model to en_core_web_lg/tagger/model\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/vocab/key2row to en_core_web_lg/vocab/key2row\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/vocab/strings.json to en_core_web_lg/vocab/strings.json\n",
      "download: s3://aspangher/en_core_web_lg-2.3.1/vocab/vectors to en_core_web_lg/vocab/vectors\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp --recursive s3://aspangher/en_core_web_lg-2.3.1 en_core_web_lg --endpoint http://s3.dev.obdc.bcs.bloomberg.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', disable=['tagger', 'ner'])\n",
    "def get_sentences_pipe(par_doc, entry_id, version, p_idx, s_idx_start=0):\n",
    "    output = []\n",
    "    sents = list(map(lambda s: s.text, par_doc.sents))\n",
    "    sents = list(map(lambda s: ' '.join(s.split()), sents))\n",
    "    for s_idx, s in enumerate(sents):\n",
    "        output.append({\n",
    "            'par_idx': p_idx,\n",
    "            'sentence': s,\n",
    "            'sent_idx': s_idx_start + s_idx,\n",
    "            'entry_id': entry_id,\n",
    "            'version': version\n",
    "        })\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_words_pipe(par_doc, entry_id, version, p_idx, s_idx_start=0):\n",
    "    output = []\n",
    "    sents = list(map(lambda s: list(map(lambda y: y.text, s)), par_doc.sents))\n",
    "    for s_idx, s in enumerate(sents):\n",
    "        output.append({\n",
    "            'par_idx': p_idx,\n",
    "            'sentence': s,\n",
    "            'sent_idx': s_idx_start + s_idx,\n",
    "            'entry_id': entry_id,\n",
    "            'version': version\n",
    "        })\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_sentences_col(df_chunk):\n",
    "    return handle_spacy_chunk(df_chunk, get_sentences_pipe)\n",
    "\n",
    "\n",
    "def get_words_col(df_chunk):\n",
    "    return handle_spacy_chunk(df_chunk, get_words_pipe)\n",
    "\n",
    "\n",
    "def handle_spacy_chunk(df_chunk, processor_function):\n",
    "    docs, entry_ids, versions = df_chunk['summary'].tolist(), df_chunk['entry_id'].tolist(), df_chunk['version'].tolist()\n",
    "    output_sentences = []\n",
    "    all_pars = []\n",
    "    all_par_ids = []\n",
    "    all_entry_ids = []\n",
    "    all_versions = []\n",
    "    # prepare\n",
    "    for entry_id, version, doc in zip(entry_ids, versions, docs):\n",
    "        pars = re.split('</p>\\s*<p>', doc)\n",
    "        p_idxes = list(range(len(pars)))\n",
    "        all_pars.extend(pars)\n",
    "        all_par_ids.extend(p_idxes)\n",
    "        all_entry_ids.extend([entry_id] * len(pars))\n",
    "        all_versions.extend([version] * len(pars))\n",
    "\n",
    "    # index\n",
    "    prev_entry_id = entry_ids[0]\n",
    "    prev_version = versions[0]\n",
    "    curr_sentences = []\n",
    "    for i, par_doc in enumerate(nlp.pipe(all_pars, batch_size=20)):\n",
    "        curr_par_id = all_par_ids[i]\n",
    "        curr_entry_id = all_entry_ids[i]\n",
    "        curr_version = all_versions[i]\n",
    "        if (curr_entry_id == prev_entry_id) and (curr_version == prev_version):\n",
    "            starting_sent_idx = len(curr_sentences)\n",
    "        else:\n",
    "            starting_sent_idx = 0\n",
    "            output_sentences.extend(curr_sentences)\n",
    "            curr_sentences = []\n",
    "        curr_sentences.extend(\n",
    "            processor_function(par_doc, curr_entry_id, curr_version, curr_par_id, s_idx_start=starting_sent_idx)\n",
    "        )\n",
    "        prev_entry_id = curr_entry_id\n",
    "        prev_version = curr_version\n",
    "\n",
    "    output_sentences.extend(curr_sentences)\n",
    "    return output_sentences\n",
    "\n",
    "\n",
    "def get_words(x, version=None, entry_id=None):\n",
    "    output_sentences = []\n",
    "    pars = re.split('</p>\\s*<p>', x)\n",
    "    s_idx = 0\n",
    "    for p_idx, p in enumerate(pars):\n",
    "        sents = list(map(lambda s: list(map(lambda y: y.text, s)), nlp(p).sents))\n",
    "        for s in sents:\n",
    "            output_sentences.append({\n",
    "                'par_idx': p_idx,\n",
    "                'sentence': s,\n",
    "                'sent_idx': s_idx,\n",
    "                'entry_id': entry_id,\n",
    "                'version': version\n",
    "            })\n",
    "            s_idx += 1    \n",
    "    return output_sentences\n",
    "\n",
    "\n",
    "def get_sentences(x, version=None, entry_id=None):\n",
    "    output_sentences = []\n",
    "    pars = re.split('</p>\\s*<p>', x)\n",
    "    s_idx = 0\n",
    "    for p_idx, p in enumerate(pars):\n",
    "        sents = list(map(lambda s: s.text, nlp(p).sents))\n",
    "        sents = list(map(lambda s: ' '.join(s.split()), sents))\n",
    "        for s in sents:\n",
    "            output_sentences.append({\n",
    "                'par_idx': p_idx,\n",
    "                'sentence': s,\n",
    "                'sent_idx': s_idx,\n",
    "                'entry_id': entry_id,\n",
    "                'version': version\n",
    "            })\n",
    "            s_idx += 1    \n",
    "    return output_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# spark = sparknlp.start()\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "      .config(\"spark.executor.instances\", \"5\")\n",
    "      .config(\"spark.driver.memory\", \"20g\")\n",
    "      .config(\"spark.executor.memory\", \"20g\")\n",
    "      .config(\"spark.sql.shuffle.partitions\", \"2000\")\n",
    "      .config(\"spark.executor.cores\", \"5\")\n",
    "      .config('spark.driver.maxResultSize', '3g')\n",
    "      .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\n",
    "      .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3\")\n",
    "      .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "                <div>\n",
       "                    <p><b>SparkContext</b></p>\n",
       "                    <p><a href=\"/sprk/4040/jobs/\">Spark UI</a></p>\n",
       "                    <dl>\n",
       "                      <dt>Version</dt>\n",
       "                        <dd><code>v3.0.2-ds-0.6</code></dd>\n",
       "                      <dt>AppName</dt>\n",
       "                        <dd><code>pyspark-shell</code></dd>\n",
       "                    </dl>\n",
       "                    <br>\n",
       "                    <b>Executor Status</b>\n",
       "                    <dl>\n",
       "                      <dt>Running</dt>\n",
       "                        <dd><code>5</code></dd>\n",
       "                      <dt>Pending</dt>\n",
       "                        <dd><code>0</code></dd>\n",
       "                      <dt>Failed</dt>\n",
       "                        <dd><code>0</code></dd>\n",
       "                    </dl>\n",
       "                </div>\n",
       "                \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9732368850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Our Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pyspark.sql.functions as F\n",
    "import sqlite3\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    already_parsed = pd.read_csv('nyt-output-sentence-matching-1.csv', index_col=0)\n",
    "\n",
    "    with sqlite3.connect('newssniffer-washpo.db') as conn:\n",
    "        df = pd.read_sql(\"\"\"\n",
    "                with c1 as (\n",
    "                    SELECT e1.entry_id as entry_id,\n",
    "                        e1.version as version_x,\n",
    "                        e2.version as version_y,\n",
    "                        e1.title as title_x,\n",
    "                        e2.title as title_y\n",
    "                    FROM entryversion e1\n",
    "                    JOIN entryversion e2\n",
    "                        ON e1.entry_id = e2.entry_id\n",
    "                        AND (e1.version + 1) = e2.version\n",
    "                    WHERE e1.title != e2.title\n",
    "                    AND e1.entry_id NOT IN (%s)\n",
    "                    AND e1.num_versions < 40 AND e1.num_versions > 1\n",
    "                )\n",
    "\n",
    "                SELECT * from entryversion\n",
    "                WHERE entry_id IN (select distinct entry_id from c1 limit 1000)\n",
    "                AND version IN (select version_x from c1 union select version_y from c1)\n",
    "            \"\"\" % ', '.join(map(str, already_parsed['entry_id'].drop_duplicates().tolist()))\n",
    "            , con=conn\n",
    "        )\n",
    "        df = (df\n",
    "              .assign(summary=lambda df: df['summary'].apply(unidecode.unidecode))\n",
    "              # .assign(summary=lambda df: df['summary'].str.replace('</p><p>', ' '))\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    version_df = pd.read_sql('''\n",
    "            with c1 as (\n",
    "                SELECT e1.entry_id as entry_id,\n",
    "                    e1.version as version_x,\n",
    "                    e2.version as version_y\n",
    "                FROM entryversion e1\n",
    "                JOIN entryversion e2\n",
    "                    ON e1.entry_id = e2.entry_id\n",
    "                    AND (e1.version + 1) = e2.version\n",
    "            )\n",
    "            SELECT * from c1\n",
    "         ''', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(distinct entry_id)\n",
      "0                     19184\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect('newssniffer-washpo.db') as conn:\n",
    "    print(pd.read_sql('''SELECT count(distinct entry_id) FROM entryversion''', con=conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('newssniffer-washpo.db') as conn:\n",
    "    df = pd.read_sql('''\n",
    "         SELECT * from entryversion \n",
    "         WHERE entry_id IN (\n",
    "             SELECT distinct entry_id FROM entryversion LIMIT 100)\n",
    "     ''', con=conn)\n",
    "\n",
    "#     df = pd.read_sql('''\n",
    "#          SELECT * from entryversion \n",
    "#          WHERE entry_id IN (1951413, 1952324, 1969148, 1451793, 1938021)\n",
    "#      ''', con=conn)\n",
    "    # , \n",
    "    df = (df\n",
    "          .assign(summary=lambda df: df['summary'].apply(unidecode.unidecode))\n",
    "#           .assign(summary=lambda df: df['summary'].str.replace('</p>\\s*<p>', ' ', regex=True))\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Spacy Parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.5 s, sys: 129 ms, total: 37.6 s\n",
      "Wall time: 37.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "all_sentences = []\n",
    "for e_id, v, s in df[['entry_id', 'version', 'summary']].itertuples(index=False):\n",
    "#     doc_sents = get_sentences(s, v, e_id)\n",
    "    doc_sents = get_words(s, v, e_id)\n",
    "    all_sentences.extend(doc_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 s, sys: 19.3 ms, total: 18.4 s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = get_words_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def chunker(df_iterable, total_length, chunksize):\n",
    "    return (df_iterable.iloc[pos: pos + chunksize] for pos in range(0, total_length, chunksize))\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    \"Flatten a list of lists to a combined list\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_parallel(df, func, chunksize=100):\n",
    "    executor = Parallel(n_jobs=11, backend='multiprocessing', prefer=\"processes\")\n",
    "    do = delayed(func)\n",
    "    tasks = (do(chunk) for chunk in chunker(df, len(df), chunksize=chunksize))\n",
    "    result = executor(tasks)\n",
    "    return flatten(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.07 s, sys: 488 ms, total: 1.56 s\n",
      "Wall time: 7.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t2 = preprocess_parallel(df, get_sentences_col, chunksize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 555 ms, total: 1.82 s\n",
      "Wall time: 7.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_words = preprocess_parallel(df, get_words_col, chunksize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dfp = pd.DataFrame(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_sents = (sent_dfp\n",
    " .groupby(['entry_id', 'version'])\n",
    " .apply(lambda df: '<SENT>'.join(df.sort_values('sent_idx')['sentence'].tolist()))\n",
    " .to_frame('summary').reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.drop(['summary'], axis=1)\n",
    " .merge(joined_sents, how='left', right_on=['entry_id', 'version'], left_on=['entry_id', 'version'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    df['summary'] = df['summary'].str.replace('</p>\\s*<p>', '<SENT>', regex=True).str.replace('<p>', '').str.replace('</p>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdf = spark.createDataFrame(df)\n",
    "sdf = spark.createDataFrame(sent_dfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer, SQLTransformer\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from scipy.spatial import distance\n",
    "from pyspark.sql.types import FloatType\n",
    "from scipy.spatial import distance\n",
    "import sparknlp.base as sb\n",
    "import sparknlp.annotator as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_THRESHOLD = .44\n",
    "\n",
    "def get_word_matching_sql(side):\n",
    "    \"\"\"Generate the SQL necessary to transform each side. Side \\in {'x', 'y'}\"\"\"\n",
    "    \n",
    "    word_pair_min_distance_sql = \"\"\"\n",
    "         SELECT entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_x,\n",
    "                sent_idx_y,\n",
    "                word_idx_%(side)s,\n",
    "                MIN(num_words) as num_words_total_list,\n",
    "                MIN(distance) as min_word_distance\n",
    "        FROM __THIS__ \n",
    "        GROUP BY entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_x,\n",
    "                sent_idx_y,\n",
    "                word_idx_%(side)s\n",
    "      \"\"\" % ({'side': side})\n",
    "    \n",
    "    sentence_pair_min_distance_sql = \"\"\"\n",
    "        SELECT entry_id,\n",
    "               version_x,\n",
    "               version_y,\n",
    "               sent_idx_x,\n",
    "               sent_idx_y,\n",
    "               (sum_min_word_distance + .5 * ( num_words_total - num_matched_words )) / num_words_total AS avg_sentence_distance\n",
    "        FROM (\n",
    "           SELECT entry_id,\n",
    "                  version_x,\n",
    "                  version_y,\n",
    "                  sent_idx_x,\n",
    "                  sent_idx_y,\n",
    "                  SUM(min_word_distance) AS sum_min_word_distance,\n",
    "                  COUNT(1) AS num_matched_words,\n",
    "                  MIN(num_words_total_list) AS num_words_total\n",
    "           FROM __THIS__\n",
    "                GROUP BY entry_id,\n",
    "                   version_x,\n",
    "                   version_y,\n",
    "                   sent_idx_x,\n",
    "                   sent_idx_y\n",
    "          )\n",
    "      \"\"\"\n",
    "    \n",
    "    sentence_min_sql = \"\"\"\n",
    "         SELECT entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_x,\n",
    "                sent_idx_y,\n",
    "                avg_sentence_distance\n",
    "           FROM (\n",
    "                    SELECT *, ROW_NUMBER() OVER (\n",
    "                         PARTITION BY entry_id, \n",
    "                                      version_x, \n",
    "                                      version_y, \n",
    "                                      sent_idx_%(side)s\n",
    "                         ORDER BY avg_sentence_distance ASC\n",
    "                ) AS rn FROM __THIS__\n",
    "        )\n",
    "         where rn = 1\n",
    "    \"\"\" % ({'side': side})\n",
    "    \n",
    "    threshold_sql = \"\"\"\n",
    "         SELECT entry_id,\n",
    "                version_x,\n",
    "                version_y,\n",
    "                sent_idx_%(join_side)s,\n",
    "                CASE \n",
    "                    WHEN (avg_sentence_distance < %(distance)s ) THEN sent_idx_%(other_side)s\n",
    "                    ELSE NULL\n",
    "                END AS sent_idx_%(other_side)s,\n",
    "                CASE \n",
    "                    WHEN (avg_sentence_distance < %(distance)s ) THEN avg_sentence_distance\n",
    "                    ELSE NULL\n",
    "                END AS avg_sentence_distance\n",
    "            FROM __THIS__\n",
    "    \"\"\" %({'join_side': side, 'other_side': list({'x', 'y'} - set(side))[0], 'distance': DISTANCE_THRESHOLD})\n",
    "    \n",
    "    return word_pair_min_distance_sql, sentence_pair_min_distance_sql, sentence_min_sql, threshold_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa.RoBertaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "documenter = (\n",
    "    sb.DocumentAssembler()\n",
    "        .setInputCol(\"summary\")\n",
    "        .setOutputCol(\"document\")\n",
    ")\n",
    "\n",
    "sentencer = (\n",
    "    sa.SentenceDetector()\n",
    "        .setInputCols([\"document\"])\n",
    "        .setOutputCol(\"sentences\")\n",
    "        .setCustomBounds(['<SENT>'])\n",
    "        .setUseCustomBoundsOnly(True)\n",
    ")\n",
    "\n",
    "tokenizer = (\n",
    "    sa.Tokenizer()\n",
    "        .setInputCols([\"sentences\"])\n",
    "        .setOutputCol(\"token\")\n",
    ")\n",
    "\n",
    "if False:\n",
    "    word_embeddings = (\n",
    "        sa.BertEmbeddings\n",
    "            .load('s3://aspangher/spark-nlp/small_bert_L4_128_en_2.6.0_2.4')\n",
    "            .setInputCols([\"sentences\", \"token\"])\n",
    "            .setOutputCol(\"embeddings\")\n",
    "            .setMaxSentenceLength(512)\n",
    "            .setBatchSize(100)\n",
    "    )\n",
    "\n",
    "    # word_embeddings = (\n",
    "    #     sa.RoBertaEmbeddings\n",
    "    #         .load('s3://aspangher/spark-nlp/distilroberta_base_en_3.1.0_2.4')\n",
    "    #         .setInputCols([\"sentences\", \"token\"])\n",
    "    #         .setOutputCol(\"embeddings\")\n",
    "    #         .setMaxSentenceLength(512)\n",
    "    #         .setBatchSize(100)\n",
    "    # )\n",
    "\n",
    "\n",
    "    tok_finisher = (\n",
    "        sb.Finisher()\n",
    "        .setInputCols([\"token\"])\n",
    "        .setIncludeMetadata(True)\n",
    "    )\n",
    "\n",
    "    embeddings_finisher = (\n",
    "        sb.EmbeddingsFinisher()\n",
    "                .setInputCols(\"embeddings\")\n",
    "                .setOutputCols(\"embeddings_vectors\")\n",
    "                .setOutputAsVector(True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparknlp_processing_pipeline = sb.RecursivePipeline(stages=[\n",
    "    documenter,\n",
    "    sentencer,\n",
    "    tokenizer,\n",
    "#     word_embeddings,\n",
    "#     embeddings_finisher,\n",
    "#     tok_finisher\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparknlp_processing_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf.repartition('entry_id', 'version').cache()\n",
    "spark_processed_df = sparknlp_processing_pipeline.fit(sdf).transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_dfp = spark_processed_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCase(str):\n",
    "    resStr=\"\"\n",
    "    arr = str.split(\" \")\n",
    "    for x in arr:\n",
    "        resStr= resStr + x[0:1].upper() + x[1:len(x)] + \" \"\n",
    "    return resStr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertUDF = udf(lambda z: convertCase(z),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spark_processed_df.select(col(\"title\"), convertUDF(col(\"summary\")).alias(\"summary\") ) \n",
    "   .show(truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCS UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import IntegerType, StringType, ArrayType, StructType, StructField, DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join_cols=['entry_id', 'version_x', 'version_y']\n",
    "joined_sdf = (\n",
    " sdf\n",
    "    .withColumnRenamed('version', 'version_x')\n",
    "    .withColumnRenamed('sentence', 'sentence_x')\n",
    "    .withColumnRenamed('par_idx', 'par_idx_x')\n",
    "    .withColumnRenamed('sent_idx', 'sent_idx_x')\n",
    "    .alias('sdf_x')\n",
    "    .join(\n",
    "        sdf\n",
    "            .withColumnRenamed('entry_id', 'entry_id_t')\n",
    "            .withColumnRenamed('par_idx', 'par_idx_y')\n",
    "            .withColumnRenamed('sent_idx', 'sent_idx_y')\n",
    "            .withColumnRenamed('version', 'version_y')\n",
    "            .withColumnRenamed('sentence', 'sentence_y')\n",
    "            .alias('sdf_y')\n",
    "        ,\n",
    "        [col(\"sdf_x.entry_id\") == col(\"sdf_y.entry_id_t\"), col(\"sdf_x.version_x\") == col(\"sdf_y.version_y\") - 1, ],\n",
    "        how='inner'\n",
    ")\n",
    "    .select('entry_id', 'version_x', 'version_y', 'par_idx_x', 'par_idx_y', 'sent_idx_x', 'sent_idx_y', 'sentence_x', 'sentence_y')\n",
    "    #.dropDuplicates(join_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+---------+---------+----------+----------+--------------------+--------------------+\n",
      "|entry_id|version_x|version_y|par_idx_x|par_idx_y|sent_idx_x|sent_idx_y|          sentence_x|          sentence_y|\n",
      "+--------+---------+---------+---------+---------+----------+----------+--------------------+--------------------+\n",
      "|  728225|        1|        2|       35|        0|       103|         0|[\", That, 's, abo...|[SALT, LAKE, CITY...|\n",
      "|  728225|        1|        2|       35|        0|       103|         1|[\", That, 's, abo...|[A, few, hours, e...|\n",
      "|  728225|        1|        2|       35|        0|       103|         2|[\", That, 's, abo...|[But, now, ,, in,...|\n",
      "|  728225|        1|        2|       35|        0|       103|         3|[\", That, 's, abo...|[The, would, -, b...|\n",
      "|  728225|        1|        2|       35|        1|       103|         4|[\", That, 's, abo...|        [Silence, .]|\n",
      "|  728225|        1|        2|       35|        2|       103|         5|[\", That, 's, abo...|[His, wife, ,, An...|\n",
      "|  728225|        1|        2|       35|        2|       103|         6|[\", That, 's, abo...|                 [\"]|\n",
      "|  728225|        1|        2|       35|        2|       103|         7|[\", That, 's, abo...|[What, 's, going,...|\n",
      "|  728225|        1|        2|       35|        3|       103|         8|[\", That, 's, abo...|[\", We, 're, writ...|\n",
      "|  728225|        1|        2|       35|        4|       103|         9|[\", That, 's, abo...|[\", It, 's, finis...|\n",
      "|  728225|        1|        2|       35|        5|       103|        10|[\", That, 's, abo...|[\", My, time, on,...|\n",
      "|  728225|        1|        2|       35|        6|       103|        11|[\", That, 's, abo...|[Ann, stares, ahe...|\n",
      "|  728225|        1|        2|       35|        6|       103|        12|[\", That, 's, abo...|[Their, sons, are...|\n",
      "|  728225|        1|        2|       35|        6|       103|        13|[\", That, 's, abo...|[The, grandkids, ...|\n",
      "|  728225|        1|        2|       35|        6|       103|        14|[\", That, 's, abo...|[The, nation, ,, ...|\n",
      "|  728225|        1|        2|       35|        7|       103|        15|[\", That, 's, abo...|[The, dramatic, c...|\n",
      "|  728225|        1|        2|       35|        8|       103|        16|[\", That, 's, abo...|[The, film, ,, wh...|\n",
      "|  728225|        1|        2|       35|        8|       103|        17|[\", That, 's, abo...|[It, shows, him, ...|\n",
      "|  728225|        1|        2|       35|        9|       103|        18|[\", That, 's, abo...|[The, documentary...|\n",
      "|  728225|        1|        2|       35|        9|       103|        19|[\", That, 's, abo...|[There, are, glim...|\n",
      "+--------+---------+---------+---------+---------+----------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(X, Y):\n",
    "    # find the length of the strings\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "  \n",
    "    # declaring the array for storing the dp values\n",
    "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
    "  \n",
    "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
    "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
    "    and Y[0..j-1]\"\"\"\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0 :\n",
    "                L[i][j] = 0\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                L[i][j] = L[i-1][j-1] + 1\n",
    "            else:\n",
    "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    "  \n",
    "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
    "    return L[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_common_substrings(seq_1, seq_2, output_format='len', minimum_overlap=3):\n",
    "    \"\"\"\n",
    "    `output_format`:\n",
    "        * = \"indices\": return raw indices\n",
    "        * = \"subseqs\": return substrings from sequences\n",
    "        * = \"len\": sum the length\n",
    "    \"\"\"\n",
    "    n = len(seq_1)\n",
    "    m = len(seq_2)\n",
    "    mat = lcs(seq_1, seq_2, n, m)\n",
    "    mat = mat[1:,1:].copy()\n",
    "    accepted_coords = get_substrings_from_matrix(mat, minimum_overlap=minimum_overlap)\n",
    "    # output format\n",
    "    if output_format == 'indices':\n",
    "        return accepted_coords\n",
    "    elif output_format == 'subseqs':\n",
    "        output_strings = []\n",
    "        for s, e in accepted_coords['x']:\n",
    "            output_strings.append(seq_1[s:e])\n",
    "        return output_strings\n",
    "    elif output_format == 'len':\n",
    "        all_len = 0\n",
    "        for s, e in accepted_coords['x']:\n",
    "            all_len += e - s\n",
    "\n",
    "        return all_len\n",
    "\n",
    "\n",
    "def lcs(seq_1, seq_2, n, m):\n",
    "    counter = np.zeros((n + 1, m + 1))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if seq_1[i] == seq_2[j]:\n",
    "                c = counter[i][j] + 1\n",
    "                counter[i+1][j+1] = c\n",
    "                x_idx_s, x_idx_e = int(i - c + 1), int(i + 1)\n",
    "                y_idx_s, y_idx_e = int(j - c + 1), int(j + 1)\n",
    "    return counter\n",
    "\n",
    "\n",
    "def get_substrings_from_matrix(mat, minimum_overlap):\n",
    "    accepted_coords = {'x': [], 'y': []}\n",
    "    str_len = int(mat.max())\n",
    "\n",
    "    while str_len >= minimum_overlap:\n",
    "        x_cord, y_cord = np.where(mat == mat.max())\n",
    "        for x_cord_i, y_cord_i in zip(x_cord, y_cord):\n",
    "            x_idx_s, x_idx_e = int(x_cord_i - str_len + 1), int(x_cord_i + 1)\n",
    "            y_idx_s, y_idx_e = int(y_cord_i - str_len + 1), int(y_cord_i + 1)\n",
    "\n",
    "            # see if there are any zeros in the diagonal - this means that the \n",
    "            # substring shares elements with a longer string that was already matched\n",
    "            diag = mat[range(x_idx_s, x_idx_e), range(y_idx_s, y_idx_e)]\n",
    "            num_zeros = str_len - np.count_nonzero(diag)\n",
    "            # if so, correct\n",
    "            if num_zeros > 0: # \n",
    "                mat[range(x_idx_s, x_idx_e), range(y_idx_s, y_idx_e)] = np.maximum(diag - num_zeros, 0)\n",
    "            else:\n",
    "                accepted_coords['x'].append((x_idx_s, x_idx_e))\n",
    "                accepted_coords['y'].append((y_idx_s, y_idx_e))\n",
    "                mat[x_idx_s:x_idx_e, :] = 0\n",
    "                mat[:, y_idx_s: y_idx_e] = 0\n",
    "\n",
    "        # continue \n",
    "        str_len = int(mat.max())\n",
    "    # return \n",
    "    return accepted_coords\n",
    "\n",
    "\n",
    "\n",
    "def lcs_old(seq_1, seq_2, minimum_overlap=3):\n",
    "    n = len(seq_1)\n",
    "    m = len(seq_2)\n",
    "#     counter = [[0] * (n + 1) for x in range(m + 1)]\n",
    "    counter = np.zeros((n + 1, m + 1))\n",
    "    longest = minimum_overlap\n",
    "    lcs_list = []\n",
    "    lcs_idx_x = defaultdict(list)\n",
    "    lcs_idx_y = defaultdict(list)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if seq_1[i] == seq_2[j]:\n",
    "                c = counter[i][j] + 1\n",
    "                counter[i+1][j+1] = c\n",
    "                x_idx_s, x_idx_e = int(i - c + 1), int(i + 1)\n",
    "                y_idx_s, y_idx_e = int(j - c + 1), int(j + 1)\n",
    "                if c > minimum_overlap:\n",
    "                    lcs_idx_x[c].append([x_idx_s, x_idx_e])\n",
    "                    lcs_idx_y[c].append([y_idx_s, y_idx_e])\n",
    "                if c > longest:\n",
    "                    lcs_list = []\n",
    "                    longest = c\n",
    "                if c >= longest:\n",
    "                    lcs_list.append(seq_1[x_idx_s: x_idx_e])\n",
    "                \n",
    "    return counter.astype(int).tolist() # , lcs_list, lcs_idx_x, lcs_idx_y\n",
    "\n",
    "\n",
    "def deduplicate(lcs_idx, seq):\n",
    "    rev_keys = sorted(lcs_idx, reverse=True)\n",
    "    accepted_output = []\n",
    "    for overlap_length in rev_keys:\n",
    "        for c_s, c_e in lcs_idx[overlap_length]:\n",
    "            overlaps = False\n",
    "            for a_s, a_e in accepted_output:\n",
    "                if (c_s < a_e and c_e > a_s) or (c_s < a_e and c_e > a_s):\n",
    "                    overlaps = True\n",
    "                    break\n",
    "\n",
    "            if not overlaps:\n",
    "                accepted_output.append((c_s, c_e))\n",
    "    return list(zip(list(map(lambda x: seq[x[0]: x[1]], accepted_output)), accepted_output))\n",
    "\n",
    "\n",
    "\n",
    "def all_lcs_in_source(source_seq, target_seq, return_type='seq_len', deduplicate_target=True, minimum_overlap=3):\n",
    "    \"\"\"Return either:\n",
    "        return_type = `output_sequences`: all the subsequences in the source that match subsequences in the target\n",
    "                    = `seq_len`: the length of all matched words in subsequences\n",
    "        Only subsequences with length greater than `minimum_overlap` are considered.\n",
    "    \"\"\"\n",
    "    lcs_list, lcs_idx_source, lcs_idx_target = lcs(source_seq, target_seq, minimum_overlap=minimum_overlap)    \n",
    "\n",
    "    ## deduplicate source\n",
    "    accepted_source = deduplicate(lcs_idx_source, source_seq)\n",
    "    if deduplicate_target:\n",
    "        accepted_target = deduplicate(lcs_idx_target, target_seq)\n",
    "        return accepted_source, accepted_target\n",
    "        accepted_output = min(lcs_idx_source, lcs_idx_target, key=len) # if there are overlaps, then one will be shorter\n",
    "        \n",
    "    \n",
    "    if return_type=='output_sequences': \n",
    "        accepted_output = sorted(accepted_output, key=lambda x: x[0])\n",
    "        return list(map(lambda x: source_seq[x[0]:x[1]], accepted_output))\n",
    "    if return_type=='seq_len':\n",
    "        return sum(map(lambda x: x[1]-x[0], accepted_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lcsUDF = udf(lcs, ArrayType(ArrayType(StringType())))\n",
    "\n",
    "# lcsUDF = udf(lcs, StructType([\n",
    "#                         StructField(\"lcs_list\", ArrayType(ArrayType(StringType()))),\n",
    "#                         StructField(\"lcs_idx_x\", ArrayType(ArrayType(IntegerType()))),\n",
    "#                         StructField(\"lcs_idx_y\", ArrayType(ArrayType(IntegerType()))),\n",
    "#                     ])\n",
    "#             )\n",
    "\n",
    "lcsUDF = udf(lcs_old, ArrayType(ArrayType(IntegerType())))\n",
    "\n",
    "get_common_substrings_udf = udf(get_all_common_substrings, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_dfp = (joined_sdf\n",
    ".select(\n",
    "    'entry_id', \n",
    "    'version_x', \n",
    "    'version_y', \n",
    "    'par_idx_x', \n",
    "    'par_idx_y', \n",
    "    'sent_idx_x', \n",
    "    'sent_idx_y', \n",
    "    'sentence_x',\n",
    "    'sentence_y',\n",
    "    F.size('sentence_x').alias('sent_x_len'),\n",
    "    F.size('sentence_y').alias('sent_y_len'),\n",
    "    get_common_substrings_udf(col(\"sentence_x\"), col(\"sentence_y\")).alias(\"len_common_substr\") \n",
    ")\n",
    ".select(\n",
    "    'entry_id', \n",
    "    'version_x', \n",
    "    'version_y', \n",
    "    'par_idx_x', \n",
    "    'par_idx_y', \n",
    "    'sent_idx_x', \n",
    "    'sent_idx_y', \n",
    "    'sentence_x',\n",
    "    'sentence_y',\n",
    "    (F.col('len_common_substr') / F.col('sent_x_len')).alias('avg_similarity_x'),\n",
    "    (F.col('len_common_substr') / F.col('sent_y_len')).alias('avg_similarity_y'),\n",
    ")\n",
    " .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0.0\n",
       "1          0.0\n",
       "2          0.0\n",
       "3          0.0\n",
       "4          0.0\n",
       "          ... \n",
       "1049883    0.0\n",
       "1049884    0.0\n",
       "1049885    0.0\n",
       "1049886    0.0\n",
       "1049887    0.0\n",
       "Name: avg_similarity_x, Length: 1049888, dtype: float64"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_dfp['avg_similarity_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.2)    1030670\n",
       "[0.2, 0.4)       3543\n",
       "[0.4, 0.6)        608\n",
       "[0.6, 0.8)        232\n",
       "[0.8, 1.0)        886\n",
       "[1.0, 1.2)      13949\n",
       "Name: avg_similarity_x, dtype: int64"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_dfp['avg_similarity_x'].pipe(lambda s: pd.cut(s, bins=np.arange(0, 1.4, .2), right=False)).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.2)    1030673\n",
       "[0.2, 0.4)       3561\n",
       "[0.4, 0.6)        595\n",
       "[0.6, 0.8)        240\n",
       "[0.8, 1.0)        848\n",
       "[1.0, 1.2)      13971\n",
       "Name: avg_similarity_y, dtype: int64"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_dfp['avg_similarity_y'].pipe(lambda s: pd.cut(s, bins=np.arange(0, 1.4, .2), right=False)).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = j_dfp.loc[lambda df: (df['avg_similarity_x'] > .6) & (df['avg_similarity_x'] < .8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = (t\n",
    " .assign(sentence_x=lambda df: df['sentence_x'].str.join(' '))\n",
    " .assign(sentence_y=lambda df: df['sentence_y'].str.join(' '))\n",
    ")#[['sentence_x', 'sentence_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>par_idx_x</th>\n",
       "      <th>par_idx_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>sentence_x</th>\n",
       "      <th>sentence_y</th>\n",
       "      <th>avg_similarity_x</th>\n",
       "      <th>avg_similarity_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>731518</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>according to the inspector general 's report .</td>\n",
       "      <td>Although the woman said their sex was consensu...</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8224</th>\n",
       "      <td>731518</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "      <td>96</td>\n",
       "      <td>according to the inspector general 's report .</td>\n",
       "      <td>She said she was first told about them two wee...</td>\n",
       "      <td>0.62500</td>\n",
       "      <td>0.128205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8238</th>\n",
       "      <td>731518</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>110</td>\n",
       "      <td>according to the inspector general 's report .</td>\n",
       "      <td>\" It 's very unbecoming , \" said an Air Force ...</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9655</th>\n",
       "      <td>731518</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>Lewd e - mails</td>\n",
       "      <td>Martin P. Schweitzer , a commander with the Ar...</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>731518</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>76</td>\n",
       "      <td>94</td>\n",
       "      <td>Lewd e - mails</td>\n",
       "      <td>The Post obtained an original , uncensored cop...</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015583</th>\n",
       "      <td>731518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>76</td>\n",
       "      <td>93</td>\n",
       "      <td>Lewd e - mails</td>\n",
       "      <td>The Post obtained an original , uncensored cop...</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015584</th>\n",
       "      <td>731518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>76</td>\n",
       "      <td>94</td>\n",
       "      <td>Lewd e - mails</td>\n",
       "      <td>In a statement released Friday , Ellmers calle...</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015588</th>\n",
       "      <td>731518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>76</td>\n",
       "      <td>98</td>\n",
       "      <td>Lewd e - mails</td>\n",
       "      <td>Last summer , according to the report , he tol...</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047550</th>\n",
       "      <td>732163</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>113</td>\n",
       "      <td>123</td>\n",
       "      <td>In 1949 , Mr. Seeger had bought 171/</td>\n",
       "      <td>In 1949 , Mr. Seeger bought 171/</td>\n",
       "      <td>0.62500</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049038</th>\n",
       "      <td>731831</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>He said the Syrian government 's tactic echoes...</td>\n",
       "      <td>The tactic echoes the \" kneel or starve \" camp...</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.729730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         entry_id  version_x  version_y  par_idx_x  par_idx_y  sent_idx_x  \\\n",
       "8186       731518          1          2         28         27          64   \n",
       "8224       731518          1          2         28         49          64   \n",
       "8238       731518          1          2         28         58          64   \n",
       "9655       731518          1          2         36          1          76   \n",
       "9746       731518          1          2         36         48          76   \n",
       "...           ...        ...        ...        ...        ...         ...   \n",
       "1015583    731518          0          1         36         47          76   \n",
       "1015584    731518          0          1         36         48          76   \n",
       "1015588    731518          0          1         36         51          76   \n",
       "1047550    732163          2          3         41         48         113   \n",
       "1049038    731831          1          2          5         14           9   \n",
       "\n",
       "         sent_idx_y                                         sentence_x  \\\n",
       "8186             58     according to the inspector general 's report .   \n",
       "8224             96     according to the inspector general 's report .   \n",
       "8238            110     according to the inspector general 's report .   \n",
       "9655              3                                     Lewd e - mails   \n",
       "9746             94                                     Lewd e - mails   \n",
       "...             ...                                                ...   \n",
       "1015583          93                                     Lewd e - mails   \n",
       "1015584          94                                     Lewd e - mails   \n",
       "1015588          98                                     Lewd e - mails   \n",
       "1047550         123               In 1949 , Mr. Seeger had bought 171/   \n",
       "1049038          20  He said the Syrian government 's tactic echoes...   \n",
       "\n",
       "                                                sentence_y  avg_similarity_x  \\\n",
       "8186     Although the woman said their sex was consensu...           0.75000   \n",
       "8224     She said she was first told about them two wee...           0.62500   \n",
       "8238     \" It 's very unbecoming , \" said an Air Force ...           0.75000   \n",
       "9655     Martin P. Schweitzer , a commander with the Ar...           0.75000   \n",
       "9746     The Post obtained an original , uncensored cop...           0.75000   \n",
       "...                                                    ...               ...   \n",
       "1015583  The Post obtained an original , uncensored cop...           0.75000   \n",
       "1015584  In a statement released Friday , Ellmers calle...           0.75000   \n",
       "1015588  Last summer , according to the report , he tol...           0.75000   \n",
       "1047550                   In 1949 , Mr. Seeger bought 171/           0.62500   \n",
       "1049038  The tactic echoes the \" kneel or starve \" camp...           0.72973   \n",
       "\n",
       "         avg_similarity_y  \n",
       "8186             0.166667  \n",
       "8224             0.128205  \n",
       "8238             0.200000  \n",
       "9655             0.037500  \n",
       "9746             0.176471  \n",
       "...                   ...  \n",
       "1015583          0.176471  \n",
       "1015584          0.176471  \n",
       "1015588          0.111111  \n",
       "1047550          0.714286  \n",
       "1049038          0.729730  \n",
       "\n",
       "[232 rows x 11 columns]"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import util.util_newssniffer_parsing as unp\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_x, s_y = t.iloc[10][['sentence_x', 'sentence_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_sent, new_sent = unp.get_word_diffs(' '.join(s_x), ' '.join(s_y))\n",
    "html_old, html_new = unp.html_compare_sentences(old_sent, new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <span style=\"background-color:rgba(255,0,0,0.3)\">President</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Obama</span> <span style=\"background-color:rgba(255,0,0,0.3)\">'s</span> <span style=\"background-color:rgba(255,0,0,0.3)\">national</span> <span style=\"background-color:rgba(255,0,0,0.3)\">security</span> <span style=\"background-color:rgba(255,0,0,0.3)\">adviser</span> <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Susan</span> <span style=\"background-color:rgba(255,0,0,0.3)\">E.</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Rice</span> <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> <span style=\"background-color:rgba(255,0,0,0.3)\">delivered</span> <span style=\"background-color:rgba(255,0,0,0.3)\">that</span> <span style=\"background-color:rgba(255,0,0,0.3)\">message</span> during a visit to Kabul last month , warning that Washington could be forced to plan for a hasty troop withdrawal if Karzai did n't relent ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_old) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(0,255,0,0.3)\">   </span>               during a visit to Kabul last month , warning that Washington could be forced to plan for a hasty troop withdrawal if Karzai did n't relent ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_new) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_sdfp = joined_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = j_sdfp.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>par_idx_x</th>\n",
       "      <th>par_idx_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>sentence_x</th>\n",
       "      <th>sentence_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117087</th>\n",
       "      <td>728205</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[MOSCOW, --]</td>\n",
       "      <td>[MOSCOW, --]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117088</th>\n",
       "      <td>728205</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[MOSCOW, --]</td>\n",
       "      <td>[Russians, love, to, think, of, their, neighbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117089</th>\n",
       "      <td>728205</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[MOSCOW, --]</td>\n",
       "      <td>[That, gives, Russia, considerable, sway, in, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117090</th>\n",
       "      <td>728205</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[MOSCOW, --]</td>\n",
       "      <td>[Its, gravitational, pull, succeeded, in, keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117091</th>\n",
       "      <td>728205</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[MOSCOW, --]</td>\n",
       "      <td>[In, December, ,, the, Ukrainian, government, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78999</th>\n",
       "      <td>728244</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>[Lara, El, Gibaly, contributed, to, this, repo...</td>\n",
       "      <td>[The, National, Council, for, Human, Rights, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79000</th>\n",
       "      <td>728244</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>[Lara, El, Gibaly, contributed, to, this, repo...</td>\n",
       "      <td>[\", There, is, no, space, for, people, to, cho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79001</th>\n",
       "      <td>728244</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>[Lara, El, Gibaly, contributed, to, this, repo...</td>\n",
       "      <td>[\", Those, who, go, out, to, vote, will, vote,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79002</th>\n",
       "      <td>728244</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>[Lara, El, Gibaly, contributed, to, this, repo...</td>\n",
       "      <td>[The, atmosphere, right, now, does, not, allow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79003</th>\n",
       "      <td>728244</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>[Lara, El, Gibaly, contributed, to, this, repo...</td>\n",
       "      <td>[Lara, El, Gibaly, contributed, to, this, repo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151570 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        entry_id  version_x  version_y  par_idx_x  par_idx_y  sent_idx_x  \\\n",
       "117087    728205          0          1          0          0           0   \n",
       "117088    728205          0          1          0          0           0   \n",
       "117089    728205          0          1          0          1           0   \n",
       "117090    728205          0          1          0          1           0   \n",
       "117091    728205          0          1          0          2           0   \n",
       "...          ...        ...        ...        ...        ...         ...   \n",
       "78999     728244          2          3         19         18          33   \n",
       "79000     728244          2          3         19         19          33   \n",
       "79001     728244          2          3         19         19          33   \n",
       "79002     728244          2          3         19         19          33   \n",
       "79003     728244          2          3         19         20          33   \n",
       "\n",
       "        sent_idx_y                                         sentence_x  \\\n",
       "117087           0                                       [MOSCOW, --]   \n",
       "117088           1                                       [MOSCOW, --]   \n",
       "117089           2                                       [MOSCOW, --]   \n",
       "117090           3                                       [MOSCOW, --]   \n",
       "117091           4                                       [MOSCOW, --]   \n",
       "...            ...                                                ...   \n",
       "78999           30  [Lara, El, Gibaly, contributed, to, this, repo...   \n",
       "79000           31  [Lara, El, Gibaly, contributed, to, this, repo...   \n",
       "79001           32  [Lara, El, Gibaly, contributed, to, this, repo...   \n",
       "79002           33  [Lara, El, Gibaly, contributed, to, this, repo...   \n",
       "79003           34  [Lara, El, Gibaly, contributed, to, this, repo...   \n",
       "\n",
       "                                               sentence_y  \n",
       "117087                                       [MOSCOW, --]  \n",
       "117088  [Russians, love, to, think, of, their, neighbo...  \n",
       "117089  [That, gives, Russia, considerable, sway, in, ...  \n",
       "117090  [Its, gravitational, pull, succeeded, in, keep...  \n",
       "117091  [In, December, ,, the, Ukrainian, government, ...  \n",
       "...                                                   ...  \n",
       "78999   [The, National, Council, for, Human, Rights, a...  \n",
       "79000   [\", There, is, no, space, for, people, to, cho...  \n",
       "79001   [\", Those, who, go, out, to, vote, will, vote,...  \n",
       "79002   [The, atmosphere, right, now, does, not, allow...  \n",
       "79003   [Lara, El, Gibaly, contributed, to, this, repo...  \n",
       "\n",
       "[151570 rows x 9 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs(t['sentenc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT CAST(entry_id AS int) as entry_id,\n",
    "                CAST(version AS int) as version, \n",
    "                ARRAYS_ZIP(finished_token, finished_token_metadata, embeddings_vectors) AS zipped_tokens\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "explode_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, POSEXPLODE(zipped_tokens) AS (word_idx, zipped_token)\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "rename_tok = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, \n",
    "                 version,\n",
    "                 CAST(zipped_token.finished_token_metadata._2 AS int) AS sent_idx,\n",
    "                 COUNT(1) OVER(PARTITION BY entry_id, version, zipped_token.finished_token_metadata._2) as num_words,\n",
    "                 CAST(word_idx AS int) word_idx,\n",
    "                 zipped_token.finished_token AS token,\n",
    "                 zipped_token.embeddings_vectors as word_embedding\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "vector_normalizer = (\n",
    "    Normalizer(\n",
    "        inputCol=\"word_embedding\", \n",
    "        outputCol=\"norm_word_embedding\", \n",
    "        p=2.0\n",
    "    )\n",
    ")\n",
    "similarty_checker = (\n",
    "    BucketedRandomProjectionLSH(\n",
    "        inputCol=\"norm_word_embedding\", \n",
    "        outputCol=\"hashes\", \n",
    "        bucketLength=3,\n",
    "        numHashTables=3\n",
    "    )\n",
    ")\n",
    "\n",
    "## get top sentences, X, pipeline\n",
    "s1x, s2x, s3x, s4x = get_word_matching_sql(side='x')\n",
    "get_word_pair_min_distance_x = SQLTransformer().setStatement(s1x)\n",
    "get_sentence_min_distance_x = SQLTransformer().setStatement(s2x)\n",
    "get_min_sentence_x = SQLTransformer().setStatement(s3x)\n",
    "threshold_x = SQLTransformer().setStatement(s4x)\n",
    "\n",
    "## get top sentences, Y, pipeline\n",
    "s1y, s2y, s3y, s4y = get_word_matching_sql(side='y')\n",
    "get_word_pair_min_distance_y = SQLTransformer().setStatement(s1y)\n",
    "get_sentence_min_distance_y = SQLTransformer().setStatement(s2y)\n",
    "get_min_sentence_y = SQLTransformer().setStatement(s3y)\n",
    "threshold_y = SQLTransformer().setStatement(s4y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparknlp_processing_pipeline = sb.RecursivePipeline(stages=[\n",
    "    documenter,\n",
    "    sentencer,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    embeddings_finisher,\n",
    "    tok_finisher\n",
    "  ]\n",
    ")\n",
    "\n",
    "explode_pipeline = sb.PipelineModel(stages=[\n",
    "    zip_tok,\n",
    "    explode_tok,\n",
    "    rename_tok,\n",
    "])\n",
    "\n",
    "similarity_pipeline = sb.Pipeline(stages=[\n",
    "    vector_normalizer,\n",
    "    similarty_checker\n",
    "])\n",
    "\n",
    "top_sentence_pipeline_x = sb.PipelineModel(stages=[\n",
    "    get_word_pair_min_distance_x,\n",
    "    get_sentence_min_distance_x,\n",
    "    get_min_sentence_x,\n",
    "    threshold_x\n",
    "])\n",
    "\n",
    "top_sentence_pipeline_y = sb.PipelineModel(stages=[\n",
    "    get_word_pair_min_distance_y,\n",
    "    get_sentence_min_distance_y,\n",
    "    get_min_sentence_y,\n",
    "    threshold_y\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting LSH Pipeline...\n"
     ]
    }
   ],
   "source": [
    "## pipeline and cache\n",
    "sdf = sdf.repartition('entry_id', 'version').cache()\n",
    "spark_processed_df = sparknlp_processing_pipeline.fit(sdf).transform(sdf)\n",
    "spark_processed_df = spark_processed_df.cache()\n",
    "\n",
    "exploded_sdf = explode_pipeline.transform(spark_processed_df)\n",
    "exploded_sdf = exploded_sdf.cache()\n",
    "\n",
    "print('fitting LSH Pipeline...')\n",
    "similarity_model = similarity_pipeline.fit(exploded_sdf)\n",
    "sim_sdf = similarity_model.transform(exploded_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sdf = sim_sdf.repartition(\n",
    "    'entry_id',\n",
    "    'version',\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing approximate join...\n"
     ]
    }
   ],
   "source": [
    "print('performing approximate join...')\n",
    "## Approximate Join\n",
    "word_pair_matched_sdf = (\n",
    "    similarity_model\n",
    "    .stages[1]\n",
    "    .approxSimilarityJoin(sim_sdf, sim_sdf, .5, distCol=\"distance\")\n",
    "    .where((F.col(\"datasetA.entry_id\") == F.col(\"datasetB.entry_id\")) & (F.col(\"datasetA.version\") + 1 == F.col(\"datasetB.version\")))\n",
    "    .select(\n",
    "         F.col(\"datasetA.entry_id\").alias(\"entry_id\"),\n",
    "         F.col(\"datasetA.version\").alias(\"version_x\"),\n",
    "         F.col(\"datasetB.version\").alias(\"version_y\"),\n",
    "         F.col(\"datasetA.sent_idx\").alias(\"sent_idx_x\"),\n",
    "         F.col(\"datasetB.sent_idx\").alias(\"sent_idx_y\"),        \n",
    "         F.col(\"datasetA.word_idx\").alias(\"word_idx_x\"),\n",
    "         F.col(\"datasetB.word_idx\").alias(\"word_idx_y\"),\n",
    "         F.col(\"datasetA.num_words\").alias(\"num_words\"),\n",
    "         F.col(\"datasetA.token\").alias(\"token_x\"),\n",
    "         F.col(\"datasetB.token\").alias(\"token_y\"),\n",
    "         F.col(\"distance\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pair_matched_sdf = word_pair_matched_sdf.repartition(\n",
    "                        'entry_id',\n",
    "                        'version_x',\n",
    "                        'version_y',\n",
    "                        'sent_idx_x',\n",
    "                        'sent_idx_y',\n",
    "#                         'word_idx_x',\n",
    "#                         'word_idx_y',\n",
    ").cache()\n",
    "\n",
    "## performing bipartite matching\n",
    "sent_pairs_x_sdf = top_sentence_pipeline_x.transform(word_pair_matched_sdf).cache()\n",
    "sent_pairs_y_sdf = top_sentence_pipeline_y.transform(word_pair_matched_sdf).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to pandas...\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "join_cols=['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y']\n",
    "final_sdf = (\n",
    " sent_pairs_x_sdf\n",
    "    .withColumnRenamed('avg_sentence_distance', 'avg_sentence_distance_x')\n",
    "    .join(\n",
    "    sent_pairs_y_sdf.withColumnRenamed('avg_sentence_distance', 'avg_sentence_distance_y', ),\n",
    "    on=join_cols, \n",
    "    how='outer'\n",
    ").dropDuplicates(join_cols))\n",
    "\n",
    "## to pandas\n",
    "print('to pandas...')\n",
    "final_dfp = final_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfp.to_csv('wp-many-docs-with-sent-breaks_word-matching.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dfp.to_csv('wp-many-docs-with-sent-breaks_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sentences for Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "normer = (\n",
    "    sa.DocumentNormalizer()\n",
    "    .setInputCols([\"document\"])\n",
    "    .setOutputCol(\"normed_document\")\n",
    "    .setPatterns([\"[^\\w\\d\\s\\.\\,\\\"\\']\"])\n",
    "#     .setPolicy('pretty_all')\n",
    ")\n",
    "\n",
    "sentencer = (\n",
    "    sa.SentenceDetector()\n",
    "        .setInputCols([\"document\"])\n",
    "        .setOutputCol(\"sentences\")\n",
    "        .setCustomBounds(['<SENT>'])\n",
    "        .setUseCustomBoundsOnly(True)\n",
    "\n",
    ")\n",
    "\n",
    "# sentencer_dl = (\n",
    "#     sa.SentenceDetectorDLModel\n",
    "#         .load('s3://aspangher/spark-nlp/sentence_detector_dl_en')\n",
    "#         .setInputCols([\"document\"])\n",
    "#         .setOutputCol(\"sentences\")            \n",
    "# )\n",
    "\n",
    "sent_finisher = (\n",
    "    sb.Finisher()\n",
    "    .setInputCols([\"sentences\"])\n",
    ")\n",
    "\n",
    "explode_sent = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, POSEXPLODE(finished_sentences) AS (sent_idx, sentence)\n",
    "         FROM __THIS__\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "sentence_splitter_pipeline = sb.RecursivePipeline(stages=[\n",
    "    documenter,\n",
    "    sentencer,\n",
    "    sent_finisher,\n",
    "    explode_sent\n",
    "])\n",
    "\n",
    "sent_dfp = sentence_splitter_pipeline.fit(sdf).transform(sdf).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dfp.to_csv('wp-many-docs-with-sent-breaks_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_3_3 = final_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_6_6 = final_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1951413</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1952324</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>80.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.021371e-07</td>\n",
       "      <td>3.021371e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952324</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951413</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1951413</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  version_x  version_y  sent_idx_x  sent_idx_y  \\\n",
       "0   1951413         17         18        27.0        27.0   \n",
       "1   1952324         13         14        80.0        78.0   \n",
       "2   1952324          5          6        47.0        47.0   \n",
       "3   1951413          5          6        15.0        15.0   \n",
       "4   1951413          4          5        14.0        14.0   \n",
       "\n",
       "   avg_sentence_distance_x  avg_sentence_distance_y  \n",
       "0             0.000000e+00             0.000000e+00  \n",
       "1             3.021371e-07             3.021371e-07  \n",
       "2             0.000000e+00             0.000000e+00  \n",
       "3             0.000000e+00             0.000000e+00  \n",
       "4             0.000000e+00             0.000000e+00  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_3_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1952324</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951413</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952324</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>80.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.021371e-07</td>\n",
       "      <td>3.021371e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951413</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1951413</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  version_x  version_y  sent_idx_x  sent_idx_y  \\\n",
       "0   1952324          5          6        47.0        47.0   \n",
       "1   1951413         17         18        27.0        27.0   \n",
       "2   1952324         13         14        80.0        78.0   \n",
       "3   1951413          5          6        35.0        38.0   \n",
       "4   1951413          4          5        14.0        14.0   \n",
       "\n",
       "   avg_sentence_distance_x  avg_sentence_distance_y  \n",
       "0             0.000000e+00             0.000000e+00  \n",
       "1             0.000000e+00             0.000000e+00  \n",
       "2             3.021371e-07             3.021371e-07  \n",
       "3             0.000000e+00             0.000000e+00  \n",
       "4             0.000000e+00             0.000000e+00  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_6_6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if reducing bucket size makes a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_x_1_1</th>\n",
       "      <th>sent_y_1_1</th>\n",
       "      <th>sent_x_6_6</th>\n",
       "      <th>sent_y_6_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>1952324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_id  version_x  version_y  sent_x_1_1  sent_y_1_1  sent_x_6_6  \\\n",
       "4851   1952324          0          1        38.0        41.0        38.0   \n",
       "\n",
       "      sent_y_6_6  \n",
       "4851        40.0  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_df_1_1[cols]\n",
    " .rename({'sent_idx_x': 'sent_x_1_1', 'sent_idx_y': 'sent_y_1_1'}, axis=1)\n",
    " .merge(\n",
    "    final_df_6_6[cols].rename({'sent_idx_x': 'sent_x_6_6', 'sent_idx_y': 'sent_y_6_6'}, axis=1),\n",
    "    right_on=['entry_id', 'version_x', 'version_y', 'sent_x_6_6'],\n",
    "    left_on=['entry_id', 'version_x', 'version_y', 'sent_x_1_1'],\n",
    "    how='outer'\n",
    ")\n",
    " .loc[lambda df: df['sent_y_1_1'] != df['sent_y_6_6']]\n",
    " .loc[lambda df: ~( df['sent_x_1_1'].isnull() & df['sent_y_1_1'].notnull())]\n",
    " .loc[lambda df: ~( df['sent_x_1_1'].notnull() & df['sent_y_1_1'].isnull())]\n",
    "#  .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>1952324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.388997</td>\n",
       "      <td>0.388997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_id  version_x  version_y  sent_idx_x  sent_idx_y  \\\n",
       "3064   1952324          0          1        38.0        41.0   \n",
       "\n",
       "      avg_sentence_distance_x  avg_sentence_distance_y  \n",
       "3064                 0.388997                 0.388997  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_df_1_1\n",
    " .loc[lambda df: df['entry_id'] == 1952324]\n",
    " .loc[lambda df: df['version_x'] == 0]\n",
    " .loc[lambda df: df['version_y'] == 1]\n",
    " .loc[lambda df: df['sent_idx_x'] == 38]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1952324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.439192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>1952324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.388997</td>\n",
       "      <td>0.388997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_id  version_x  version_y  sent_idx_x  sent_idx_y  \\\n",
       "541    1952324          0          1        38.0        40.0   \n",
       "3064   1952324          0          1        38.0        41.0   \n",
       "\n",
       "      avg_sentence_distance_x  avg_sentence_distance_y  \n",
       "541                       NaN                 0.439192  \n",
       "3064                 0.388997                 0.388997  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_df_3_3\n",
    " .loc[lambda df: df['entry_id'] == 1952324]\n",
    " .loc[lambda df: df['version_x'] == 0]\n",
    " .loc[lambda df: df['version_y'] == 1]\n",
    " .loc[lambda df: df['sent_idx_x'] == 38]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_x_3_3</th>\n",
       "      <th>sent_y_3_3</th>\n",
       "      <th>sent_x_6_6</th>\n",
       "      <th>sent_y_6_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>1952324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>1952324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_id  version_x  version_y  sent_x_3_3  sent_y_3_3  sent_x_6_6  \\\n",
       "2378   1952324          0          1        38.0        40.0        38.0   \n",
       "2379   1952324          0          1        38.0        41.0        38.0   \n",
       "\n",
       "      sent_y_6_6  \n",
       "2378        41.0  \n",
       "2379        40.0  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_df_3_3[cols]\n",
    " .rename({'sent_idx_x': 'sent_x_3_3', 'sent_idx_y': 'sent_y_3_3'}, axis=1)\n",
    " .merge(\n",
    "    final_df_6_6[cols].rename({'sent_idx_x': 'sent_x_6_6', 'sent_idx_y': 'sent_y_6_6'}, axis=1),\n",
    "    right_on=['entry_id', 'version_x', 'version_y', 'sent_x_6_6'],\n",
    "    left_on=['entry_id', 'version_x', 'version_y', 'sent_x_3_3'],\n",
    ")\n",
    " .loc[lambda df: df['sent_y_3_3'] != df['sent_y_6_6']]\n",
    " .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_x_3_3</th>\n",
       "      <th>sent_y_3_3</th>\n",
       "      <th>sent_x_6_6</th>\n",
       "      <th>sent_y_6_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1952324</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1952324</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>1951413</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>79.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>1951413</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>1952324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>1952324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>1951413</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>1951413</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>1951413</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>1951413</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_id  version_x  version_y  sent_x_3_3  sent_y_3_3  sent_x_6_6  \\\n",
       "101    1952324          4          5        25.0        25.0        24.0   \n",
       "102    1952324          4          5        24.0        25.0        25.0   \n",
       "2140   1951413         12         13        79.0        73.0        72.0   \n",
       "2141   1951413         12         13        72.0        73.0        79.0   \n",
       "3048   1952324          0          1         7.0         8.0         8.0   \n",
       "3049   1952324          0          1         8.0         8.0         7.0   \n",
       "3412   1951413          5          6        64.0        67.0        67.0   \n",
       "3413   1951413          5          6        67.0        67.0        64.0   \n",
       "4066   1951413          1          2        22.0        52.0        18.0   \n",
       "4067   1951413          1          2        18.0        52.0        22.0   \n",
       "\n",
       "      sent_y_6_6  \n",
       "101         25.0  \n",
       "102         25.0  \n",
       "2140        73.0  \n",
       "2141        73.0  \n",
       "3048         8.0  \n",
       "3049         8.0  \n",
       "3412        67.0  \n",
       "3413        67.0  \n",
       "4066        52.0  \n",
       "4067        52.0  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_df_3_3[cols]\n",
    " .rename({'sent_idx_x': 'sent_x_3_3', 'sent_idx_y': 'sent_y_3_3'}, axis=1)\n",
    " .merge(\n",
    "    final_df_6_6[cols].rename({'sent_idx_x': 'sent_x_6_6', 'sent_idx_y': 'sent_y_6_6'}, axis=1),\n",
    "    right_on=['entry_id', 'version_x', 'version_y', 'sent_y_6_6'],\n",
    "    left_on=['entry_id', 'version_x', 'version_y', 'sent_y_3_3'],\n",
    ")\n",
    " .loc[lambda df: df['sent_x_3_3'] != df['sent_x_6_6']]\n",
    " .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_3_3 = final_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_dfp[['entry_id', 'version_x', 'version_y']].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "## download spacy model \n",
    "# download data\n",
    "from util import util_data_access\n",
    "import os\n",
    "if not os.path.exists('en_core_web_lg'):\n",
    "    util_data_access.download_file('en_core_web_lg.tar.gz', 'edit-pathways/spacy/en_core_web_lg.tar.gz')\n",
    "    ! tar -xf en_core_web_lg.tar.gz\n",
    "    ! mv en_core_web_lg-2.3.1 en_core_web_lg\n",
    "import util.util_newssniffer_parsing as unp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (final_df_3_3\n",
    "#  .loc[lambda df: df['entry_id'] == 1952324]\n",
    "#  .loc[lambda df: df['version_x'] == 0]\n",
    "#  .loc[lambda df: df['version_y'] == 1]\n",
    "#  .loc[lambda df: df['sent_idx_x'] == 38]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (sent_dfp\n",
    "#  .loc[lambda df: df['entry_id'] == 1952324]\n",
    "#  .loc[lambda df: df['version_x'] == 0]\n",
    "#  .loc[lambda df: df['version_y'] == 1]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_sents = (final_df_3_3\n",
    " .loc[lambda df: df['entry_id'] == 1952324]\n",
    " .loc[lambda df: df['version_x'] == 0]\n",
    " .loc[lambda df: df['version_y'] == 1]\n",
    " .merge(\n",
    "    sent_dfp,\n",
    "    left_on=['entry_id', 'version_x', 'sent_idx_x'],\n",
    "    right_on=['entry_id', 'version', 'sent_idx'],\n",
    "    how='left'\n",
    " ).drop(['version', 'sent_idx',], axis=1)\n",
    " .merge(\n",
    "    sent_dfp, \n",
    "    left_on=['entry_id', 'version_y', 'sent_idx_y'],\n",
    "    right_on=['entry_id', 'version', 'sent_idx'],\n",
    "    how='left'\n",
    " )\n",
    " .drop(['version', 'sent_idx',], axis=1)\n",
    " .sort_values(['sent_idx_x', 'sent_idx_y'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What happened in Minneapolis and elsewhere this week reflected the broad and diverse scope of the movement that took flight six years ago, with young but already veteran organizers trying to keep the focus on police accountability and systemic racism through chanting and marching.'"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 or ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = [\n",
    "    '<table>',\n",
    "    '<tr><th>SIdx Old</th><th>Old Version</th><th>New Version</th><th>SIdx New</th><th>Distance</th></tr>',\n",
    "]\n",
    "for s_idx_1, s_idx_2, s1, s2, d in (\n",
    "        comp_sents\n",
    "            [['sent_idx_x', 'sent_idx_y', 'sentence_x', 'sentence_y', 'avg_sentence_distance_x']]\n",
    "    .fillna('')\n",
    "#             .loc[lambda df: df['avg_sentence_distance_x'] > .44]\n",
    "            .itertuples(index=False)\n",
    "):\n",
    "    one_row = '<tr><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td></tr>'\n",
    "    w1, w2 = unp.get_words(s1), unp.get_words(s2)\n",
    "    hs1, hs2 = unp.html_compare_sentences(*unp.get_list_diff(w1, w2))\n",
    "    html.append(one_row % (s_idx_1, hs1, hs2, s_idx_2, d))\n",
    "    \n",
    "html_output = ''.join(html).replace('$', r'\\$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>SIdx Old</th><th>Old Version</th><th>New Version</th><th>SIdx New</th><th>Distance</th></tr><tr><td>0.0</td><td>MINNEAPOLIS  With the Third Police Precinct headquarters engulfed in flames ,    a cathartic release swept through the streets of Minneapolis s South Side  Thursday night .</td><td>MINNEAPOLIS  With the Third Police Precinct headquarters engulfed in flames , <span style=\"background-color:rgba(0,255,0,0.3)\">what </span> <span style=\"background-color:rgba(0,255,0,0.3)\">felt </span> <span style=\"background-color:rgba(0,255,0,0.3)\">like </span> a cathartic release swept through the streets of Minneapolis s South Side <span style=\"background-color:rgba(0,255,0,0.3)\">on </span> Thursday night .</td><td>0.0</td><td>0.21324550597266542</td></tr><tr><td>1.0</td><td>Some people danced to Beyonc , others passed out beer .</td><td>Some people danced to Beyonc , others passed out beer .</td><td>1.0</td><td>0.0</td></tr><tr><td>2.0</td><td>Still others chanted :  No justice , no peace !</td><td>Still others chanted :  No justice , no peace !</td><td>2.0</td><td>0.0</td></tr><tr><td>3.0</td><td>Prosecute the police !  The police killing of George Floyd in Minneapolis has incited a wave of demonstrations and unrest across the nation , renewing passionate street uprisings that gave rise to the Black Lives Matter movement six years ago .</td><td>Prosecute the police !  The police killing of George Floyd in Minneapolis has incited a wave of demonstrations and unrest across the nation , renewing passionate street uprisings that gave rise to the Black Lives Matter movement six years ago .</td><td>3.0</td><td>2.8922584885719725e-09</td></tr><tr><td>4.0</td><td><span style=\"background-color:rgba(255,0,0,0.3)\">What</span> <span style=\"background-color:rgba(255,0,0,0.3)\">happened</span> <span style=\"background-color:rgba(255,0,0,0.3)\">in</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Minneapolis</span> <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">elsewhere</span> <span style=\"background-color:rgba(255,0,0,0.3)\">this</span> <span style=\"background-color:rgba(255,0,0,0.3)\">week</span> <span style=\"background-color:rgba(255,0,0,0.3)\">reflected</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">broad</span> <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">diverse</span> <span style=\"background-color:rgba(255,0,0,0.3)\">scope</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">movement</span> <span style=\"background-color:rgba(255,0,0,0.3)\">that</span> <span style=\"background-color:rgba(255,0,0,0.3)\">took</span> <span style=\"background-color:rgba(255,0,0,0.3)\">flight</span> <span style=\"background-color:rgba(255,0,0,0.3)\">six</span> <span style=\"background-color:rgba(255,0,0,0.3)\">years</span> <span style=\"background-color:rgba(255,0,0,0.3)\">ago</span> <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> <span style=\"background-color:rgba(255,0,0,0.3)\">with</span> <span style=\"background-color:rgba(255,0,0,0.3)\">young</span> <span style=\"background-color:rgba(255,0,0,0.3)\">but</span> <span style=\"background-color:rgba(255,0,0,0.3)\">already</span> <span style=\"background-color:rgba(255,0,0,0.3)\">veteran</span> <span style=\"background-color:rgba(255,0,0,0.3)\">organizers</span> <span style=\"background-color:rgba(255,0,0,0.3)\">trying</span> <span style=\"background-color:rgba(255,0,0,0.3)\">to</span> <span style=\"background-color:rgba(255,0,0,0.3)\">keep</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">focus</span> <span style=\"background-color:rgba(255,0,0,0.3)\">on</span> <span style=\"background-color:rgba(255,0,0,0.3)\">police</span> <span style=\"background-color:rgba(255,0,0,0.3)\">accountability</span> <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">systemic</span> <span style=\"background-color:rgba(255,0,0,0.3)\">racism</span> <span style=\"background-color:rgba(255,0,0,0.3)\">through</span> <span style=\"background-color:rgba(255,0,0,0.3)\">chanting</span> <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">marching</span> <span style=\"background-color:rgba(255,0,0,0.3)\">.</span></td><td>                                             </td><td></td><td></td></tr><tr><td>5.0</td><td>Others <span style=\"background-color:rgba(255,0,0,0.3)\">came</span>      to revel in the energy of the moment .</td><td>Others  <span style=\"background-color:rgba(0,255,0,0.3)\">have </span> <span style=\"background-color:rgba(0,255,0,0.3)\">taken </span> <span style=\"background-color:rgba(0,255,0,0.3)\">to </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">streets </span> to revel in the energy of the moment .</td><td>13.0</td><td>0.3894617381729948</td></tr><tr><td>6.0</td><td>Some  <span style=\"background-color:rgba(255,0,0,0.3)\">came</span> to loot and set fires .</td><td>Some <span style=\"background-color:rgba(0,255,0,0.3)\">have </span> <span style=\"background-color:rgba(0,255,0,0.3)\">come </span> to loot and set fires .</td><td>14.0</td><td>0.30127327025396794</td></tr><tr><td>7.0</td><td>Mike Griffin , an organizer in Minneapolis , said these are mostly decentralized protests                 .</td><td>Mike Griffin , an organizer in Minneapolis , said these are mostly decentralized protests <span style=\"background-color:rgba(0,255,0,0.3)\">: </span> <span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">That </span> <span style=\"background-color:rgba(0,255,0,0.3)\">happens </span> <span style=\"background-color:rgba(0,255,0,0.3)\">without </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">black </span> <span style=\"background-color:rgba(0,255,0,0.3)\">pastor </span> <span style=\"background-color:rgba(0,255,0,0.3)\">coming </span> <span style=\"background-color:rgba(0,255,0,0.3)\">in </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">telling </span> <span style=\"background-color:rgba(0,255,0,0.3)\">us </span> <span style=\"background-color:rgba(0,255,0,0.3)\">to </span> <span style=\"background-color:rgba(0,255,0,0.3)\">do </span> <span style=\"background-color:rgba(0,255,0,0.3)\">it </span> .</td><td>8.0</td><td>0.23169662857866907</td></tr><tr><td>8.0</td><td>                That happens without the black pastor coming in and telling us to do it .</td><td><span style=\"background-color:rgba(0,255,0,0.3)\">Mike </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Griffin </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">an </span> <span style=\"background-color:rgba(0,255,0,0.3)\">organizer </span> <span style=\"background-color:rgba(0,255,0,0.3)\">in </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Minneapolis </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">said </span> <span style=\"background-color:rgba(0,255,0,0.3)\">these </span> <span style=\"background-color:rgba(0,255,0,0.3)\">are </span> <span style=\"background-color:rgba(0,255,0,0.3)\">mostly </span> <span style=\"background-color:rgba(0,255,0,0.3)\">decentralized </span> <span style=\"background-color:rgba(0,255,0,0.3)\">protests </span> <span style=\"background-color:rgba(0,255,0,0.3)\">: </span>  That happens without the black pastor coming in and telling us to do it .</td><td>8.0</td><td>0.3689505579705126</td></tr><tr><td>9.0</td><td>That s organic .</td><td>That s organic .</td><td>9.0</td><td>0.0</td></tr><tr><td>10.0</td><td>These are organic protests .</td><td>These are organic protests .</td><td>10.0</td><td>0.0</td></tr><tr><td>11.0</td><td><span style=\"background-color:rgba(255,0,0,0.3)\"></span> <span style=\"background-color:rgba(255,0,0,0.3)\">But</span> <span style=\"background-color:rgba(255,0,0,0.3)\">that</span> <span style=\"background-color:rgba(255,0,0,0.3)\">decentralized</span> <span style=\"background-color:rgba(255,0,0,0.3)\">nature</span> <span style=\"background-color:rgba(255,0,0,0.3)\">comes</span> <span style=\"background-color:rgba(255,0,0,0.3)\">with</span> <span style=\"background-color:rgba(255,0,0,0.3)\">risks</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">a</span> <span style=\"background-color:rgba(255,0,0,0.3)\">moment</span> <span style=\"background-color:rgba(255,0,0,0.3)\">that</span> <span style=\"background-color:rgba(255,0,0,0.3)\">can</span> <span style=\"background-color:rgba(255,0,0,0.3)\">spin</span> <span style=\"background-color:rgba(255,0,0,0.3)\">out</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">control</span> <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> <span style=\"background-color:rgba(255,0,0,0.3)\">with</span> <span style=\"background-color:rgba(255,0,0,0.3)\">images</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">flames</span> <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">looting</span> <span style=\"background-color:rgba(255,0,0,0.3)\">or</span> <span style=\"background-color:rgba(255,0,0,0.3)\">worse</span> <span style=\"background-color:rgba(255,0,0,0.3)\">that</span> <span style=\"background-color:rgba(255,0,0,0.3)\">can</span> <span style=\"background-color:rgba(255,0,0,0.3)\">easily</span> <span style=\"background-color:rgba(255,0,0,0.3)\">overshadow</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">central</span> <span style=\"background-color:rgba(255,0,0,0.3)\">message</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">an</span> <span style=\"background-color:rgba(255,0,0,0.3)\">end</span> <span style=\"background-color:rgba(255,0,0,0.3)\">to</span> <span style=\"background-color:rgba(255,0,0,0.3)\">police</span> <span style=\"background-color:rgba(255,0,0,0.3)\">abuse</span> <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">systemic</span> <span style=\"background-color:rgba(255,0,0,0.3)\">racism</span> <span style=\"background-color:rgba(255,0,0,0.3)\">.</span></td><td>                                          </td><td></td><td></td></tr><tr><td>12.0</td><td>The protesters come from <span style=\"background-color:rgba(255,0,0,0.3)\">all</span>  racial backgrounds with ardent cadres of young white allies quite unlike earlier eras of racial unrest .</td><td>The protesters come from  <span style=\"background-color:rgba(0,255,0,0.3)\">diverse </span> racial backgrounds with ardent cadres of young white allies quite unlike earlier eras of racial unrest .</td><td>15.0</td><td>0.0900618706107505</td></tr><tr><td>13.0</td><td>Some marches are led by national or local activist organizations .</td><td>Some marches are led by national or local activist organizations .</td><td>16.0</td><td>0.0</td></tr><tr><td>14.0</td><td>Many others are simply spontaneous , sprouting up from long - simmering frustrations in city neighborhoods .</td><td>Many others are simply spontaneous , sprouting up from long - simmering frustrations in city neighborhoods .</td><td>17.0</td><td>0.0</td></tr><tr><td>15.0</td><td><span style=\"background-color:rgba(255,0,0,0.3)\">But</span> <span style=\"background-color:rgba(255,0,0,0.3)\">underlying</span> it <span style=\"background-color:rgba(255,0,0,0.3)\">all</span>    was a moment of witness , part anger , part despair , part hope , defined by the seemingly endless drumbeat of deaths as senseless as that of George Floyd .</td><td> <span style=\"background-color:rgba(0,255,0,0.3)\">Underlying </span> it  <span style=\"background-color:rgba(0,255,0,0.3)\">at </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">start </span> was a moment of witness , part anger , part despair , part hope , defined by the seemingly endless drumbeat of deaths as senseless as that of George Floyd .</td><td>18.0</td><td>0.18135384762550394</td></tr><tr><td>16.0</td><td> May 27 , 2020 , changed my life forever ,  said Kayla JuNaye Johnson , 21 , a student majoring in criminal justice at Grambling State University , a historically black public university in Louisiana .</td><td> May 27 , 2020 , changed my life forever ,  said Kayla JuNaye Johnson , 21 , a student majoring in criminal justice at Grambling State University , a historically black public university in Louisiana .</td><td>19.0</td><td>5.141921976802261e-07</td></tr><tr><td>17.0</td><td> I would always go out and support protests but never took full action like I did yesterday .</td><td> I would always go out and support protests but never took full action like I did yesterday .</td><td>20.0</td><td>0.0</td></tr><tr><td>18.0</td><td>I stood on the front line shouting ,  Hands up , do nt shoot .</td><td>I stood on the front line shouting ,  Hands up , do nt shoot .</td><td>21.0</td><td>0.0</td></tr><tr><td>19.0</td><td> Now I finally know how us African - Americans felt during the civil rights movement .</td><td> Now I finally know how us African - Americans felt during the civil rights movement .</td><td>22.0</td><td>3.360135248551894e-07</td></tr><tr><td>20.0</td><td>I am a part of history .</td><td>I am a part of history .</td><td>23.0</td><td>0.0</td></tr><tr><td>21.0</td><td><span style=\"background-color:rgba(255,0,0,0.3)\"></span>  <span style=\"background-color:rgba(255,0,0,0.3)\">Protests</span>      played out around the country from Atlanta to    Los Angeles on Friday night .</td><td> <span style=\"background-color:rgba(0,255,0,0.3)\">Angry </span> <span style=\"background-color:rgba(0,255,0,0.3)\">protests </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">clashes </span> <span style=\"background-color:rgba(0,255,0,0.3)\">with </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">police </span> played out around the country from Atlanta to <span style=\"background-color:rgba(0,255,0,0.3)\">New </span> <span style=\"background-color:rgba(0,255,0,0.3)\">York </span> <span style=\"background-color:rgba(0,255,0,0.3)\">to </span> Los Angeles on Friday night .</td><td>25.0</td><td>0.38128707571231435</td></tr><tr><td>22.0</td><td>A particular hot spot this week was Louisville , Ky.</td><td>A particular hot spot this week was Louisville , Ky.</td><td>26.0</td><td>0.0</td></tr><tr><td>23.0</td><td>Gunfire broke out in the late hours of a demonstration on Thursday that was protesting the shooting death of Breonna Taylor , a 26-year - old emergency medical technician   killed by Louisville police officers executing a search warrant .</td><td>Gunfire broke out in the late hours of a demonstration on Thursday that was protesting the shooting death of Breonna Taylor , a 26-year - old emergency medical technician <span style=\"background-color:rgba(0,255,0,0.3)\">who </span> <span style=\"background-color:rgba(0,255,0,0.3)\">was </span> killed by Louisville police officers executing a search warrant .</td><td>27.0</td><td>0.10445698456771427</td></tr><tr><td>24.0</td><td>Seven demonstrators were injured .</td><td>Seven demonstrators were injured .</td><td>28.0</td><td>0.0</td></tr><tr><td>25.0</td><td>It is still unclear who fired the shots , though  authorities said they came from within the crowd .</td><td>It is still unclear who fired the shots , though <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> authorities said they came from within the crowd .</td><td>29.0</td><td>0.11316967634628927</td></tr><tr><td>26.0</td><td> We have to be careful to control our message , and violence changes that message ,  said Keisha Dorsey , a Louisville city councilwoman who supports police reform .</td><td> We have to be careful to control our message , and violence changes that message ,  said Keisha Dorsey , a Louisville city councilwoman who supports police reform .</td><td>30.0</td><td>4.2779826640464414e-09</td></tr><tr><td>27.0</td><td>She said , with the endless fire hose of social media , it <span style=\"background-color:rgba(255,0,0,0.3)\">can</span>  become easy for a protest to lose all focus .</td><td>She said , with the endless fire hose of social media , it  <span style=\"background-color:rgba(0,255,0,0.3)\">could </span> become easy for a protest to lose all focus .</td><td>31.0</td><td>0.1129169719122576</td></tr><tr><td>28.0</td><td> At that point  that centralized voice , if it s not cohesive , can get lost ,  she said .</td><td> At that point <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> that centralized voice , if it s not cohesive , can get lost ,  she said .</td><td>32.0</td><td>0.16563969974542692</td></tr><tr><td>29.0</td><td>Many of the nationwide demonstrations this week have pushed for the arrest of the officers involved in Mr. Floyd s death .</td><td>Many of the nationwide demonstrations this week have pushed for the arrest of the officers involved in Mr. Floyd s death .</td><td>33.0</td><td>4.925577322500392e-07</td></tr><tr><td>30.0</td><td>But every city has also had its own cases and rallying cries .</td><td>But every city has also had its own cases and rallying cries .</td><td>34.0</td><td>4.82897055259856e-07</td></tr><tr><td>31.0</td><td>A demonstration in Columbus , Ohio , on Thursday night , which ended in clashes between  police and protesters <span style=\"background-color:rgba(255,0,0,0.3)\">and</span>    damage to the Ohio Statehouse , was not only about Mr. Floyd and Ms. Taylor , but  a number of other black people killed at the hands of  police , including a 16-year - old killed in a police sting in Columbus in late 2018 .</td><td>A demonstration in Columbus , Ohio , on Thursday night , which ended in clashes between <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> police and protesters  <span style=\"background-color:rgba(0,255,0,0.3)\">as </span> <span style=\"background-color:rgba(0,255,0,0.3)\">well </span> <span style=\"background-color:rgba(0,255,0,0.3)\">as </span> damage to the Ohio Statehouse , was not only about Mr. Floyd and Ms. Taylor , but <span style=\"background-color:rgba(0,255,0,0.3)\">also </span> a number of other black people killed at the hands of <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> police , including a 16-year - old killed in a police sting in Columbus in late 2018 .</td><td>35.0</td><td>0.2427571331545464</td></tr><tr><td>32.0</td><td>In Phoenix , a controversial local activist called a march which , while not fully supported by the other police accountability groups in the city , ended up drawing hundreds , many of them protesting the long - troubled record of the Phoenix police in addition to the death of Mr. Floyd .</td><td>In Phoenix , a controversial local activist called a march which , while not fully supported by the other police accountability groups in the city , ended up drawing hundreds , many of them protesting the long - troubled record of the Phoenix police in addition to the death of Mr. Floyd .</td><td>36.0</td><td>2.505135387506182e-09</td></tr><tr><td>33.0</td><td>In Memphis , an aggressive police response to a demonstration organized by local educators on Wednesday night prompted a second protest on Thursday , in part responding to the police actions during the first .</td><td>In Memphis , an aggressive police response to a demonstration organized by local educators on Wednesday night prompted a second protest on Thursday , in part responding to the police actions during the first .</td><td>37.0</td><td>0.0</td></tr><tr><td>34.0</td><td> It started out as the George Floyd issue ,  said Ayo Akinmoladun , a Memphis educator who organized what was intended to be a small silent protest .</td><td> It started out as the George Floyd issue ,  said Ayo Akinmoladun , a Memphis educator who organized what was intended to be a small silent protest .</td><td>38.0</td><td>0.0</td></tr><tr><td>35.0</td><td> All of these other issues are now coming out .</td><td> All of these other issues are now coming out .</td><td>39.0</td><td>0.0</td></tr><tr><td>36.0</td><td><span style=\"background-color:rgba(255,0,0,0.3)\"></span> <span style=\"background-color:rgba(255,0,0,0.3)\">While</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">demonstrations</span> <span style=\"background-color:rgba(255,0,0,0.3)\">are</span> <span style=\"background-color:rgba(255,0,0,0.3)\">largely</span> <span style=\"background-color:rgba(255,0,0,0.3)\">unmanaged</span> <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> <span style=\"background-color:rgba(255,0,0,0.3)\">there</span> <span style=\"background-color:rgba(255,0,0,0.3)\">is</span> <span style=\"background-color:rgba(255,0,0,0.3)\">also</span> <span style=\"background-color:rgba(255,0,0,0.3)\">a</span> <span style=\"background-color:rgba(255,0,0,0.3)\">more</span> <span style=\"background-color:rgba(255,0,0,0.3)\">structured</span> <span style=\"background-color:rgba(255,0,0,0.3)\">element</span> <span style=\"background-color:rgba(255,0,0,0.3)\">to</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">overall</span> <span style=\"background-color:rgba(255,0,0,0.3)\">attempt</span> <span style=\"background-color:rgba(255,0,0,0.3)\">to</span> <span style=\"background-color:rgba(255,0,0,0.3)\">win</span> <span style=\"background-color:rgba(255,0,0,0.3)\">policy</span> <span style=\"background-color:rgba(255,0,0,0.3)\">reforms</span> <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> <span style=\"background-color:rgba(255,0,0,0.3)\">with</span> <span style=\"background-color:rgba(255,0,0,0.3)\">activists</span> <span style=\"background-color:rgba(255,0,0,0.3)\">who</span> <span style=\"background-color:rgba(255,0,0,0.3)\">came</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">age</span> <span style=\"background-color:rgba(255,0,0,0.3)\">on</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">streets</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Ferguson</span> <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Mo.</span></td><td>                                    </td><td></td><td></td></tr><tr><td>37.0</td><td><span style=\"background-color:rgba(255,0,0,0.3)\">,</span> <span style=\"background-color:rgba(255,0,0,0.3)\">or</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Baltimore</span> <span style=\"background-color:rgba(255,0,0,0.3)\">or</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Cleveland</span> <span style=\"background-color:rgba(255,0,0,0.3)\">making</span> <span style=\"background-color:rgba(255,0,0,0.3)\">better</span> <span style=\"background-color:rgba(255,0,0,0.3)\">use</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">technology</span> <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">other</span> <span style=\"background-color:rgba(255,0,0,0.3)\">tools</span> <span style=\"background-color:rgba(255,0,0,0.3)\">than</span> <span style=\"background-color:rgba(255,0,0,0.3)\">in</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">past</span> <span style=\"background-color:rgba(255,0,0,0.3)\">.</span></td><td>                 </td><td></td><td></td></tr><tr><td>38.0</td><td> DeRay Mckesson became a well - known activist after spending months in Ferguson   <span style=\"background-color:rgba(255,0,0,0.3)\">chronicling</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">nightly</span> <span style=\"background-color:rgba(255,0,0,0.3)\">vigils</span> <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">clashes</span> <span style=\"background-color:rgba(255,0,0,0.3)\">with</span> <span style=\"background-color:rgba(255,0,0,0.3)\">police</span> <span style=\"background-color:rgba(255,0,0,0.3)\">over</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">killing</span> <span style=\"background-color:rgba(255,0,0,0.3)\">of</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Michael</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Brown</span> <span style=\"background-color:rgba(255,0,0,0.3)\">.</span></td><td><span style=\"background-color:rgba(0,255,0,0.3)\"> </span> DeRay Mckesson became a well - known activist after spending months in Ferguson <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Mo. </span>               </td><td>40.0</td><td></td></tr><tr><td>38.0</td><td> <span style=\"background-color:rgba(255,0,0,0.3)\">DeRay</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Mckesson</span> <span style=\"background-color:rgba(255,0,0,0.3)\">became</span> <span style=\"background-color:rgba(255,0,0,0.3)\">a</span> <span style=\"background-color:rgba(255,0,0,0.3)\">well</span> <span style=\"background-color:rgba(255,0,0,0.3)\">-</span> <span style=\"background-color:rgba(255,0,0,0.3)\">known</span> <span style=\"background-color:rgba(255,0,0,0.3)\">activist</span> <span style=\"background-color:rgba(255,0,0,0.3)\">after</span> <span style=\"background-color:rgba(255,0,0,0.3)\">spending</span> <span style=\"background-color:rgba(255,0,0,0.3)\">months</span> <span style=\"background-color:rgba(255,0,0,0.3)\">in</span> <span style=\"background-color:rgba(255,0,0,0.3)\">Ferguson</span> chronicling the nightly vigils and clashes with  police over the killing of Michael Brown .</td><td><span style=\"background-color:rgba(0,255,0,0.3)\">, </span>              chronicling the nightly vigils and clashes with <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> police over the killing of Michael Brown .</td><td>41.0</td><td>0.38899701642404866</td></tr><tr><td>39.0</td><td>He is not heading to Minneapolis , where he used to live , to protest .</td><td>He is not heading to Minneapolis , where he used to live , to protest .</td><td>42.0</td><td>3.412804699190741e-07</td></tr><tr><td>40.0</td><td>Instead , he has been speaking with organizers on the ground to craft strategy , he said , in line with the work he has done in more recent years to develop policy reforms .</td><td>Instead , he has been speaking with organizers on the ground to craft strategy , he said , in line with the work he has done in more recent years to develop policy reforms .</td><td>43.0</td><td>0.0</td></tr><tr><td>41.0</td><td> There needs to be an immediate response to the trauma ,  he said , referring to street protests .</td><td> There needs to be an immediate response to the trauma ,  he said , referring to street protests .</td><td>44.0</td><td>0.0</td></tr><tr><td>42.0</td><td> There are people who do that , and I support that .</td><td> There are people who do that , and I support that .</td><td>45.0</td><td>0.0</td></tr><tr><td>43.0</td><td>I can be most helpful pushing around policy changes , structural changes and helping to make sure the story we tell is consistent with the world we re trying to build .</td><td>I can be most helpful pushing around policy changes , structural changes and helping to make sure the story we tell is consistent with the world we re trying to build .</td><td>46.0</td><td>2.6365956967357695e-08</td></tr><tr><td>44.0</td><td> In Minneapolis , some local activist groups have led rallies on the South Side , where Mr. Floyd was killed .</td><td> In Minneapolis , some local activist groups have led rallies on the South Side , where Mr. Floyd was killed .</td><td>47.0</td><td>0.0</td></tr><tr><td>45.0</td><td>They have set up tables with fliers <span style=\"background-color:rgba(255,0,0,0.3)\">and</span> <span style=\"background-color:rgba(255,0,0,0.3)\">also</span>    handed out water and other things to keep the people at rallies comfortable .</td><td>They have set up tables with fliers   <span style=\"background-color:rgba(0,255,0,0.3)\">as </span> <span style=\"background-color:rgba(0,255,0,0.3)\">well </span> <span style=\"background-color:rgba(0,255,0,0.3)\">as </span> handed out water and other things to keep the people at rallies comfortable .</td><td>48.0</td><td>0.17110351923047604</td></tr><tr><td>46.0</td><td>But young residents , unaffiliated with particular organizations , have led a more spontaneous uprising , said Mr. Griffin , a senior organizer with Community Change , a national activist group .</td><td>But young residents , unaffiliated with particular organizations , have led a more spontaneous uprising , said Mr. Griffin , a senior organizer with Community Change , a national activist group .</td><td>49.0</td><td>0.0</td></tr><tr><td>47.0</td><td>Even the Black Lives Matter network had public meetings and agendas and a decision - making structure , he said .</td><td>Even the Black Lives Matter network had public meetings and agendas and a decision - making structure , he said .</td><td>50.0</td><td>0.0</td></tr><tr><td>48.0</td><td>Now <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> there is  an army of young people who are more fired up , more pissed off , more ready to be in your face to fix this system than we were five years ago     .</td><td>Now  there is  an army of young people who are more fired up , more pissed off , more ready to be in your face to fix this system than we were five years ago <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">he </span> <span style=\"background-color:rgba(0,255,0,0.3)\">added </span> .</td><td>51.0</td><td>0.18217232438222775</td></tr><tr><td>49.0</td><td><span style=\"background-color:rgba(255,0,0,0.3)\"></span> Carol Becker , a longtime Minneapolis resident , took her 13-year - old to witness some of the demonstrations earlier in the week while there was still light out and things were under control .</td><td> Carol Becker , a longtime Minneapolis resident , took her 13-year - old to witness some of the demonstrations earlier in the week while there was still light out and things were under control .</td><td>52.0</td><td>0.19866342893717304</td></tr><tr><td>50.0</td><td>She supported the protests because she believed that the officers were  absolutely wrong ,  she said .</td><td>She supported the protests because she believed that the officers were  absolutely wrong ,  she said .</td><td>53.0</td><td>0.0</td></tr><tr><td>51.0</td><td>But by nightfall , with unrest giving way to tear gas , rubber bullets , and burned and looted businesses , she found herself standing in front of her father s apartment building , fending off people trying to set it on fire , she said .</td><td>But by nightfall , with unrest giving way to tear gas , rubber bullets , and burned and looted businesses , she found herself standing in front of her father s apartment building , fending off people trying to set it on fire , she said .</td><td>54.0</td><td>0.0</td></tr><tr><td>52.0</td><td> There were protesters at the police precinct ,  she said .</td><td> There were protesters at the police precinct ,  she said .</td><td>55.0</td><td>0.0</td></tr><tr><td>53.0</td><td> When you got even a block away , there were nt protesters anymore .</td><td> When you got even a block away , there were nt protesters anymore .</td><td>56.0</td><td>0.0</td></tr><tr><td>54.0</td><td>These people were nt protesting .</td><td>These people were nt protesting .</td><td>57.0</td><td>0.0</td></tr><tr><td>55.0</td><td>They were breaking into things and taking things .</td><td>They were breaking into things and taking things .</td><td>58.0</td><td>0.0</td></tr><tr><td>56.0</td><td> Minneapolis has a core group of anarchists , residents say , describing them as white activists of the Occupy Wall Street mold , challenging the moneyed elite in a city with a high concentration of Fortune 500 companies .</td><td> Minneapolis has a core group of anarchists , residents say , describing them as white activists of the Occupy Wall Street mold , challenging the moneyed elite in a city with a high concentration of Fortune 500 companies .</td><td>59.0</td><td>0.0</td></tr><tr><td>57.0</td><td>One man in particular has become a focus of those who believe that outsiders could be trying to discredit the protest movement and its goals .</td><td>One man in particular has become a focus of those who believe that outsiders could be trying to discredit the protest movement and its goals .</td><td>60.0</td><td>0.0</td></tr><tr><td>58.0</td><td>Dressed in all black , with a black gas mask and carrying a black umbrella ,  Umbrella Man ,  who appears to be white if otherwise unidentifiable , was filmed breaking windows at an AutoZone store .</td><td>Dressed in all black , with a black gas mask and carrying a black umbrella ,  Umbrella Man ,  who appears to be white if otherwise unidentifiable , was filmed breaking windows at an AutoZone store .</td><td>61.0</td><td>0.0</td></tr><tr><td>59.0</td><td>People sympathetic to the protests continue to view figures like  Umbrella Man  with deep suspicion .</td><td>People sympathetic to the protests continue to view figures like  Umbrella Man  with deep suspicion .</td><td>62.0</td><td>3.1211929901477153e-07</td></tr><tr><td>60.0</td><td> I am well aware there are often people at these rallies who incite violence to discredit those peacefully assembled ,  said Camille Gage , 63 , an artist in Minneapolis who said that the building where she keeps her studio was on fire .</td><td> I am well aware there are often people at these rallies who incite violence to discredit those peacefully assembled ,  said Camille Gage , 63 , an artist in Minneapolis who said that the building where she keeps her studio was on fire .</td><td>63.0</td><td>0.0</td></tr><tr><td>61.0</td><td> I feared there would be an effort by some to use violence and destruction of property at the rally to honor Mr. Floyd , and I was sadly correct .</td><td> I feared there would be an effort by some to use violence and destruction of property at the rally to honor Mr. Floyd , and I was sadly correct .</td><td>64.0</td><td>0.0</td></tr><tr><td>62.0</td><td><span style=\"background-color:rgba(255,0,0,0.3)\"></span> <span style=\"background-color:rgba(255,0,0,0.3)\">But</span> <span style=\"background-color:rgba(255,0,0,0.3)\">some</span> <span style=\"background-color:rgba(255,0,0,0.3)\">said</span> <span style=\"background-color:rgba(255,0,0,0.3)\">the</span> <span style=\"background-color:rgba(255,0,0,0.3)\">destruction</span> <span style=\"background-color:rgba(255,0,0,0.3)\">was</span> <span style=\"background-color:rgba(255,0,0,0.3)\">necessary</span> <span style=\"background-color:rgba(255,0,0,0.3)\">.</span></td><td>        </td><td></td><td></td></tr><tr><td>63.0</td><td> We ve tried being peaceful ,  said Rashaad Dinkins , an 18-year - old college student from Minneapolis .</td><td> We ve tried being peaceful ,  said Rashaad Dinkins , an 18-year - old college student from Minneapolis .</td><td>70.0</td><td>6.035190606897309e-08</td></tr><tr><td>64.0</td><td> We ve tried doing the kneeling and the silence for so long , and we get criticized for even doing that .</td><td> We ve tried doing the kneeling and the silence for so long , and we get criticized for even doing that .</td><td>71.0</td><td>0.0</td></tr><tr><td>65.0</td><td>  This is what needs to be done for the world to pay attention ,  his friend , Amra Zahirovic , added .</td><td>  This is what needs to be done for the world to pay attention ,  his friend , Amra Zahirovic , added .</td><td>72.0</td><td>2.862999694496372e-08</td></tr><tr><td>66.0</td><td> People have had enough .</td><td> People have had enough .</td><td>73.0</td><td>3.017000240920418e-07</td></tr><tr><td>67.0</td><td> It is impossible to manage and control a group as varied and eclectic as those who have shown up at the protest scene in Minneapolis : a 40-year - old black mother of three who had joined her boss , a 21-year - old white woman , to pay homage before their shifts started at a Little Caesars pizza place in the suburbs ;</td><td> It is impossible to manage and control a group as varied and eclectic as those who have shown up at the protest scene in Minneapolis : a 40-year - old black mother of three who had joined her boss , a 21-year - old white woman , to pay homage before their shifts started at a Little Caesars pizza place in the suburbs ;</td><td>74.0</td><td>0.0</td></tr><tr><td>68.0</td><td>a couple of Green Party members who were helping with donations at the first - aid station at Holy Trinity Lutheran Church ;</td><td>a couple of Green Party members who were helping with donations at the first - aid station at Holy Trinity Lutheran Church ;</td><td>75.0</td><td>0.0</td></tr><tr><td>69.0</td><td>a trio of young white men dressed in headgear and goggles who appeared ready for battle .</td><td>a trio of young white men dressed in headgear and goggles who appeared ready for battle .</td><td>76.0</td><td>4.811373870390599e-07</td></tr><tr><td>70.0</td><td> Cub is my grocery store ;</td><td> Cub is my grocery store ;</td><td>77.0</td><td>0.0</td></tr><tr><td>71.0</td><td>I eat here and it s trashed ,  said Johnnie Green , 54 , who lives about four blocks away .</td><td>I eat here and it s trashed ,  said Johnnie Green , 54 , who lives about four blocks away .</td><td>78.0</td><td>0.0</td></tr><tr><td>72.0</td><td>He studied the graffiti and destruction , considering where he may have to go for groceries now .</td><td>He studied the graffiti and destruction , considering where he may have to go for groceries now .</td><td>79.0</td><td>5.256542942780613e-07</td></tr><tr><td>73.0</td><td> I m an optimistic person , but I ve never seen this in Minneapolis ,  he said , remarking on how friendly and diverse he found the neighborhood .</td><td> I m an optimistic person , but I ve never seen this in Minneapolis ,  he said , remarking on how friendly and diverse he found the neighborhood .</td><td>80.0</td><td>0.0</td></tr><tr><td>74.0</td><td>But he understood where the anger came from .</td><td>But he understood where the anger came from .</td><td>81.0</td><td>0.0</td></tr><tr><td>75.0</td><td> The police never stand up for us ,  Mr. Green said , sipping on a beer .</td><td> The police never stand up for us ,  Mr. Green said , sipping on a beer .</td><td>82.0</td><td>0.0</td></tr><tr><td>76.0</td><td> With the Covid pandemic people are hungry and homeless .</td><td> With the Covid pandemic people are hungry and homeless .</td><td>83.0</td><td>5.110015453465274e-07</td></tr><tr><td>77.0</td><td>With no job , what do you expect ?</td><td>With no job , what do you expect ?</td><td>84.0</td><td>0.0</td></tr><tr><td>78.0</td><td>I think that s going to happen to masses of people across this country .</td><td>I think that s going to happen to masses of people across this country .</td><td>85.0</td><td>0.0</td></tr><tr><td>79.0</td><td>We could reach the point that it s civil war .</td><td>We could reach the point that it s civil war .</td><td>86.0</td><td>0.0</td></tr><tr><td>80.0</td><td> Still , in city <span style=\"background-color:rgba(255,0,0,0.3)\">,</span> after city , people turned out ,    hoping for the best .</td><td> Still , in city  after city , people turned out , <span style=\"background-color:rgba(0,255,0,0.3)\">most </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> <span style=\"background-color:rgba(0,255,0,0.3)\">them </span> hoping for the best .</td><td>87.0</td><td>0.23663726656442277</td></tr><tr><td>81.0</td><td> I m here for peace ,  said Kenny Washington , 39 , of northeast Minneapolis who came out with her newly minted college freshman son , Trenton Washington , 19 , after some rest from the exhausting first night of protest .</td><td> I m here for peace ,  said Kenny Washington , 39 , of northeast Minneapolis who came out with her newly minted college freshman son , Trenton Washington , 19 , after some rest from the exhausting first night of protest .</td><td>88.0</td><td>0.0</td></tr><tr><td>82.0</td><td> Destruction is only going to bring chaos .</td><td> Destruction is only going to bring chaos .</td><td>89.0</td><td>0.0</td></tr><tr><td>83.0</td><td>People want to bring change , and we came back to give peace another chance .</td><td>People want to bring change , and we came back to give peace another chance .</td><td>90.0</td><td>5.944268980727762e-07</td></tr><tr><td>84.0</td><td> John Eligon and Matt Furber reported from Minneapolis  and Campbell Robertson from Pittsburgh .</td><td> John Eligon and Matt Furber reported from Minneapolis <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> and Campbell Robertson from Pittsburgh .</td><td>91.0</td><td>0.10934600647885702</td></tr><tr><td></td><td>                                                                             </td><td><span style=\"background-color:rgba(0,255,0,0.3)\">But </span> <span style=\"background-color:rgba(0,255,0,0.3)\">if </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">scene </span> <span style=\"background-color:rgba(0,255,0,0.3)\">on </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Thursday </span> <span style=\"background-color:rgba(0,255,0,0.3)\">felt </span> <span style=\"background-color:rgba(0,255,0,0.3)\">like </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">victory </span> <span style=\"background-color:rgba(0,255,0,0.3)\">for </span> <span style=\"background-color:rgba(0,255,0,0.3)\">some </span> <span style=\"background-color:rgba(0,255,0,0.3)\">protesters </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">escalating </span> <span style=\"background-color:rgba(0,255,0,0.3)\">violence </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">destruction </span> <span style=\"background-color:rgba(0,255,0,0.3)\">that </span> <span style=\"background-color:rgba(0,255,0,0.3)\">spread </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Friday </span> <span style=\"background-color:rgba(0,255,0,0.3)\">in </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Minneapolis </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">elsewhere </span> <span style=\"background-color:rgba(0,255,0,0.3)\">around </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">country </span> <span style=\"background-color:rgba(0,255,0,0.3)\">felt </span> <span style=\"background-color:rgba(0,255,0,0.3)\">more </span> <span style=\"background-color:rgba(0,255,0,0.3)\">like </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">warning </span> <span style=\"background-color:rgba(0,255,0,0.3)\">that </span> <span style=\"background-color:rgba(0,255,0,0.3)\">this </span> <span style=\"background-color:rgba(0,255,0,0.3)\">moment </span> <span style=\"background-color:rgba(0,255,0,0.3)\">could </span> <span style=\"background-color:rgba(0,255,0,0.3)\">be </span> <span style=\"background-color:rgba(0,255,0,0.3)\">spinning </span> <span style=\"background-color:rgba(0,255,0,0.3)\">out </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> <span style=\"background-color:rgba(0,255,0,0.3)\">control </span> <span style=\"background-color:rgba(0,255,0,0.3)\">both </span> <span style=\"background-color:rgba(0,255,0,0.3)\">because </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">limitations </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">largely </span> <span style=\"background-color:rgba(0,255,0,0.3)\">spontaneous </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">leaderless </span> <span style=\"background-color:rgba(0,255,0,0.3)\">movement </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">because </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">protesters </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">officials </span> <span style=\"background-color:rgba(0,255,0,0.3)\">warned </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">there </span> <span style=\"background-color:rgba(0,255,0,0.3)\">were </span> <span style=\"background-color:rgba(0,255,0,0.3)\">indications </span> <span style=\"background-color:rgba(0,255,0,0.3)\">it </span> <span style=\"background-color:rgba(0,255,0,0.3)\">was </span> <span style=\"background-color:rgba(0,255,0,0.3)\">also </span> <span style=\"background-color:rgba(0,255,0,0.3)\">being </span> <span style=\"background-color:rgba(0,255,0,0.3)\">undermined </span> <span style=\"background-color:rgba(0,255,0,0.3)\">by </span> <span style=\"background-color:rgba(0,255,0,0.3)\">agitators </span> <span style=\"background-color:rgba(0,255,0,0.3)\">trying </span> <span style=\"background-color:rgba(0,255,0,0.3)\">to </span> <span style=\"background-color:rgba(0,255,0,0.3)\">sabotage </span> <span style=\"background-color:rgba(0,255,0,0.3)\">it </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>4.0</td><td></td></tr><tr><td></td><td>               </td><td><span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">I </span> <span style=\"background-color:rgba(0,255,0,0.3)\">need </span> <span style=\"background-color:rgba(0,255,0,0.3)\">those </span> <span style=\"background-color:rgba(0,255,0,0.3)\">legitimate </span> <span style=\"background-color:rgba(0,255,0,0.3)\">folks </span> <span style=\"background-color:rgba(0,255,0,0.3)\">who </span> <span style=\"background-color:rgba(0,255,0,0.3)\">are </span> <span style=\"background-color:rgba(0,255,0,0.3)\">grieving </span> <span style=\"background-color:rgba(0,255,0,0.3)\">to </span> <span style=\"background-color:rgba(0,255,0,0.3)\">take </span> <span style=\"background-color:rgba(0,255,0,0.3)\">this </span> <span style=\"background-color:rgba(0,255,0,0.3)\">back </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Gov. </span></td><td>5.0</td><td></td></tr><tr><td></td><td>                       </td><td><span style=\"background-color:rgba(0,255,0,0.3)\">Tim </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Walz </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Minnesota </span> <span style=\"background-color:rgba(0,255,0,0.3)\">said </span> <span style=\"background-color:rgba(0,255,0,0.3)\">at </span> <span style=\"background-color:rgba(0,255,0,0.3)\">an </span> <span style=\"background-color:rgba(0,255,0,0.3)\">early </span> <span style=\"background-color:rgba(0,255,0,0.3)\">morning </span> <span style=\"background-color:rgba(0,255,0,0.3)\">news </span> <span style=\"background-color:rgba(0,255,0,0.3)\">conference </span> <span style=\"background-color:rgba(0,255,0,0.3)\">as </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">bank </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">gas </span> <span style=\"background-color:rgba(0,255,0,0.3)\">station </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">several </span> <span style=\"background-color:rgba(0,255,0,0.3)\">other </span> <span style=\"background-color:rgba(0,255,0,0.3)\">buildings </span> <span style=\"background-color:rgba(0,255,0,0.3)\">burned </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>6.0</td><td></td></tr><tr><td></td><td>                                                   </td><td><span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Why </span> <span style=\"background-color:rgba(0,255,0,0.3)\">are </span> <span style=\"background-color:rgba(0,255,0,0.3)\">we </span> <span style=\"background-color:rgba(0,255,0,0.3)\">talking </span> <span style=\"background-color:rgba(0,255,0,0.3)\">about </span> <span style=\"background-color:rgba(0,255,0,0.3)\">anarchists </span> <span style=\"background-color:rgba(0,255,0,0.3)\">who </span> <span style=\"background-color:rgba(0,255,0,0.3)\">are </span> <span style=\"background-color:rgba(0,255,0,0.3)\">burning </span> <span style=\"background-color:rgba(0,255,0,0.3)\">down </span> <span style=\"background-color:rgba(0,255,0,0.3)\">damn </span> <span style=\"background-color:rgba(0,255,0,0.3)\">buildings </span> <span style=\"background-color:rgba(0,255,0,0.3)\">? </span> <span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">And </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">beyond </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">chaos </span> <span style=\"background-color:rgba(0,255,0,0.3)\">in </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Minneapolis </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">there </span> <span style=\"background-color:rgba(0,255,0,0.3)\">were </span> <span style=\"background-color:rgba(0,255,0,0.3)\">widespread </span> <span style=\"background-color:rgba(0,255,0,0.3)\">fears </span> <span style=\"background-color:rgba(0,255,0,0.3)\">that </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">movement </span> <span style=\"background-color:rgba(0,255,0,0.3)\">protesting </span> <span style=\"background-color:rgba(0,255,0,0.3)\">police </span> <span style=\"background-color:rgba(0,255,0,0.3)\">violence </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">systemic </span> <span style=\"background-color:rgba(0,255,0,0.3)\">racism </span> <span style=\"background-color:rgba(0,255,0,0.3)\">was </span> <span style=\"background-color:rgba(0,255,0,0.3)\">instead </span> <span style=\"background-color:rgba(0,255,0,0.3)\">being </span> <span style=\"background-color:rgba(0,255,0,0.3)\">subverted </span> <span style=\"background-color:rgba(0,255,0,0.3)\">by </span> <span style=\"background-color:rgba(0,255,0,0.3)\">images </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> <span style=\"background-color:rgba(0,255,0,0.3)\">violence </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">chaos </span> <span style=\"background-color:rgba(0,255,0,0.3)\">playing </span> <span style=\"background-color:rgba(0,255,0,0.3)\">out </span> <span style=\"background-color:rgba(0,255,0,0.3)\">around </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">country </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>7.0</td><td></td></tr><tr><td></td><td>            </td><td><span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">But </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">result </span> <span style=\"background-color:rgba(0,255,0,0.3)\">from </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">start </span> <span style=\"background-color:rgba(0,255,0,0.3)\">has </span> <span style=\"background-color:rgba(0,255,0,0.3)\">drawn </span> <span style=\"background-color:rgba(0,255,0,0.3)\">wildly </span> <span style=\"background-color:rgba(0,255,0,0.3)\">diverse </span> <span style=\"background-color:rgba(0,255,0,0.3)\">participants </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>11.0</td><td></td></tr><tr><td></td><td>                   </td><td><span style=\"background-color:rgba(0,255,0,0.3)\">Organizers </span> <span style=\"background-color:rgba(0,255,0,0.3)\">have </span> <span style=\"background-color:rgba(0,255,0,0.3)\">been </span> <span style=\"background-color:rgba(0,255,0,0.3)\">trying </span> <span style=\"background-color:rgba(0,255,0,0.3)\">to </span> <span style=\"background-color:rgba(0,255,0,0.3)\">keep </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">focus </span> <span style=\"background-color:rgba(0,255,0,0.3)\">on </span> <span style=\"background-color:rgba(0,255,0,0.3)\">police </span> <span style=\"background-color:rgba(0,255,0,0.3)\">accountability </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">social </span> <span style=\"background-color:rgba(0,255,0,0.3)\">justice </span> <span style=\"background-color:rgba(0,255,0,0.3)\">issues </span> <span style=\"background-color:rgba(0,255,0,0.3)\">through </span> <span style=\"background-color:rgba(0,255,0,0.3)\">chanting </span> <span style=\"background-color:rgba(0,255,0,0.3)\">and </span> <span style=\"background-color:rgba(0,255,0,0.3)\">marching </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>12.0</td><td></td></tr><tr><td></td><td>             </td><td><span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">But </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">chaos </span> <span style=\"background-color:rgba(0,255,0,0.3)\">unfolding </span> <span style=\"background-color:rgba(0,255,0,0.3)\">threatens </span> <span style=\"background-color:rgba(0,255,0,0.3)\">to </span> <span style=\"background-color:rgba(0,255,0,0.3)\">send </span> <span style=\"background-color:rgba(0,255,0,0.3)\">out </span> <span style=\"background-color:rgba(0,255,0,0.3)\">an </span> <span style=\"background-color:rgba(0,255,0,0.3)\">entirely </span> <span style=\"background-color:rgba(0,255,0,0.3)\">different </span> <span style=\"background-color:rgba(0,255,0,0.3)\">message </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>24.0</td><td></td></tr><tr><td></td><td>                 </td><td><span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">And </span> <span style=\"background-color:rgba(0,255,0,0.3)\">others </span> <span style=\"background-color:rgba(0,255,0,0.3)\">warned </span> <span style=\"background-color:rgba(0,255,0,0.3)\">that </span> <span style=\"background-color:rgba(0,255,0,0.3)\">other </span> <span style=\"background-color:rgba(0,255,0,0.3)\">agitators </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">largely </span> <span style=\"background-color:rgba(0,255,0,0.3)\">white </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">were </span> <span style=\"background-color:rgba(0,255,0,0.3)\">trying </span> <span style=\"background-color:rgba(0,255,0,0.3)\">to </span> <span style=\"background-color:rgba(0,255,0,0.3)\">undermine </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">protests </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>65.0</td><td></td></tr><tr><td></td><td>                                      </td><td><span style=\"background-color:rgba(0,255,0,0.3)\">Jeremiah </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Ellison </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Minneapolis </span> <span style=\"background-color:rgba(0,255,0,0.3)\">city </span> <span style=\"background-color:rgba(0,255,0,0.3)\">councilman </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\">tweeted </span> <span style=\"background-color:rgba(0,255,0,0.3)\">that </span> <span style=\"background-color:rgba(0,255,0,0.3)\">community </span> <span style=\"background-color:rgba(0,255,0,0.3)\">members </span> <span style=\"background-color:rgba(0,255,0,0.3)\">told </span> <span style=\"background-color:rgba(0,255,0,0.3)\">him </span> <span style=\"background-color:rgba(0,255,0,0.3)\">that </span> <span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">three </span> <span style=\"background-color:rgba(0,255,0,0.3)\">suspicious </span> <span style=\"background-color:rgba(0,255,0,0.3)\">white </span> <span style=\"background-color:rgba(0,255,0,0.3)\">men </span> <span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">started </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">fire </span> <span style=\"background-color:rgba(0,255,0,0.3)\">at </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">well </span> <span style=\"background-color:rgba(0,255,0,0.3)\">- </span> <span style=\"background-color:rgba(0,255,0,0.3)\">known </span> <span style=\"background-color:rgba(0,255,0,0.3)\">barbershop </span> <span style=\"background-color:rgba(0,255,0,0.3)\">on </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">city </span> <span style=\"background-color:rgba(0,255,0,0.3)\">s </span> <span style=\"background-color:rgba(0,255,0,0.3)\">predominantly </span> <span style=\"background-color:rgba(0,255,0,0.3)\">black </span> <span style=\"background-color:rgba(0,255,0,0.3)\">North </span> <span style=\"background-color:rgba(0,255,0,0.3)\">Side </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>66.0</td><td></td></tr><tr><td></td><td>                   </td><td><span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">I </span> <span style=\"background-color:rgba(0,255,0,0.3)\">have </span> <span style=\"background-color:rgba(0,255,0,0.3)\">a </span> <span style=\"background-color:rgba(0,255,0,0.3)\">hard </span> <span style=\"background-color:rgba(0,255,0,0.3)\">time </span> <span style=\"background-color:rgba(0,255,0,0.3)\">believing </span> <span style=\"background-color:rgba(0,255,0,0.3)\">ANYONE </span> <span style=\"background-color:rgba(0,255,0,0.3)\">who </span> <span style=\"background-color:rgba(0,255,0,0.3)\">lives </span> <span style=\"background-color:rgba(0,255,0,0.3)\">here </span> <span style=\"background-color:rgba(0,255,0,0.3)\">would </span> <span style=\"background-color:rgba(0,255,0,0.3)\">set </span> <span style=\"background-color:rgba(0,255,0,0.3)\">it </span> <span style=\"background-color:rgba(0,255,0,0.3)\">ablaze </span> <span style=\"background-color:rgba(0,255,0,0.3)\">, </span> <span style=\"background-color:rgba(0,255,0,0.3)\"> </span> <span style=\"background-color:rgba(0,255,0,0.3)\">he </span> <span style=\"background-color:rgba(0,255,0,0.3)\">wrote </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>68.0</td><td></td></tr><tr><td></td><td>           </td><td><span style=\"background-color:rgba(0,255,0,0.3)\">But </span> <span style=\"background-color:rgba(0,255,0,0.3)\">not </span> <span style=\"background-color:rgba(0,255,0,0.3)\">all </span> <span style=\"background-color:rgba(0,255,0,0.3)\">protesters </span> <span style=\"background-color:rgba(0,255,0,0.3)\">were </span> <span style=\"background-color:rgba(0,255,0,0.3)\">unhappy </span> <span style=\"background-color:rgba(0,255,0,0.3)\">with </span> <span style=\"background-color:rgba(0,255,0,0.3)\">some </span> <span style=\"background-color:rgba(0,255,0,0.3)\">of </span> <span style=\"background-color:rgba(0,255,0,0.3)\">the </span> <span style=\"background-color:rgba(0,255,0,0.3)\">destruction </span> <span style=\"background-color:rgba(0,255,0,0.3)\">. </span></td><td>69.0</td><td></td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_output))\n",
    "# 38.0\t40.0\t38.0\t41.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloomberg.ai.logtools.dsp_logger import setup_logger\n",
    "import logging\n",
    "hdfs_log_dir = \"hdfs:///groups/ai_yourteam/job_logs/\"\n",
    "setup_logger(hdfs_location=hdfs_log_dir, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Biggest factor is the hash-bucket size!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## num articles = 2, num rows = 34, num partitions = 1000\n",
    "## ----------------------------------------------------------------------------------\n",
    "## spark_processed_df.toPandas(): 5s, no memory swapped\n",
    "## exploded_df.toPandas(): 5s, 63 MB swapped\n",
    "## \n",
    "## ----------------------------------------------------------------------------------\n",
    "## repartition similarity_sdf (pre- word_pair_matched_sdf)\n",
    "## >>> word_pair_matched_sdf.toPandas()\n",
    "## without version repartition, next step swaps   READ: 1677.2 MB, WRITE: 1865.6 MB\n",
    "## without sent_idx repartition, next step swaps  READ: 1673.8 MB, WRITE: 1865.6 MB\n",
    "## without word_idx repartition, next step swaps  READ: 1677.2 MB, WRITE: 1865.6 MB\n",
    "## with word_idx repartition, next step swaps     READ: 1768.6 MB, WRITE: 1865.6 MB\n",
    "## ----------------------------------------------------------------------------------\n",
    "## repartition word_pair_matched_sdf\n",
    "## >>> word_pair_matched_sdf.toPandas()\n",
    "##\n",
    "## \n",
    "## without word_idx_x, word_idx_y READ: 1865.6 MB WRITE: 8.0 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(spark.sparkContext)\n",
    "explode_sent = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT entry_id, version, sent_idx \n",
    "         FROM (\n",
    "             SELECT entry_id, version, POSEXPLODE(sentences) AS (sent_idx, sentence)\n",
    "             FROM __THIS__\n",
    "         )\n",
    "    \"\"\")\n",
    ")\n",
    "sent_idx_sdf = explode_sent.transform(init_sdf)\n",
    "min_sent_df_x.registerTempTable(\"matchedSentencesX\")\n",
    "sent_idx_sdf.registerTempTable(\"Sentences\")\n",
    "missing_y_df = sqlContext.sql(\"\"\"\n",
    "    SELECT entry_id, version, full_sent_idx as unmatched_sent_idx\n",
    "    FROM (\n",
    "        SELECT s.entry_id as entry_id, \n",
    "               s.version AS version, \n",
    "               s.sent_idx as full_sent_idx,\n",
    "               m.sent_idx_y as matched_sent_idx\n",
    "        FROM matchedSentencesX m\n",
    "        FULL OUTER JOIN Sentences s\n",
    "        ON s.entry_id = m.entry_id\n",
    "        AND s.version = m.version_y\n",
    "        AND s.sent_idx = m.sent_idx_y\n",
    "    ) where matched_sent_idx is NULL\n",
    "\"\"\").toPandas()\n",
    "\n",
    "min_sent_dfp.merge(sent_idx_sdfp, \n",
    "                   left_on=['entry_id', 'version_y',  'sent_idx_y'],\n",
    "                   right_on=['entry_id', 'version', 'sent_idx'],\n",
    "                   how='right'\n",
    "                  ).loc[lambda df: df['sent_idx_y'].isnull()]\n",
    "\n",
    "get_missing_y = (\n",
    "    SQLTransformer()\n",
    "        .set_statement(\"\"\"\n",
    "            SELECT entry_id,\n",
    "                version_y,\n",
    "                sent_idx_y\n",
    "        \n",
    "        \"\"\")\n",
    ")\n",
    "\n",
    "y_matches = sb.PipelineModel(stages=[])\n",
    "\n",
    "min_sent_df_x = top_sentence_pipeline_x.transform(joined_df)\n",
    "# min_sent_dfp = min_sent_df.toPandas()\n",
    "sent_idx_sdfp = sent_idx_sdf.toPandas()\n",
    "sent_idx_sdfp.head()\n",
    "sent_idx_sdfp.shape\n",
    "\n",
    "def cosine_distance(x, y):\n",
    "    return float(distance.cosine(x, y))\n",
    "spark.udf.register(\"cosine_distance\", cosine_distance, \"float\")\n",
    "\n",
    "inner_join = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT word_emb.entry_id                                                    AS entry_id, \n",
    "                 word_emb.version                                                    AS version_x,\n",
    "                 word_emb_2.version                                                  AS version_y,\n",
    "                 word_emb.sent_idx                                                   AS sent_idx_x,\n",
    "                 word_emb_2.sent_idx                                                 AS sent_idx_y,\n",
    "                 word_emb.num_words                                                  AS num_words_x,\n",
    "                 word_emb.word_idx                                                   AS word_idx_x,\n",
    "                 word_emb_2.word_idx                                                 AS word_idx_y,\n",
    "                 word_emb.token                                                      AS token_x,\n",
    "                 word_emb_2.token                                                    AS token_y,\n",
    "                 cosine_distance(word_emb.word_embedding, word_emb_2.word_embedding) AS cosine_distance\n",
    "         FROM __THIS__ word_emb\n",
    "         JOIN __THIS__ word_emb_2\n",
    "         ON word_emb.entry_id = word_emb_2.entry_id and\n",
    "         word_emb.version + 1 = word_emb_2.version\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "## todo:\n",
    "## -----------------------------------------------------------------------------------------------------------------\n",
    "## 1. Determine mapping cutoff to differentiate similar and dissimilar sentences (probably .4)\n",
    "##\n",
    "## 2. Implement algorithm:\n",
    "## \n",
    "## a. for all x with distance > .4, drop y\n",
    "## b. for all y without a label, do the sentence match in reverse\n",
    "## c. for all y with a distance > .4, drop x\n",
    "\n",
    "import numpy as np \n",
    "(min_sent_dfp\n",
    " .assign(sent_idx_y = lambda df: df.apply(lambda x: x['sent_idx_y'] if x['avg_sentence_distance'] < .44 else np.nan, axis=1))\n",
    ")\n",
    "\n",
    "min_sent_dfp['avg_sentence_distance'].hist(bins=50)\n",
    "min_sent_dfp['avg_sentence_distance'].hist(bins=50)#, range=(0, 20))\n",
    "min_sent_dfp = min_sent_dfp.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])\n",
    "final_df_3_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if the approximation is the same as the full inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist_inner_join = word_emb_sdfp.groupby([\n",
    "    'entry_id',\n",
    "    'version_x',\n",
    "    'version_y',\n",
    "    'sent_idx_x',\n",
    "    'sent_idx_y',\n",
    "    'word_idx_x',\n",
    "    'token_x',\n",
    "])['cosine_distance'].min()\n",
    "\n",
    "min_dist_inner_join.shape\n",
    "\n",
    "min_dist_approx = joined_dfp.groupby([\n",
    "    'entry_id',\n",
    "    'version_x',\n",
    "    'version_y',\n",
    "    'sent_idx_x',\n",
    "    'sent_idx_y',\n",
    "    'word_idx_x',\n",
    "    'num_words',\n",
    "    'token_x',\n",
    "])['distance'].min()\n",
    "\n",
    "joined_dfp[['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y', 'num_words']].drop_duplicates()['num_words'].sum()\n",
    "\n",
    "min_full = (word_emb_sdfp\n",
    " ## get max words\n",
    " .loc[lambda df: df.groupby(['entry_id', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['cosine_distance'].idxmin()]#[des_col_list]\n",
    " ## get mean of sentence\n",
    " .groupby(['entry_id', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'])['cosine_distance'].mean().reset_index()\n",
    " ## get max sentence\n",
    " .loc[lambda df: df.groupby(['entry_id', 'version_x', 'sent_idx_x', 'version_y'])['cosine_distance'].idxmin()]\n",
    ")\n",
    "\n",
    "min_approx = (joined_dfp\n",
    " ## get max words\n",
    " .loc[lambda df: df.groupby(['entry_id', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['distance'].idxmin()]#[des_col_list]\n",
    " ## get mean of sentence\n",
    " .groupby(['entry_id', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'])['distance'].mean().reset_index()\n",
    " ## get max sentence\n",
    " .loc[lambda df: df.groupby(['entry_id', 'version_x', 'sent_idx_x', 'version_y'])['distance'].idxmin()]\n",
    ")\n",
    "\n",
    "(min_full.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['sent_idx_x'].values\n",
    "== min_approx.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['sent_idx_x'].values)\n",
    "\n",
    "(min_full.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['sent_idx_y'].values\n",
    "== min_approx.sort_values(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['sent_idx_y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf = word_emb_sdf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf = word_emb_sdf.repartition('entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y')#, 'word_idx_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_sdf = get_max_word_min.transform(word_emb_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import spark_partition_id, asc, desc\n",
    "partitions = (\n",
    "    word_emb_sdf\n",
    "        .withColumn(\"partitionId\", spark_partition_id())\n",
    "        .groupBy(\"partitionId\")\n",
    "        .count()\n",
    "        .orderBy(asc(\"count\"))\n",
    "        .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755380"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+----------+----------+----------+--------------------+\n",
      "|entry_id|version_x|version_y|sent_idx_x|sent_idx_y|word_idx_x|min(cosine_distance)|\n",
      "+--------+---------+---------+----------+----------+----------+--------------------+\n",
      "|  547991|        2|        3|         0|        23|         0|          0.45366806|\n",
      "|  547991|        2|        3|         0|        23|         1|          0.31662515|\n",
      "|  547991|        2|        3|         0|        23|         2|          0.32143697|\n",
      "|  547991|        2|        3|         0|        23|         3|          0.32374802|\n",
      "|  547991|        2|        3|         0|        23|         4|          0.34763005|\n",
      "|  547991|        2|        3|         0|        23|         5|           0.3871965|\n",
      "|  547991|        2|        3|         0|        23|         6|          0.33349082|\n",
      "|  547991|        2|        3|         0|        23|         7|          0.40576532|\n",
      "|  547991|        2|        3|         0|        23|         8|           0.3442957|\n",
      "|  547991|        2|        3|         0|        23|         9|          0.39317727|\n",
      "|  547991|        2|        3|         0|        23|        10|          0.42770043|\n",
      "|  547991|        2|        3|         0|        23|        11|           0.5083151|\n",
      "|  547991|        2|        3|         0|        23|        12|          0.42195985|\n",
      "|  547991|        2|        3|         0|        23|        13|          0.31820232|\n",
      "|  547991|        2|        3|         0|        23|        14|           0.4619458|\n",
      "|  547991|        2|        3|         0|        23|        15|          0.36894196|\n",
      "|  547991|        2|        3|         0|        23|        16|          0.35431597|\n",
      "|  547991|        2|        3|         0|        23|        17|            0.537521|\n",
      "|  547991|        2|        3|         0|        23|        18|          0.38610688|\n",
      "|  547991|        2|        3|         0|        23|        19|           0.3644004|\n",
      "+--------+---------+---------+----------+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_emb_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: calculate num words per sentence.\n",
    "## set a filter threshold to filter out any cosine distances that as > .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_emb_sdf.write.mode(\"overwrite\").parquet(\"s3://aspangher/tmp/tmp_bert_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_word_rn = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT *\n",
    "         FROM (SELECT *, ROW_NUMBER() OVER (\n",
    "                         PARTITION BY entry_id, \n",
    "                                      version_x, \n",
    "                                      version_y, \n",
    "                                      sent_idx_x, \n",
    "                                      sent_idx_y, \n",
    "                                      word_idx_x, \n",
    "                                      token_x \n",
    "                                      ORDER BY cosine_distance ASC\n",
    "                                      ) AS rn FROM __THIS__)\n",
    "         where rn = 1\n",
    "    \"\"\")\n",
    ") \n",
    "\n",
    "get_max_word_cross = (\n",
    "    SQLTransformer()\n",
    "     .setStatement(\"\"\"\n",
    "         SELECT t1.token_x FROM __THIS__ AS t1\n",
    "         CROSS APPLY\n",
    "             (select TOP 1 cosine_distance\n",
    "              from __THIS__ t2\n",
    "              WHERE t1.entry_id = t2.entry_id\n",
    "              AND t1.version_x = t2.version_x\n",
    "              AND t1.version_y = t2.version_y\n",
    "              AND t1.sent_idx_x = t2.sent_idx_x\n",
    "              AND t1.sent_idx_y = t2.sent_idx_y\n",
    "              AND t1.word_idx_x = t2.word_idx_x\n",
    "              AND t1.token_x = t2.token_x\n",
    "              order by cosine_distance ASC) as t2\n",
    "      \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(inner_join_df\n",
    " ## get max words\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['dot_product'].idxmax()][des_col_list]\n",
    " ## get mean of sentence\n",
    " .groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'])['dot_product'].mean().reset_index()\n",
    " ## get max sentence\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y'])['dot_product'].idxmax()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, b = np.histogram(inner_join_df['dot_product'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_plot = pd.Series({b_i:c_i for c_i, b_i in zip(c, b[:-1])})\n",
    "hist_plot.plot(kind='bar')\n",
    "plt.xticks(range(len(hist_plot))[::2], list(map(lambda x: round(x, 4), hist_plot.index))[::2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entry_id_x  version_x  sent_idx_x  sent_idx_y  word_idx_x  token_x   \n",
       "547989      0          0           0           0           WASHINGTON       0\n",
       "                                               1                         608\n",
       "                                               2           Weapons       1216\n",
       "Name: dot_product, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inner_join_df\n",
    " .groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])\n",
    " ['dot_product'].idxmax()\n",
    " .head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = (inner_join_df\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'sent_idx_y', 'word_idx_x', 'token_x'])['dot_product'].idxmax()]\n",
    " [des_col_list]\n",
    " .groupby([\n",
    "     'entry_id_x', 'version_x', 'sent_idx_x', 'version_y', 'sent_idx_y'\n",
    " ])['dot_product']\n",
    " .mean()\n",
    " .reset_index()\n",
    " .loc[lambda df: df.groupby(['entry_id_x', 'version_x', 'sent_idx_x', 'version_y'])['dot_product'].idxmax()]\n",
    " .sort_values('sent_idx_x')\n",
    "#  .loc[lambda df: df['sent_idx_x'] != df['sent_idx_y']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sents = []\n",
    "for entry_id, version, text in tqdm(df[['entry_id', 'version', 'summary']].itertuples(index=False), total=len(df)):\n",
    "    num_sents.append({\n",
    "        'entry_id': entry_id,\n",
    "        'version': version,\n",
    "        'num_sents': len(unp.split_sents(text))\n",
    "    })\n",
    "\n",
    "pd.concat([\n",
    "    sent_dfp_dl.groupby(['entry_id', 'version']).apply(lambda df: len(df)).to_frame('dl'),\n",
    "    sent_dfp_nondl.groupby(['entry_id', 'version']).apply(lambda df: len(df)).to_frame('nondl'),\n",
    "    pd.DataFrame(num_sents).set_index(['entry_id', 'version'])['num_sents'].to_frame('spacy')\n",
    "], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                  CONCAT(word_emb.entry_id, '-', \n",
    "#                         word_emb.version, '-',\n",
    "#                         word_emb_2.version, '-',\n",
    "#                         word_emb.sent_idx, '-',\n",
    "#                         word_emb_2.sent_idx, '-',\n",
    "#                         word_emb.word_idx, '-',\n",
    "#                         word_emb_2.word_idx, '-',\n",
    "#                         word_emb.token, '-'\n",
    "#                         )                                                            AS partition_key,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
