{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import ast\n",
    "import pandas as pd \n",
    "import sqlite3\n",
    "import sys\n",
    "sys.path.insert(0, '../util')\n",
    "import util_refactorings as ur\n",
    "from util_label import get_split_and_matched_dfs, label_sentences_add, get_sentence_and_doc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_data = pd.read_csv('../../controlled-sequence-gen/data/doc-edits-large__add-labels.tsv', sep='\\t', header=None)\n",
    "idx = doc_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can't Use Orig Crowdsourcing Data -- Too much is in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../evaluation/data/data-downsampled.json') as f:\n",
    "    balanced_output = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = idx.str.replace('.0', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_idx = (pd.DataFrame(balanced_output)\n",
    " .T.reset_index()['index']\n",
    " .apply(ast.literal_eval)\n",
    " .apply(lambda x: '%s-%s-%s' % (x[0], x[1], x[2]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     267\n",
       "False    133\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_idx.isin(idx).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create New Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "all_output_df = pd.read_pickle('cache/all-short-documents-eval-processed.pkl')\n",
    "count_df = pd.read_csv('../modeling/data/training_data_short_15.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = count_df.set_index(['source', 'entry_id', 'version'])\n",
    "count_df_sums = (\n",
    "    count_df\n",
    "    .assign(num_sents=1)\n",
    "    .assign(refactored_up=lambda df: (df['refactored_label'] < 0).astype(int))\n",
    "    .assign(refactored_down=lambda df: (df['refactored_label'] > 0).astype(int))\n",
    "    .drop(['sent_idx', 'sentence'], axis=1)\n",
    "    .groupby(level=[0, 1, 2])\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "all_output_df_w_counts = pd.merge(\n",
    "    left=count_df_sums.reset_index(),\n",
    "    right=all_output_df.reset_index(),\n",
    "    left_on=['source', 'entry_id', 'version'],\n",
    "    right_on=['source', 'entry_id', 'version_x']\n",
    ").set_index(['source', 'entry_id', 'version_x', 'version_y']).drop(['version'], axis=1)\n",
    "\n",
    "all_output_df_w_counts = (all_output_df_w_counts\n",
    " .loc[lambda df: (df['num_sents'] > 5) & (df['num_sents'] < 10)]\n",
    ")\n",
    "\n",
    "add_above_weights = (\n",
    "    all_output_df_w_counts['add_above_label']\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .pipe(lambda s: 1/s)\n",
    "    .to_frame('add_weight')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "delete_weights = (\n",
    "    all_output_df_w_counts['deleted_label']\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .pipe(lambda s: 1/s)\n",
    "    .to_frame('del_weight')\n",
    "    .reset_index()\n",
    "\n",
    ")\n",
    "\n",
    "refactored_weights = (\n",
    "    all_output_df_w_counts['refactored_up']\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .pipe(lambda s: 1/s)\n",
    "    .to_frame('ref_weight')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "source_weights = (\n",
    "    all_output_df_w_counts\n",
    "    .reset_index()\n",
    "    ['source']\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .pipe(lambda s: 1/s)\n",
    "    .to_frame('source_weight')\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_output_df_w_counts = (all_output_df_w_counts\n",
    " .assign(key=lambda df: \n",
    "         df.reset_index()\n",
    "         .apply(lambda x: '%s-%s-%s' % (x['source'], x['entry_id'], x['version_x']), axis=1)\n",
    "         .values\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>deleted_label</th>\n",
       "      <th>add_above_label</th>\n",
       "      <th>add_below_label</th>\n",
       "      <th>edited_label</th>\n",
       "      <th>unchanged_label</th>\n",
       "      <th>refactored_label</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>refactored_up</th>\n",
       "      <th>refactored_down</th>\n",
       "      <th>nodes</th>\n",
       "      <th>arcs</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ap</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 6, 'sent_idx': 0, 'sentence': 'WA...</td>\n",
       "      <td>[{'version_x': 6, 'version_y': 7, 'sent_idx_x'...</td>\n",
       "      <td>ap-5-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 15, 'sent_idx': 0, 'sentence': 'W...</td>\n",
       "      <td>[{'version_x': 15, 'version_y': 16, 'sent_idx_...</td>\n",
       "      <td>ap-5-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 15, 'sent_idx': 0, 'sentence': 'O...</td>\n",
       "      <td>[{'version_x': 15, 'version_y': 16, 'sent_idx_...</td>\n",
       "      <td>ap-14-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">17</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 13, 'sent_idx': 0, 'sentence': 'O...</td>\n",
       "      <td>[{'version_x': 13, 'version_y': 14, 'sent_idx_...</td>\n",
       "      <td>ap-17-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 14, 'sent_idx': 0, 'sentence': 'O...</td>\n",
       "      <td>[{'version_x': 14, 'version_y': 15, 'sent_idx_...</td>\n",
       "      <td>ap-17-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">wp</th>\n",
       "      <th>1918327</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 0, 'sent_idx': 0, 'sentence': 'TO...</td>\n",
       "      <td>[{'version_x': 0, 'version_y': 1, 'sent_idx_x'...</td>\n",
       "      <td>wp-1918327-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925996</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 0, 'sent_idx': 0, 'sentence': 'Th...</td>\n",
       "      <td>[{'version_x': 0, 'version_y': 1, 'sent_idx_x'...</td>\n",
       "      <td>wp-1925996-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926724</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 0, 'sent_idx': 0, 'sentence': 'Re...</td>\n",
       "      <td>[{'version_x': 0, 'version_y': 1, 'sent_idx_x'...</td>\n",
       "      <td>wp-1926724-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927548</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 0, 'sent_idx': 0, 'sentence': 'Th...</td>\n",
       "      <td>[{'version_x': 0, 'version_y': 1, 'sent_idx_x'...</td>\n",
       "      <td>wp-1927548-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946717</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'version': 0, 'sent_idx': 0, 'sentence': 'Pr...</td>\n",
       "      <td>[{'version_x': 0, 'version_y': 1, 'sent_idx_x'...</td>\n",
       "      <td>wp-1946717-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58252 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     deleted_label  add_above_label  \\\n",
       "source entry_id version_x version_y                                   \n",
       "ap     5        6         7                    4.0              5.0   \n",
       "                15        16                   9.0              0.0   \n",
       "       14       15        16                   8.0              0.0   \n",
       "       17       13        14                   4.0              4.0   \n",
       "                14        15                   8.0              0.0   \n",
       "...                                            ...              ...   \n",
       "wp     1918327  0         1                    0.0              3.0   \n",
       "       1925996  0         1                    0.0              0.0   \n",
       "       1926724  0         1                    5.0              7.0   \n",
       "       1927548  0         1                    5.0              2.0   \n",
       "       1946717  0         1                    0.0              0.0   \n",
       "\n",
       "                                     add_below_label  edited_label  \\\n",
       "source entry_id version_x version_y                                  \n",
       "ap     5        6         7                      5.0           4.0   \n",
       "                15        16                     0.0           0.0   \n",
       "       14       15        16                     7.0           0.0   \n",
       "       17       13        14                     4.0           3.0   \n",
       "                14        15                     8.0           0.0   \n",
       "...                                              ...           ...   \n",
       "wp     1918327  0         1                      3.0           2.0   \n",
       "       1925996  0         1                      0.0           2.0   \n",
       "       1926724  0         1                      0.0           0.0   \n",
       "       1927548  0         1                      2.0           1.0   \n",
       "       1946717  0         1                      0.0           2.0   \n",
       "\n",
       "                                     unchanged_label  refactored_label  \\\n",
       "source entry_id version_x version_y                                      \n",
       "ap     5        6         7                      1.0               0.0   \n",
       "                15        16                     0.0               0.0   \n",
       "       14       15        16                     1.0               0.0   \n",
       "       17       13        14                     2.0               0.0   \n",
       "                14        15                     1.0               0.0   \n",
       "...                                              ...               ...   \n",
       "wp     1918327  0         1                      6.0               0.0   \n",
       "       1925996  0         1                      7.0               0.0   \n",
       "       1926724  0         1                      1.0               0.0   \n",
       "       1927548  0         1                      3.0               0.0   \n",
       "       1946717  0         1                      7.0               0.0   \n",
       "\n",
       "                                     num_sents  refactored_up  \\\n",
       "source entry_id version_x version_y                             \n",
       "ap     5        6         7                  9              0   \n",
       "                15        16                 9              0   \n",
       "       14       15        16                 9              0   \n",
       "       17       13        14                 9              0   \n",
       "                14        15                 9              0   \n",
       "...                                        ...            ...   \n",
       "wp     1918327  0         1                  8              0   \n",
       "       1925996  0         1                  9              0   \n",
       "       1926724  0         1                  6              0   \n",
       "       1927548  0         1                  9              0   \n",
       "       1946717  0         1                  9              0   \n",
       "\n",
       "                                     refactored_down  \\\n",
       "source entry_id version_x version_y                    \n",
       "ap     5        6         7                        0   \n",
       "                15        16                       0   \n",
       "       14       15        16                       0   \n",
       "       17       13        14                       0   \n",
       "                14        15                       0   \n",
       "...                                              ...   \n",
       "wp     1918327  0         1                        0   \n",
       "       1925996  0         1                        0   \n",
       "       1926724  0         1                        0   \n",
       "       1927548  0         1                        0   \n",
       "       1946717  0         1                        0   \n",
       "\n",
       "                                                                                 nodes  \\\n",
       "source entry_id version_x version_y                                                      \n",
       "ap     5        6         7          [{'version': 6, 'sent_idx': 0, 'sentence': 'WA...   \n",
       "                15        16         [{'version': 15, 'sent_idx': 0, 'sentence': 'W...   \n",
       "       14       15        16         [{'version': 15, 'sent_idx': 0, 'sentence': 'O...   \n",
       "       17       13        14         [{'version': 13, 'sent_idx': 0, 'sentence': 'O...   \n",
       "                14        15         [{'version': 14, 'sent_idx': 0, 'sentence': 'O...   \n",
       "...                                                                                ...   \n",
       "wp     1918327  0         1          [{'version': 0, 'sent_idx': 0, 'sentence': 'TO...   \n",
       "       1925996  0         1          [{'version': 0, 'sent_idx': 0, 'sentence': 'Th...   \n",
       "       1926724  0         1          [{'version': 0, 'sent_idx': 0, 'sentence': 'Re...   \n",
       "       1927548  0         1          [{'version': 0, 'sent_idx': 0, 'sentence': 'Th...   \n",
       "       1946717  0         1          [{'version': 0, 'sent_idx': 0, 'sentence': 'Pr...   \n",
       "\n",
       "                                                                                  arcs  \\\n",
       "source entry_id version_x version_y                                                      \n",
       "ap     5        6         7          [{'version_x': 6, 'version_y': 7, 'sent_idx_x'...   \n",
       "                15        16         [{'version_x': 15, 'version_y': 16, 'sent_idx_...   \n",
       "       14       15        16         [{'version_x': 15, 'version_y': 16, 'sent_idx_...   \n",
       "       17       13        14         [{'version_x': 13, 'version_y': 14, 'sent_idx_...   \n",
       "                14        15         [{'version_x': 14, 'version_y': 15, 'sent_idx_...   \n",
       "...                                                                                ...   \n",
       "wp     1918327  0         1          [{'version_x': 0, 'version_y': 1, 'sent_idx_x'...   \n",
       "       1925996  0         1          [{'version_x': 0, 'version_y': 1, 'sent_idx_x'...   \n",
       "       1926724  0         1          [{'version_x': 0, 'version_y': 1, 'sent_idx_x'...   \n",
       "       1927548  0         1          [{'version_x': 0, 'version_y': 1, 'sent_idx_x'...   \n",
       "       1946717  0         1          [{'version_x': 0, 'version_y': 1, 'sent_idx_x'...   \n",
       "\n",
       "                                              key  \n",
       "source entry_id version_x version_y                \n",
       "ap     5        6         7                ap-5-6  \n",
       "                15        16              ap-5-15  \n",
       "       14       15        16             ap-14-15  \n",
       "       17       13        14             ap-17-13  \n",
       "                14        15             ap-17-14  \n",
       "...                                           ...  \n",
       "wp     1918327  0         1          wp-1918327-0  \n",
       "       1925996  0         1          wp-1925996-0  \n",
       "       1926724  0         1          wp-1926724-0  \n",
       "       1927548  0         1          wp-1927548-0  \n",
       "       1946717  0         1          wp-1946717-0  \n",
       "\n",
       "[58252 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_output_df_w_counts.loc[lambda df: ~df['key'].isin(idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_bal = (\n",
    "    all_output_df_w_counts\n",
    "             .reset_index()\n",
    "             .loc[lambda df: ~df['key'].isin(idx)]\n",
    "             # downsample for refactoring\n",
    "             .merge(refactored_weights, left_on='refactored_up', right_on='index')\n",
    "             .pipe(lambda df: df.sample(4_000, weights=df['ref_weight']))\n",
    "             #  source weights\n",
    "             .merge(source_weights, left_on='source', right_on='index')\n",
    "             .assign(source_weight=lambda df: df.apply(lambda x: x['source_weight'] if x['refactored_up'] == 0 else x['source_weight'], axis=1))\n",
    "             .pipe(lambda df: df.sample(2_000, weights=df['source_weight']))     \n",
    "             .set_index(['source', 'entry_id', 'version_x', 'version_y'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_bal = (\n",
    "    all_output_df_w_counts\n",
    "     .reset_index()\n",
    "     .loc[lambda df: ~df['key'].isin(idx)]\n",
    "     # add_above_weights    \n",
    "     .merge(add_above_weights, left_on='add_above_label', right_on='index')\n",
    "     .pipe(lambda df: df.sample(50_000, weights=df['add_weight']))\n",
    "     # source weights\n",
    "     .merge(source_weights, left_on='source', right_on='index')\n",
    "     .pipe(lambda df: df.sample(40_000, weights=df['source_weight']))     \n",
    "     .set_index(['source', 'entry_id', 'version_x', 'version_y'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_bal = (\n",
    "    all_output_df_w_counts\n",
    "     .reset_index()\n",
    "     .loc[lambda df: ~df['key'].isin(idx)]\n",
    "     # delete weights\n",
    "     .merge(delete_weights, left_on='deleted_label', right_on='index')\n",
    "     .pipe(lambda df: df.sample(4_000, weights=df['del_weight']))\n",
    "     #  source weights\n",
    "     .merge(source_weights, left_on='source', right_on='index')\n",
    "     .pipe(lambda df: df.sample(2_000, weights=df['source_weight']))     \n",
    "     .set_index(['source', 'entry_id', 'version_x', 'version_y'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_labels(df_to_transform):\n",
    "    all_orig_sent_labels = []\n",
    "    all_orig_doc_labels = []\n",
    "\n",
    "    for idx in tqdm(range(len(df_to_transform))):\n",
    "        df = df_to_transform.iloc[idx]\n",
    "        ## orig data\n",
    "        doc_sentences = df['nodes']\n",
    "        x_ver = min(list(map(lambda x: x['version'], doc_sentences)))\n",
    "        doc_sentences = list(filter(lambda x: x['version'] == x_ver, doc_sentences))\n",
    "        doc_sents = pd.DataFrame(doc_sentences)\n",
    "        e_id = df.name[1]\n",
    "        doc = pd.DataFrame(df['arcs'])\n",
    "        doc['entry_id'] = e_id\n",
    "        doc_sents['entry_id'] = e_id\n",
    "        orig_sents, orig_doc = get_sentence_and_doc_labels(doc, doc_sents)\n",
    "        all_orig_sent_labels.append(orig_sents)\n",
    "        all_orig_doc_labels.append(orig_doc)\n",
    "        \n",
    "    return pd.concat(all_orig_sent_labels), pd.concat(all_orig_doc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8723d5adbe44ae7952f4716123cf7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ref_sent_labels_df, ref_doc_labels_df  = get_labels(ref_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_doc_labels_df.to_csv('../modeling/data/doc-eval__ref-balanced.csv')\n",
    "ref_sent_labels_df.to_csv('../modeling/data/sent-eval__ref-balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f9d856847c4153bbf6e78b0ce2d165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_sent_labels_df, add_doc_labels_df  = get_labels(add_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_sent_labels_df.to_csv('../modeling/data/sent-eval__add-balanced-large.csv')\n",
    "add_doc_labels_df.to_csv('../modeling/data/doc-eval__add-balanced-large.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec851d26f91496cba13f770366717db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del_sent_labels_df, del_doc_labels_df = get_labels(del_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_sent_labels_df.to_csv('../modeling/data/sent-eval__del-balanced.csv')\n",
    "del_doc_labels_df.to_csv('../modeling/data/doc-eval__del-balanced.csv')\n",
    "# del_sent_labels_df[['deleted_label', 'edited_label', 'unchanged_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num_deleted</th>\n",
       "      <th>num_added</th>\n",
       "      <th>num_edited</th>\n",
       "      <th>num_refactored</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry_id</th>\n",
       "      <th>version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>996666</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Two Japanese mountain climbers caught in a snowstorm and buried under nearly a half-century of Alpine ice have been identified, police in Switzerland announced on Tuesday.&lt;SENT&gt;The remains of Masa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106243</th>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MADRID -- Spain's members of parliament have started voting on Socialist leader Pedro Sanchez' bid to form a new government, two months after the country held inconclusive elections.&lt;SENT&gt;The voti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15655</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>LOS ANGELES (AP) -- Jennifer Aniston and Justin Theroux are separating.&lt;SENT&gt;The couple says in a statement released through her publicist Thursday that the decision to split ''was mutual and lovi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8346</th>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A gunman opened fire inside a gym at an upscale shopping mall outside Miami on Saturday afternoon, wounding two people before he was killed, Miami-Dade County police told local media.&lt;SENT&gt;The sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CHAMPAIGN, Ill.&lt;SENT&gt;(AP) -- Relatives of a missing Chinese woman studying at the University of Illinois say they won't leave the country without her as the reward in the case rose to $50,000. Fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119352</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A Briton who was missing in Brussels since the bomb attacks in the Belgian capital has been confirmed as dead by the Foreign Office.&lt;SENT&gt;David Dixon, 53, from Nottingham, lived in Brussels with h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011512</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The Football Association has apologised for its own-goal in omitting one of England's most prolific scorers from a roll of honour at Wembley Stadium.&lt;SENT&gt;Bolton Wanderers legend Nat Lofthouse was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694870</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>The discovery of two bodies at a Nottinghamshire house is being treated as a double murder by police.&lt;SENT&gt;The property in Blenheim Close, Forest Town, was searched on 10 October after a tip-off.&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260796</th>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Two people have been injured in a bomb explosion at an army barracks in Milan in northern Italy.&lt;SENT&gt;One of those injured was the attacker who threw the device, according to the Italian news agen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797213</th>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A security alert at the Westminster parliament building has been called off, after police concluded that a drinks bottle and a mobile phone had not been fashioned into a dangerous device.&lt;SENT&gt;Spe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  num_deleted  num_added  num_edited  num_refactored  \\\n",
       "entry_id version                                                       \n",
       "996666   0                  0          3           2               0   \n",
       "1106243  2                  5          3           0               0   \n",
       "15655    0                  1          2           3               0   \n",
       "8346     0                  6          4           2               0   \n",
       "9751     7                  5          6           0               0   \n",
       "...                       ...        ...         ...             ...   \n",
       "1119352  0                  0          2           2               0   \n",
       "1011512  0                  1          1           0               0   \n",
       "694870   1                  1          4           4               1   \n",
       "260796   2                  5          6           3               1   \n",
       "797213   0                  5          4           2               1   \n",
       "\n",
       "                                                                                                                                                                                                                sentences  \n",
       "entry_id version                                                                                                                                                                                                           \n",
       "996666   0        Two Japanese mountain climbers caught in a snowstorm and buried under nearly a half-century of Alpine ice have been identified, police in Switzerland announced on Tuesday.<SENT>The remains of Masa...  \n",
       "1106243  2        MADRID -- Spain's members of parliament have started voting on Socialist leader Pedro Sanchez' bid to form a new government, two months after the country held inconclusive elections.<SENT>The voti...  \n",
       "15655    0        LOS ANGELES (AP) -- Jennifer Aniston and Justin Theroux are separating.<SENT>The couple says in a statement released through her publicist Thursday that the decision to split ''was mutual and lovi...  \n",
       "8346     0        A gunman opened fire inside a gym at an upscale shopping mall outside Miami on Saturday afternoon, wounding two people before he was killed, Miami-Dade County police told local media.<SENT>The sho...  \n",
       "9751     7        CHAMPAIGN, Ill.<SENT>(AP) -- Relatives of a missing Chinese woman studying at the University of Illinois say they won't leave the country without her as the reward in the case rose to $50,000. Fam...  \n",
       "...                                                                                                                                                                                                                   ...  \n",
       "1119352  0        A Briton who was missing in Brussels since the bomb attacks in the Belgian capital has been confirmed as dead by the Foreign Office.<SENT>David Dixon, 53, from Nottingham, lived in Brussels with h...  \n",
       "1011512  0        The Football Association has apologised for its own-goal in omitting one of England's most prolific scorers from a roll of honour at Wembley Stadium.<SENT>Bolton Wanderers legend Nat Lofthouse was...  \n",
       "694870   1        The discovery of two bodies at a Nottinghamshire house is being treated as a double murder by police.<SENT>The property in Blenheim Close, Forest Town, was searched on 10 October after a tip-off.<...  \n",
       "260796   2        Two people have been injured in a bomb explosion at an army barracks in Milan in northern Italy.<SENT>One of those injured was the attacker who threw the device, according to the Italian news agen...  \n",
       "797213   0        A security alert at the Westminster parliament building has been called off, after police concluded that a drinks bottle and a mobile phone had not been fashioned into a dangerous device.<SENT>Spe...  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_doc_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>deleted_label</th>\n",
       "      <th>add_above_label</th>\n",
       "      <th>add_below_label</th>\n",
       "      <th>edited_label</th>\n",
       "      <th>unchanged_label</th>\n",
       "      <th>refactored_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>VIENNA (Reuters) - Austrian authorities are investigating reports of a man appearing in public in Adolf Hitler's birthplace as the Nazi dictator's double, including the distinctive mustache, hairc...</td>\n",
       "      <td>2841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>''I have often seen this gentlemen in Braunau and wonder if this means something,'' the Oberoesterreichische Nachrichten paper cited a local resident as saying on his Facebook page alongside a pic...</td>\n",
       "      <td>2841</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Hitler was born in Braunau am Inn, then part of Austria-Hungary, in 1889.</td>\n",
       "      <td>2841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Prosecutors confirmed the report.</td>\n",
       "      <td>2841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>The man, estimated to be 25 to 30 years old, was last seen in a local bookstore browsing through magazines about World War Two, adding he had identified himself in a local bar as ''Harald Hitler.</td>\n",
       "      <td>2841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Recent figures suggested almost 80,000 Scots were still without a NHS dentist.</td>\n",
       "      <td>301499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NHS Grampian has more than 31,000 on its waiting list.</td>\n",
       "      <td>301499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Mr Newton said: ''I am sure there are a lot of people who want care but realise there is not any to have. ''They have heard there are so many on the waiting lists and they have thought they won't ...</td>\n",
       "      <td>301499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>'' He said that as soon as more dentists started to reduce waiting lists more people would come forward to be seen.</td>\n",
       "      <td>301499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>First Minister Alex Salmond and Public Health Minister Shona Robison toured the new Foresterhill facility, meet students and see the technology for training.</td>\n",
       "      <td>301499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15539 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    version  sent_idx  \\\n",
       "0         2         0   \n",
       "1         2         1   \n",
       "2         2         2   \n",
       "3         2         3   \n",
       "4         2         4   \n",
       "..      ...       ...   \n",
       "4         1         4   \n",
       "5         1         5   \n",
       "6         1         6   \n",
       "7         1         7   \n",
       "8         1         8   \n",
       "\n",
       "                                                                                                                                                                                                   sentence  \\\n",
       "0   VIENNA (Reuters) - Austrian authorities are investigating reports of a man appearing in public in Adolf Hitler's birthplace as the Nazi dictator's double, including the distinctive mustache, hairc...   \n",
       "1   ''I have often seen this gentlemen in Braunau and wonder if this means something,'' the Oberoesterreichische Nachrichten paper cited a local resident as saying on his Facebook page alongside a pic...   \n",
       "2                                                                                                                                 Hitler was born in Braunau am Inn, then part of Austria-Hungary, in 1889.   \n",
       "3                                                                                                                                                                         Prosecutors confirmed the report.   \n",
       "4       The man, estimated to be 25 to 30 years old, was last seen in a local bookstore browsing through magazines about World War Two, adding he had identified himself in a local bar as ''Harald Hitler.   \n",
       "..                                                                                                                                                                                                      ...   \n",
       "4                                                                                                                            Recent figures suggested almost 80,000 Scots were still without a NHS dentist.   \n",
       "5                                                                                                                                                    NHS Grampian has more than 31,000 on its waiting list.   \n",
       "6   Mr Newton said: ''I am sure there are a lot of people who want care but realise there is not any to have. ''They have heard there are so many on the waiting lists and they have thought they won't ...   \n",
       "7                                                                                       '' He said that as soon as more dentists started to reduce waiting lists more people would come forward to be seen.   \n",
       "8                                             First Minister Alex Salmond and Public Health Minister Shona Robison toured the new Foresterhill facility, meet students and see the technology for training.   \n",
       "\n",
       "    entry_id  deleted_label  add_above_label  add_below_label  edited_label  \\\n",
       "0       2841              0                0                1             0   \n",
       "1       2841              0                1                0             1   \n",
       "2       2841              0                0                0             0   \n",
       "3       2841              0                0                0             0   \n",
       "4       2841              0                0                0             0   \n",
       "..       ...            ...              ...              ...           ...   \n",
       "4     301499              0                0                0             0   \n",
       "5     301499              0                0                0             1   \n",
       "6     301499              0                0                0             0   \n",
       "7     301499              0                0                0             0   \n",
       "8     301499              0                0                0             1   \n",
       "\n",
       "    unchanged_label  refactored_label  \n",
       "0                 1                 0  \n",
       "1                 0                 0  \n",
       "2                 1                 0  \n",
       "3                 1                 0  \n",
       "4                 1                 0  \n",
       "..              ...               ...  \n",
       "4                 1                 0  \n",
       "5                 0                 0  \n",
       "6                 1                 0  \n",
       "7                 1                 0  \n",
       "8                 0                 0  \n",
       "\n",
       "[15539 rows x 10 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_sent_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Models to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd \n",
    "from tensorboard_reducer import load_tb_events, reduce_events, write_csv, write_tb_events\n",
    "import yaml\n",
    "import glob\n",
    "\n",
    "def get_events(version_num, path_to_ver):\n",
    "    if isinstance(version_num, (str, int)):\n",
    "        version_num = [version_num]    \n",
    "    events_files = []\n",
    "    for v in version_num:\n",
    "        events_file = path_to_ver + '/version_%s' % v\n",
    "        events_files.append(events_file)\n",
    "    events = load_tb_events(events_files, handle_dup_steps='keep-last')\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "0                                              Roberta, Deleted binary, attention, more unfrozen\n",
       "1                                              Roberta, Doc Add binary, attention, more unfrozen\n",
       "2                                                           Roberta, Doc Edits binary, attention\n",
       "3                                                        Roberta, Doc Refactor binary, attention\n",
       "4                                              Roberta, Doc Add binary, attention, more unfrozen\n",
       "5                                  Roberta, Deleted binary, attention, more unfrozen, no context\n",
       "6                                               Roberta, Doc Edits binary, attention, no context\n",
       "7                                  Roberta, Doc Add binary, attention, more unfrozen, no context\n",
       "8                                            Roberta, Doc Refactor binary, attention, no context\n",
       "9                                              Roberta, Doc Edits binary, CLS, no context, large\n",
       "10                                Roberta, Doc Add binary, CLS, more unfrozen, no context, large\n",
       "11                                Roberta, Deleted binary, CLS, more unfrozen, no context, large\n",
       "13                                          Roberta, Doc Refactor binary, CLS, no context, large\n",
       "14                 Roberta, Deleted binary, CLS, more unfrozen, no context, large, grad accum 10\n",
       "15                 Roberta, Doc Add binary, CLS, more unfrozen, no context, large, grad accum 10\n",
       "16                              Roberta, Doc Edits binary, CLS, no context, large, grad accum 10\n",
       "17                                          Roberta, Doc Refactor binary, CLS, no context, large\n",
       "18       Roberta, Deleted binary, CLS, more unfrozen, no context, large, grad accum 10, +Version\n",
       "19                       Roberta, Deleted binary, CLS, more unfrozen, LSTM, large, grad accum 10\n",
       "20                           Roberta, Doc Refactor binary, CLS, LSTM no context, large, +Version\n",
       "21             Roberta, Doc Add binary, CLS, more unfrozen, LSTM, large, grad accum 10, +Version\n",
       "22                          Roberta, Doc Edits binary, CLS, LSTM, large, grad accum 10, +Version\n",
       "23                                    Roberta, Doc Edits binary, CLS, LSTM, large, grad accum 10\n",
       "24                       Roberta, Doc Add binary, CLS, more unfrozen, LSTM, large, grad accum 10\n",
       "25                      Roberta, Doc Refactor binary, CLS, LSTM no context, large, grad accum 10\n",
       "26      Roberta, Multitask, CLS, more unfrozen, no context, large, grad accum 10. +Version +LSTM\n",
       "27      Roberta, Multitask, CLS, more unfrozen, no context, large, grad accum 10. +Version +LSTM\n",
       "28                    Roberta, Deleted binary, CLS, 1-6 frozen, no context, large, grad accum 10\n",
       "29                    Roberta, Doc Add binary, CLS, 1-6 frozen, no context, large, grad accum 10\n",
       "30      Roberta, Multitask, CLS, more unfrozen, no context, large, grad accum 10. +Version +LSTM\n",
       "32                          Roberta, Deleted binary, CLS, 1-6 frozen, LSTM, large, grad accum 10\n",
       "33                          Roberta, Doc Add binary, CLS, 1-6 frozen, LSTM, large, grad accum 10\n",
       "34                       Roberta, Doc Edits binary, CLS,  1-6 frozen, LSTM, large, grad accum 10\n",
       "35                           Roberta, Doc Refactor binary, CLS, 1-6 frozen, large, grad accum 10\n",
       "36                               Roberta, Doc Edits binary, CLS no context, large, grad accum 10\n",
       "37    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "38                Roberta, Doc Refactor binary, CLS no context, 1-6 frozen, large, grad accum 10\n",
       "39    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "40    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "41    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "42    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "43    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "44    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "45    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "46    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "47    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "48    Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM\n",
       "49               Roberta, Deleted binary, CLS, no context, 1-6 unfrozen, grad accum 10, +Version\n",
       "50                           Roberta, Doc Add binary, CLS, 1-6 unfrozen, grad accum 10, +Version\n",
       "51                              Roberta, Doc Refactor binary, CLS, 1-6 unfrozen, large, +Version\n",
       "52                         Roberta, Doc Edits binary, CLS, 1-6 unfrozen, grad accum 10, +Version\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_hparams = {}\n",
    "path_to_versions = '../modeling/tensorboard/old_architecture_docs/default'\n",
    "\n",
    "version_num_to_notes = {}\n",
    "for hparams_file in glob.glob(path_to_versions + '/*/hparams.yaml'):\n",
    "    version_num = hparams_file.split('/')[-2]\n",
    "    with open(hparams_file, \"r\") as stream:\n",
    "        hparams = yaml.safe_load(stream)\n",
    "        version_num_to_notes[version_num] = hparams.get('notes')\n",
    "        doc_hparams[version_num] = hparams\n",
    "        \n",
    "version_map_s = pd.Series(version_num_to_notes)\n",
    "\n",
    "pd.options.display.max_colwidth=200\n",
    "\n",
    "(version_map_s\n",
    " .reset_index()\n",
    " .assign(index=lambda df: df['index'].str.split('_').str.get(1).astype(int)).sort_values('index')\n",
    " .dropna()\n",
    " .set_index('index')[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accumulate_grad_batches      100\n",
       "adam_beta1                   0.9\n",
       "adam_beta2                 0.999\n",
       "adam_epsilon                 0.0\n",
       "batch_size                     1\n",
       "                           ...  \n",
       "warmup_steps                 0.0\n",
       "weight_decay                   0\n",
       "do_multitask                 NaN\n",
       "do_version                   NaN\n",
       "loss_weighting               NaN\n",
       "Name: version_8, Length: 80, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "hparam_df = pd.DataFrame(doc_hparams).T\n",
    "hparam_df.iloc[0]#.apply(lambda x: set(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'int'>         25\n",
       "<class 'bool'>        22\n",
       "<class 'str'>         14\n",
       "<class 'float'>       12\n",
       "<class 'NoneType'>     5\n",
       "<class 'list'>         2\n",
       "Name: version_8, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparam_df.iloc[0].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freeze_encoder_layers                                               []\n",
       "label_to_idx_mapper      [refactored: (-1, 0], refactored: (-100, -1]]\n",
       "Name: version_8, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparam_df.iloc[0].loc[lambda s: s.apply(lambda x: isinstance(x, list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(filter(lambda x: x not in ['freeze_encoder_layers', 'label_to_idx_mapper'],  list(hparam_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam_variants = {}\n",
    "for c in hparam_df.columns:\n",
    "    if c not in ['label_to_idx_mapper', 'freeze_encoder_layers', 'num_output_tags', 'loss_weighting']:\n",
    "        hparam_variants[c] = set(hparam_df[c].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/alex/.cache/torch/transformers/named-models/roberta-base/config.json') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json              pytorch_model.bin        tokenizer_config.json\r\n",
      "merges.txt               special_tokens_map.json  vocab.json\r\n"
     ]
    }
   ],
   "source": [
    "ls /Users/alex/.cache/torch/transformers/named-models/roberta-base/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accumulate_grad_batches': {10, 20, 100},\n",
       " 'adam_beta1': {0.9},\n",
       " 'adam_beta2': {0.999},\n",
       " 'adam_epsilon': {1e-08},\n",
       " 'batch_size': {1},\n",
       " 'bidirectional': {False},\n",
       " 'concat_headline': {False},\n",
       " 'context_layer': {'lstm'},\n",
       " 'contextual_layer_type': {'lstm'},\n",
       " 'dataset_size': {27000, 135000},\n",
       " 'discriminator_path': {None},\n",
       " 'do_doc_pred': {True},\n",
       " 'do_eval': {True},\n",
       " 'do_train': {True},\n",
       " 'doc_embed_arithmetic': {False},\n",
       " 'dropout': {0.1},\n",
       " 'embedding_dim': {768},\n",
       " 'embedding_model_type': {'roberta'},\n",
       " 'env': {'local'},\n",
       " 'eval_data_file_s3': {None},\n",
       " 'experiment': {'lstm_sequential'},\n",
       " 'finetuned_lm_file': {None},\n",
       " 'freeze_embedding_layer': {False},\n",
       " 'freeze_pooling_layer': {False},\n",
       " 'freeze_transformer': {False, True},\n",
       " 'gradient_accumulation': {10, 20, 100},\n",
       " 'hidden_dim': {512},\n",
       " 'learning_rate': {1e-06},\n",
       " 'local': {False},\n",
       " 'log_all_metrics': {True},\n",
       " 'log_interval': {10},\n",
       " 'lstm_bidirectional': {False},\n",
       " 'lstm_num_hidden_layers': {0, 2},\n",
       " 'main_data_file': {'/job/.local/lib/python3.7/site-packages/discriminator/input_data.csv',\n",
       "  '/job/.local/lib/python3.7/site-packages/discriminator/input_data.csv.gz'},\n",
       " 'max_grad_norm': {0},\n",
       " 'max_length_seq': {512},\n",
       " 'max_num_sentences': {100},\n",
       " 'max_num_word_positions': {2048},\n",
       " 'max_position_embeddings': {40},\n",
       " 'model_type': {''},\n",
       " 'notes': {'Roberta, Deleted binary, CLS, 1-6 frozen, LSTM, large, grad accum 10',\n",
       "  'Roberta, Deleted binary, CLS, 1-6 frozen, no context, large, grad accum 10',\n",
       "  'Roberta, Deleted binary, CLS, more unfrozen, LSTM, large, grad accum 10',\n",
       "  'Roberta, Deleted binary, CLS, more unfrozen, no context, large',\n",
       "  'Roberta, Deleted binary, CLS, more unfrozen, no context, large, grad accum 10',\n",
       "  'Roberta, Deleted binary, CLS, more unfrozen, no context, large, grad accum 10, +Version',\n",
       "  'Roberta, Deleted binary, CLS, no context, 1-6 unfrozen, grad accum 10, +Version',\n",
       "  'Roberta, Deleted binary, attention, more unfrozen',\n",
       "  'Roberta, Deleted binary, attention, more unfrozen, no context',\n",
       "  'Roberta, Doc Add binary, CLS, 1-6 frozen, LSTM, large, grad accum 10',\n",
       "  'Roberta, Doc Add binary, CLS, 1-6 frozen, no context, large, grad accum 10',\n",
       "  'Roberta, Doc Add binary, CLS, 1-6 unfrozen, grad accum 10, +Version',\n",
       "  'Roberta, Doc Add binary, CLS, more unfrozen, LSTM, large, grad accum 10',\n",
       "  'Roberta, Doc Add binary, CLS, more unfrozen, LSTM, large, grad accum 10, +Version',\n",
       "  'Roberta, Doc Add binary, CLS, more unfrozen, no context, large',\n",
       "  'Roberta, Doc Add binary, CLS, more unfrozen, no context, large, grad accum 10',\n",
       "  'Roberta, Doc Add binary, attention, more unfrozen',\n",
       "  'Roberta, Doc Add binary, attention, more unfrozen, no context',\n",
       "  'Roberta, Doc Edits binary, CLS no context, large, grad accum 10',\n",
       "  'Roberta, Doc Edits binary, CLS,  1-6 frozen, LSTM, large, grad accum 10',\n",
       "  'Roberta, Doc Edits binary, CLS, 1-6 unfrozen, grad accum 10, +Version',\n",
       "  'Roberta, Doc Edits binary, CLS, LSTM, large, grad accum 10',\n",
       "  'Roberta, Doc Edits binary, CLS, LSTM, large, grad accum 10, +Version',\n",
       "  'Roberta, Doc Edits binary, CLS, no context, large',\n",
       "  'Roberta, Doc Edits binary, CLS, no context, large, grad accum 10',\n",
       "  'Roberta, Doc Edits binary, attention',\n",
       "  'Roberta, Doc Edits binary, attention, no context',\n",
       "  'Roberta, Doc Refactor binary, CLS no context, 1-6 frozen, large, grad accum 10',\n",
       "  'Roberta, Doc Refactor binary, CLS, 1-6 frozen, large, grad accum 10',\n",
       "  'Roberta, Doc Refactor binary, CLS, 1-6 unfrozen, large, +Version',\n",
       "  'Roberta, Doc Refactor binary, CLS, LSTM no context, large, +Version',\n",
       "  'Roberta, Doc Refactor binary, CLS, LSTM no context, large, grad accum 10',\n",
       "  'Roberta, Doc Refactor binary, CLS, no context, large',\n",
       "  'Roberta, Doc Refactor binary, attention',\n",
       "  'Roberta, Doc Refactor binary, attention, no context',\n",
       "  'Roberta, Multitask, CLS, more frozen 1-6, no context, large, grad accum 10. +Version +LSTM',\n",
       "  'Roberta, Multitask, CLS, more unfrozen, no context, large, grad accum 10. +Version +LSTM'},\n",
       " 'num_contextual_layers': {0, 2},\n",
       " 'num_dataloader_cpus': {10},\n",
       " 'num_gpus': {1},\n",
       " 'num_nodes': {1},\n",
       " 'num_sent_attn_heads': {2},\n",
       " 'num_steps_per_epoch': {27000, 135000},\n",
       " 'num_train_epochs': {3},\n",
       " 'num_warmup_steps': {0},\n",
       " 'pad_id': {1},\n",
       " 'pretrained_cache_dir': {'./roberta-base'},\n",
       " 'pretrained_files_s3': {'roberta-base'},\n",
       " 'processed_data_fname': {None},\n",
       " 'save_model': {False},\n",
       " 'sentence_embedding_method': {'attention', 'attention, more unfrozen', 'cls'},\n",
       " 'sinusoidal_embeddings': {False},\n",
       " 'split_type': {'random'},\n",
       " 'tb_logdir': {None},\n",
       " 'total_steps': {405000, 2025000},\n",
       " 'train_data_file_s3': {'data/doc-edits-large__add-labels.tsv.gz',\n",
       "  'data/doc-edits-large__deleted-labels.tsv.gz',\n",
       "  'data/doc-edits-large__edited-labels.tsv.gz',\n",
       "  'data/doc-edits-large__multitask.tsv.gz',\n",
       "  'data/doc-edits-large__refactored-labels.tsv.gz',\n",
       "  'data/doc-edits__add-labels.tsv',\n",
       "  'data/doc-edits__deleted-labels.tsv',\n",
       "  'data/doc-edits__edited-labels.tsv',\n",
       "  'data/doc-edits__refactored-labels.tsv'},\n",
       " 'train_perc': {1.0},\n",
       " 'transformer_attention_probs_dropout_prob': {0.1},\n",
       " 'transformer_hidden_dropout_prob': {0.1},\n",
       " 'transformers_version': {'4.5.1'},\n",
       " 'use_cpu': {False},\n",
       " 'use_doc_emb': {False},\n",
       " 'use_doc_embs': {False},\n",
       " 'use_headline_embs': {False},\n",
       " 'use_headlines': {False},\n",
       " 'use_pos_embs': {False},\n",
       " 'use_positional': {False},\n",
       " 'use_tsa': {False},\n",
       " 'warmup_steps': {0.0},\n",
       " 'weight_decay': {0},\n",
       " 'do_multitask': {nan, False, True},\n",
       " 'do_version': {nan, False, True}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparam_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_25    Roberta, Doc Refactor binary, CLS, LSTM no context, large, grad accum 10\n",
      "Name: notes, dtype: object\n",
      "version_38    Roberta, Doc Refactor binary, CLS no context, 1-6 frozen, large, grad accum 10\n",
      "Name: notes, dtype: object\n",
      "version_51    Roberta, Doc Refactor binary, CLS, 1-6 unfrozen, large, +Version\n",
      "Name: notes, dtype: object\n",
      "version_35    Roberta, Doc Refactor binary, CLS, 1-6 frozen, large, grad accum 10\n",
      "Name: notes, dtype: object\n"
     ]
    }
   ],
   "source": [
    "t1 = (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('refactored-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    " .loc[lambda df: df['freeze_transformer'] == True]\n",
    " .loc[lambda df: df['do_version'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t1)\n",
    "\n",
    "t2= (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('refactored-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 0]\n",
    " .loc[lambda df: df['do_version'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t2)\n",
    "\n",
    "\n",
    "t3 = (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('refactored-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 0]\n",
    " .loc[lambda df: df['do_version'] == True]\n",
    " .loc[lambda df: df['freeze_transformer'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t3)\n",
    "\n",
    "t4 = (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('refactored-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    "#  .loc[lambda df: df['do_version'] == False]\n",
    " .loc[lambda df: df['freeze_transformer'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_24    Roberta, Doc Add binary, CLS, more unfrozen, LSTM, large, grad accum 10\n",
      "Name: notes, dtype: object\n",
      "version_29    Roberta, Doc Add binary, CLS, 1-6 frozen, no context, large, grad accum 10\n",
      "Name: notes, dtype: object\n",
      "version_50    Roberta, Doc Add binary, CLS, 1-6 unfrozen, grad accum 10, +Version\n",
      "Name: notes, dtype: object\n",
      "version_33    Roberta, Doc Add binary, CLS, 1-6 frozen, LSTM, large, grad accum 10\n",
      "Name: notes, dtype: object\n"
     ]
    }
   ],
   "source": [
    "t1 = (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('add-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    " .loc[lambda df: df['freeze_transformer'] == True]\n",
    " .loc[lambda df: df['do_version'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t1)\n",
    "\n",
    "t2= (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('add-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 0]\n",
    " .loc[lambda df: df['do_version'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t2)\n",
    "\n",
    "\n",
    "t3 = (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('add-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 0]\n",
    " .loc[lambda df: df['do_version'] == True]\n",
    " .loc[lambda df: df['freeze_transformer'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t3)\n",
    "\n",
    "t4 = (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('add-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    "#  .loc[lambda df: df['do_version'] == False]\n",
    " .loc[lambda df: df['freeze_transformer'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial-Roberta, Doc Add binary, CLS, more unfrozen, LSTM, large, grad accum 10, +Version__epoch=09-f1_macro=0.36.ckpt\n",
    "\n",
    "trial-Roberta, Doc Add binary, CLS, more unfrozen, no context, large, grad accum 10__epoch=09-f1_macro=0.36.ckpt\n",
    "\n",
    "trial-Roberta, Doc Add binary, CLS, more unfrozen, no context, large__epoch=09-f1_macro=0.30.ckpt\n",
    "\n",
    "trial-Roberta, Doc Add binary, attention, more unfrozen, no context__epoch=09-f1_macro=0.32.ckpt\n",
    "\n",
    "trial-Roberta, Doc Add binary, attention, more unfrozen__epoch=08-f1_macro=0.22.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_19    Roberta, Deleted binary, CLS, more unfrozen, LSTM, large, grad accum 10\n",
      "Name: notes, dtype: object\n",
      "version_28    Roberta, Deleted binary, CLS, 1-6 frozen, no context, large, grad accum 10\n",
      "Name: notes, dtype: object\n",
      "version_49    Roberta, Deleted binary, CLS, no context, 1-6 unfrozen, grad accum 10, +Version\n",
      "Name: notes, dtype: object\n",
      "version_32    Roberta, Deleted binary, CLS, 1-6 frozen, LSTM, large, grad accum 10\n",
      "Name: notes, dtype: object\n"
     ]
    }
   ],
   "source": [
    "t1 = (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('deleted-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    " .loc[lambda df: df['freeze_transformer'] == True]\n",
    " .loc[lambda df: df['do_version'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t1)\n",
    "\n",
    "t2= (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('deleted-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 0]\n",
    " .loc[lambda df: df['do_version'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t2)\n",
    "\n",
    "\n",
    "t3 = (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('deleted-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 0]\n",
    " .loc[lambda df: df['do_version'] == True]\n",
    " .loc[lambda df: df['freeze_transformer'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t3)\n",
    "\n",
    "t4 = (hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('deleted-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    "#  .loc[lambda df: df['do_version'] == False]\n",
    " .loc[lambda df: df['freeze_transformer'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "0                         Roberta, Sentence Operations binary, high level labels\n",
       "1                         Roberta, Sentence Operations binary, high level labels\n",
       "2                                Roberta, Sentence Add binary, high level labels\n",
       "3                         Roberta, Sentence Operations binary, high level labels\n",
       "4                                Roberta, Sentence Add binary, high level labels\n",
       "5                         Roberta, Sentence Operations binary, high level labels\n",
       "6                           Roberta, Sentence Refactor binary, high level labels\n",
       "7                                Roberta, Sentence Add binary, high level labels\n",
       "8                                Roberta, Sentence Add binary, high level labels\n",
       "9                         Roberta, Sentence Operations binary, high level labels\n",
       "10                          Roberta, Sentence Refactor binary, high level labels\n",
       "11                                Roberta, Sentence Operations binary, attention\n",
       "12                 Roberta, Sentence Operations binary, attention, more unfrozen\n",
       "13                                  Roberta, Sentence Refactor binary, attention\n",
       "14                        Roberta, Sentence Add binary, attention, more unfrozen\n",
       "15                                       Roberta, Sentence Add binary, attention\n",
       "16                                  Roberta, Sentence Refactor binary, attention\n",
       "17                 Roberta, Sentence Operations binary, attention, more unfrozen\n",
       "18                                  Roberta, Sentence Refactor binary, attention\n",
       "19                        Roberta, Sentence Add binary, attention, more unfrozen\n",
       "20               Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Version\n",
       "21          Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +Version\n",
       "22          Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +Version\n",
       "23               Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Version\n",
       "24        Roberta, Sentence Operations binary, attention, 1-6 Unfrozen, +Version\n",
       "25                  Roberta, Sentence Add binary, attention, 1-6 Unfrozen, -LSTM\n",
       "26           Roberta, Sentence Operations binary, attention, 1-6 Unfrozen, -LSTM\n",
       "27             Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, -LSTM\n",
       "28    Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Version +Multitask\n",
       "29             Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Multitask\n",
       "30             Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Multitask\n",
       "31    Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Version +Multitask\n",
       "32             Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Multitask\n",
       "33    Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Version +Multitask\n",
       "34    Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Version +Multitask\n",
       "35             Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +Multitask\n",
       "36           Roberta, Sentence Operations binary, attention, 1-6 Unfrozen, +LSTM\n",
       "37                  Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +LSTM\n",
       "38             Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +LSTM\n",
       "39                  Roberta, Sentence Add binary, attention, 1-6 Unfrozen, +LSTM\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_hparams = {}\n",
    "path_to_versions = '../modeling/tensorboard/old_architecture/default'\n",
    "\n",
    "version_num_to_notes = {}\n",
    "for hparams_file in glob.glob(path_to_versions + '/*/hparams.yaml'):\n",
    "    version_num = hparams_file.split('/')[-2]\n",
    "    with open(hparams_file, \"r\") as stream:\n",
    "        hparams = yaml.safe_load(stream)\n",
    "        version_num_to_notes[version_num] = hparams.get('notes')\n",
    "        doc_hparams[version_num] = hparams\n",
    "        \n",
    "version_map_s = pd.Series(version_num_to_notes)\n",
    "\n",
    "pd.options.display.max_colwidth=200\n",
    "\n",
    "(version_map_s\n",
    " .reset_index()\n",
    " .assign(index=lambda df: df['index'].str.split('_').str.get(1).astype(int)).sort_values('index')\n",
    " .dropna()\n",
    " .set_index('index')[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: notes, dtype: object)\n",
      "version_27    Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, -LSTM\n",
      "Name: notes, dtype: object\n",
      "version_22    Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +Version\n",
      "version_21    Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +Version\n",
      "Name: notes, dtype: object\n",
      "version_38    Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +LSTM\n",
      "Name: notes, dtype: object\n"
     ]
    }
   ],
   "source": [
    "t1 = (sent_hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('refactor-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    " .loc[lambda df: df['freeze_transformer'] == True]\n",
    " .loc[lambda df: df['do_version'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t1)\n",
    "\n",
    "t2= (sent_hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('refactor-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 0]\n",
    " .loc[lambda df: df['do_version'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t2)\n",
    "\n",
    "\n",
    "t3 = (sent_hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('refactor-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    " .loc[lambda df: df['do_version'] == True]\n",
    " .loc[lambda df: df['freeze_transformer'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t3)\n",
    "\n",
    "t4 = (sent_hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('refactor-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    " .loc[lambda df: df['do_version'] == False]\n",
    " .loc[lambda df: df['freeze_transformer'] == False]\n",
    " ['notes']\n",
    ")\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version_22</th>\n",
       "      <th>version_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accumulate_grad_batches</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adam_beta1</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adam_beta2</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adam_epsilon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concat_headline</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_layer</th>\n",
       "      <td>lstm</td>\n",
       "      <td>lstm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contextual_layer_type</th>\n",
       "      <td>lstm</td>\n",
       "      <td>lstm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_size</th>\n",
       "      <td>45000</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discriminator_path</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do_eval</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do_train</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_embed_arithmetic</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedding_dim</th>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedding_model_type</th>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>env</th>\n",
       "      <td>local</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_data_file_s3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>lstm_sequential</td>\n",
       "      <td>lstm_sequential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finetuned_lm_file</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freeze_embedding_layer</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freeze_encoder_layers</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freeze_pooling_layer</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freeze_transformer</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_accumulation</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_dim</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_to_idx_mapper</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_all_metrics</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_interval</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm_bidirectional</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm_num_hidden_layers</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_data_file</th>\n",
       "      <td>/job/.local/lib/python3.7/site-packages/discriminator/input_data.csv</td>\n",
       "      <td>/job/.local/lib/python3.7/site-packages/discriminator/input_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_grad_norm</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_length_seq</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_num_sentences</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_num_word_positions</th>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_position_embeddings</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +Version</td>\n",
       "      <td>Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +Version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_contextual_layers</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_dataloader_cpus</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_gpus</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_output_tags</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sent_attn_heads</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_steps_per_epoch</th>\n",
       "      <td>45000</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_train_epochs</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_warmup_steps</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pad_id</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained_cache_dir</th>\n",
       "      <td>./roberta-base</td>\n",
       "      <td>./roberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained_files_s3</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>roberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processed_data_fname</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>save_model</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_embedding_method</th>\n",
       "      <td>attention</td>\n",
       "      <td>attention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinusoidal_embeddings</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_type</th>\n",
       "      <td>random</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tb_logdir</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_steps</th>\n",
       "      <td>675000</td>\n",
       "      <td>675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_data_file_s3</th>\n",
       "      <td>data/sentence-edits__refactor-labels.tsv</td>\n",
       "      <td>data/sentence-edits__refactor-labels.tsv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_perc</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transformer_attention_probs_dropout_prob</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transformer_hidden_dropout_prob</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transformers_version</th>\n",
       "      <td>4.5.1</td>\n",
       "      <td>4.5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_cpu</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_doc_emb</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_doc_embs</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_headline_embs</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_headlines</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_pos_embs</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_positional</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_tsa</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warmup_steps</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_decay</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do_doc_pred</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do_multitask</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do_version</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_weighting</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    version_22  \\\n",
       "accumulate_grad_batches                                                                                    100   \n",
       "adam_beta1                                                                                                 0.9   \n",
       "adam_beta2                                                                                               0.999   \n",
       "adam_epsilon                                                                                               0.0   \n",
       "batch_size                                                                                                   1   \n",
       "bidirectional                                                                                            False   \n",
       "concat_headline                                                                                          False   \n",
       "context_layer                                                                                             lstm   \n",
       "contextual_layer_type                                                                                     lstm   \n",
       "dataset_size                                                                                             45000   \n",
       "discriminator_path                                                                                        None   \n",
       "do_eval                                                                                                   True   \n",
       "do_train                                                                                                  True   \n",
       "doc_embed_arithmetic                                                                                     False   \n",
       "dropout                                                                                                    0.1   \n",
       "embedding_dim                                                                                              768   \n",
       "embedding_model_type                                                                                   roberta   \n",
       "env                                                                                                      local   \n",
       "eval_data_file_s3                                                                                         None   \n",
       "experiment                                                                                     lstm_sequential   \n",
       "finetuned_lm_file                                                                                         None   \n",
       "freeze_embedding_layer                                                                                   False   \n",
       "freeze_encoder_layers                                                                    [0, 1, 2, 3, 4, 5, 6]   \n",
       "freeze_pooling_layer                                                                                     False   \n",
       "freeze_transformer                                                                                       False   \n",
       "gradient_accumulation                                                                                      100   \n",
       "hidden_dim                                                                                                 512   \n",
       "label_to_idx_mapper                                                                                        NaN   \n",
       "learning_rate                                                                                         0.000001   \n",
       "local                                                                                                    False   \n",
       "log_all_metrics                                                                                           True   \n",
       "log_interval                                                                                                10   \n",
       "lstm_bidirectional                                                                                       False   \n",
       "lstm_num_hidden_layers                                                                                       2   \n",
       "main_data_file                            /job/.local/lib/python3.7/site-packages/discriminator/input_data.csv   \n",
       "max_grad_norm                                                                                                0   \n",
       "max_length_seq                                                                                             512   \n",
       "max_num_sentences                                                                                          100   \n",
       "max_num_word_positions                                                                                    2048   \n",
       "max_position_embeddings                                                                                     40   \n",
       "model_type                                                                                                       \n",
       "notes                                     Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +Version   \n",
       "num_contextual_layers                                                                                        2   \n",
       "num_dataloader_cpus                                                                                         10   \n",
       "num_gpus                                                                                                     1   \n",
       "num_nodes                                                                                                    1   \n",
       "num_output_tags                                                                                              2   \n",
       "num_sent_attn_heads                                                                                          2   \n",
       "num_steps_per_epoch                                                                                      45000   \n",
       "num_train_epochs                                                                                             3   \n",
       "num_warmup_steps                                                                                             0   \n",
       "pad_id                                                                                                       1   \n",
       "pretrained_cache_dir                                                                            ./roberta-base   \n",
       "pretrained_files_s3                                                                               roberta-base   \n",
       "processed_data_fname                                                                                      None   \n",
       "save_model                                                                                               False   \n",
       "sentence_embedding_method                                                                            attention   \n",
       "sinusoidal_embeddings                                                                                    False   \n",
       "split_type                                                                                              random   \n",
       "tb_logdir                                                                                                 None   \n",
       "total_steps                                                                                             675000   \n",
       "train_data_file_s3                                                    data/sentence-edits__refactor-labels.tsv   \n",
       "train_perc                                                                                                 1.0   \n",
       "transformer_attention_probs_dropout_prob                                                                   0.1   \n",
       "transformer_hidden_dropout_prob                                                                            0.1   \n",
       "transformers_version                                                                                     4.5.1   \n",
       "use_cpu                                                                                                  False   \n",
       "use_doc_emb                                                                                              False   \n",
       "use_doc_embs                                                                                             False   \n",
       "use_headline_embs                                                                                        False   \n",
       "use_headlines                                                                                            False   \n",
       "use_pos_embs                                                                                             False   \n",
       "use_positional                                                                                           False   \n",
       "use_tsa                                                                                                  False   \n",
       "warmup_steps                                                                                               0.0   \n",
       "weight_decay                                                                                                 0   \n",
       "do_doc_pred                                                                                              False   \n",
       "do_multitask                                                                                             False   \n",
       "do_version                                                                                                True   \n",
       "loss_weighting                                                                                            None   \n",
       "\n",
       "                                                                                                    version_21  \n",
       "accumulate_grad_batches                                                                                    100  \n",
       "adam_beta1                                                                                                 0.9  \n",
       "adam_beta2                                                                                               0.999  \n",
       "adam_epsilon                                                                                               0.0  \n",
       "batch_size                                                                                                   1  \n",
       "bidirectional                                                                                            False  \n",
       "concat_headline                                                                                          False  \n",
       "context_layer                                                                                             lstm  \n",
       "contextual_layer_type                                                                                     lstm  \n",
       "dataset_size                                                                                             45000  \n",
       "discriminator_path                                                                                        None  \n",
       "do_eval                                                                                                   True  \n",
       "do_train                                                                                                  True  \n",
       "doc_embed_arithmetic                                                                                     False  \n",
       "dropout                                                                                                    0.1  \n",
       "embedding_dim                                                                                              768  \n",
       "embedding_model_type                                                                                   roberta  \n",
       "env                                                                                                      local  \n",
       "eval_data_file_s3                                                                                         None  \n",
       "experiment                                                                                     lstm_sequential  \n",
       "finetuned_lm_file                                                                                         None  \n",
       "freeze_embedding_layer                                                                                   False  \n",
       "freeze_encoder_layers                                                                    [0, 1, 2, 3, 4, 5, 6]  \n",
       "freeze_pooling_layer                                                                                     False  \n",
       "freeze_transformer                                                                                       False  \n",
       "gradient_accumulation                                                                                      100  \n",
       "hidden_dim                                                                                                 512  \n",
       "label_to_idx_mapper                                                                                        NaN  \n",
       "learning_rate                                                                                         0.000001  \n",
       "local                                                                                                    False  \n",
       "log_all_metrics                                                                                           True  \n",
       "log_interval                                                                                                10  \n",
       "lstm_bidirectional                                                                                       False  \n",
       "lstm_num_hidden_layers                                                                                       2  \n",
       "main_data_file                            /job/.local/lib/python3.7/site-packages/discriminator/input_data.csv  \n",
       "max_grad_norm                                                                                                0  \n",
       "max_length_seq                                                                                             512  \n",
       "max_num_sentences                                                                                          100  \n",
       "max_num_word_positions                                                                                    2048  \n",
       "max_position_embeddings                                                                                     40  \n",
       "model_type                                                                                                      \n",
       "notes                                     Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +Version  \n",
       "num_contextual_layers                                                                                        2  \n",
       "num_dataloader_cpus                                                                                         10  \n",
       "num_gpus                                                                                                     1  \n",
       "num_nodes                                                                                                    1  \n",
       "num_output_tags                                                                                              2  \n",
       "num_sent_attn_heads                                                                                          2  \n",
       "num_steps_per_epoch                                                                                      45000  \n",
       "num_train_epochs                                                                                             3  \n",
       "num_warmup_steps                                                                                             0  \n",
       "pad_id                                                                                                       1  \n",
       "pretrained_cache_dir                                                                            ./roberta-base  \n",
       "pretrained_files_s3                                                                               roberta-base  \n",
       "processed_data_fname                                                                                      None  \n",
       "save_model                                                                                               False  \n",
       "sentence_embedding_method                                                                            attention  \n",
       "sinusoidal_embeddings                                                                                    False  \n",
       "split_type                                                                                              random  \n",
       "tb_logdir                                                                                                 None  \n",
       "total_steps                                                                                             675000  \n",
       "train_data_file_s3                                                    data/sentence-edits__refactor-labels.tsv  \n",
       "train_perc                                                                                                 1.0  \n",
       "transformer_attention_probs_dropout_prob                                                                   0.1  \n",
       "transformer_hidden_dropout_prob                                                                            0.1  \n",
       "transformers_version                                                                                     4.5.1  \n",
       "use_cpu                                                                                                  False  \n",
       "use_doc_emb                                                                                              False  \n",
       "use_doc_embs                                                                                             False  \n",
       "use_headline_embs                                                                                        False  \n",
       "use_headlines                                                                                            False  \n",
       "use_pos_embs                                                                                             False  \n",
       "use_positional                                                                                           False  \n",
       "use_tsa                                                                                                  False  \n",
       "warmup_steps                                                                                               0.0  \n",
       "weight_decay                                                                                                 0  \n",
       "do_doc_pred                                                                                              False  \n",
       "do_multitask                                                                                             False  \n",
       "do_version                                                                                                True  \n",
       "loss_weighting                                                                                            None  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sent_hparam_df\n",
    " .loc[lambda df: df['train_data_file_s3'].str.contains('refactor-labels')]\n",
    " .loc[lambda df: df['num_contextual_layers'] == 2]\n",
    " .loc[lambda df: df['do_version'] == True]\n",
    " .loc[lambda df: df['freeze_transformer'] == False].T\n",
    "#  ['notes']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  trial-Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +LSTM__epoch=09-f1_macro=0.50.ckpt\n",
    "#  trial-Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +LSTM__epoch=09-f1_macro=0.54.ckpt\n",
    "#  trial-Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, +Version__epoch=04-f1_macro=0.51.ckpt\n",
    "#  trial-Roberta, Sentence Refactor binary, attention, 1-6 Unfrozen, -LSTM__epoch=00-f1_macro=0.50.ckpt\n",
    "#  trial-Roberta, Sentence Refactor binary, attention__epoch=00-f1_macro=0.50.ckpt\n",
    "#  trial-Roberta, Sentence Refactor binary, attention__epoch=02-f1_macro=0.50.ckpt\n",
    "#  trial-Roberta, Sentence Refactor binary, high level labels__epoch=00-f1_macro=0.50.ckpt\n",
    "#  trial-Roberta, Sentence Refactor binary, high level labels__epoch=08-f1_macro=0.59.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_hparams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8eb09fed2010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_hparam_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_hparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_hparams' is not defined"
     ]
    }
   ],
   "source": [
    "sent_hparam_df = pd.DataFrame(doc_hparams).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "version_8           data/sentence-edits__add-labels.tsv\n",
       "version_36    data/sentence-edits__operation-labels.tsv\n",
       "version_31          data/sentence-edits__add-labels.tsv\n",
       "version_38     data/sentence-edits__refactor-labels.tsv\n",
       "version_6      data/sentence-edits__refactor-labels.tsv\n",
       "version_1            data/sentence-operation-labels.tsv\n",
       "version_0            data/sentence-operation-labels.tsv\n",
       "version_39          data/sentence-edits__add-labels.tsv\n",
       "version_7           data/sentence-edits__add-labels.tsv\n",
       "version_30          data/sentence-edits__add-labels.tsv\n",
       "version_9            data/sentence-operation-labels.tsv\n",
       "version_37          data/sentence-edits__add-labels.tsv\n",
       "version_15          data/sentence-edits__add-labels.tsv\n",
       "version_12           data/sentence-operation-labels.tsv\n",
       "version_24    data/sentence-edits__operation-labels.tsv\n",
       "version_23          data/sentence-edits__add-labels.tsv\n",
       "version_22     data/sentence-edits__refactor-labels.tsv\n",
       "version_25          data/sentence-edits__add-labels.tsv\n",
       "version_13     data/sentence-edits__refactor-labels.tsv\n",
       "version_14          data/sentence-edits__add-labels.tsv\n",
       "version_32          data/sentence-edits__add-labels.tsv\n",
       "version_35           data/sentence-edits__multitask.tsv\n",
       "version_2           data/sentence-edits__add-labels.tsv\n",
       "version_5            data/sentence-operation-labels.tsv\n",
       "version_4           data/sentence-edits__add-labels.tsv\n",
       "version_3            data/sentence-operation-labels.tsv\n",
       "version_34           data/sentence-edits__multitask.tsv\n",
       "version_33          data/sentence-edits__add-labels.tsv\n",
       "version_11           data/sentence-operation-labels.tsv\n",
       "version_16     data/sentence-edits__refactor-labels.tsv\n",
       "version_29          data/sentence-edits__add-labels.tsv\n",
       "version_20          data/sentence-edits__add-labels.tsv\n",
       "version_27     data/sentence-edits__refactor-labels.tsv\n",
       "version_18     data/sentence-edits__refactor-labels.tsv\n",
       "version_26    data/sentence-edits__operation-labels.tsv\n",
       "version_19          data/sentence-edits__add-labels.tsv\n",
       "version_21     data/sentence-edits__refactor-labels.tsv\n",
       "version_17           data/sentence-operation-labels.tsv\n",
       "version_28          data/sentence-edits__add-labels.tsv\n",
       "version_10     data/sentence-edits__refactor-labels.tsv\n",
       "Name: train_data_file_s3, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_hparam_df['train_data_file_s3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../modeling/data/edits__docs-ref-baseline.txt\r\n",
      "../modeling/data/edits__docs-ref-partially-unfrozen-no-context.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls ../modeling/data/edits__docs-ref-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_baseline = open('../modeling/data/edits__docs-ref-baseline.txt').read().split('\\n')\n",
    "ref_unfrozen = open('../modeling/data/edits__docs-ref-partially-unfrozen-no-context.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.write(str(pred_tags))\n",
    "# f.write(label_col.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= list(map(lambda x: x.replace('[', '').split(']'), ref_baseline[1::2]))\n",
    "t_df = pd.DataFrame(t, columns=['pred', 'true'])\n",
    "t_df['true'] = t_df['true'].astype(int).pipe(lambda s: s > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6455"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(t_df['true'].astype(str), t_df['pred'].astype(str), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3922819811607414"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(t_df['true'].astype(str), t_df['pred'].astype(str), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_unfrozen = pd.DataFrame(\n",
    "    list(map(lambda x: x.replace('[', '').split(']'), ref_unfrozen[1::2])), \n",
    "    columns=['pred', 'true']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_unfrozen['true'] = partially_unfrozen['true'].astype(int).pipe(lambda s: s > 0).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6455"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(partially_unfrozen['true'], partially_unfrozen['pred'], average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3922819811607414"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(partially_unfrozen['true'], partially_unfrozen['pred'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6455"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(partially_unfrozen['true'], ['0'] * 2000, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3922819811607414"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(partially_unfrozen['true'], ['0'] * 2000, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2579447323290069"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(partially_unfrozen['true'], np.random.choice(['0', '1', '-1'], 2000), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3415"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(partially_unfrozen['true'], np.random.choice(['0', '1', '-1'], 2000), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate sentence ref data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../modeling/data/edits__sents-ref-context.txt\r\n",
      "../modeling/data/edits__sents-ref-partially-unfrozen.txt\r\n",
      "../modeling/data/edits__sents-ref-version-with-context.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls ../modeling/data/edits__sents-ref-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = open('../modeling/data/edits__sents-ref-version-with-context.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(filter(lambda x: 'refactored_label' in x, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(map(lambda x: x.split(']{'), b)))\n",
    "df[1] = df[1].str.split(':').str.get(1).str.replace('}', '', regex=False).apply(ast.literal_eval)\n",
    "df[0] = df[0].pipe(lambda s: s + ']').apply(ast.literal_eval)\n",
    "df[1] = df[1].apply(lambda x: list(map(lambda y: int(y == 0), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [j2 for i2 in df[0].tolist() for j2 in i2]\n",
    "y_true = [j2 for i1 in df[1].tolist() for j2 in i1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame([y_pred, y_true]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = t[1].value_counts().pipe(lambda s: 1/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_t = (t\n",
    " .assign(w=lambda df: df.merge(w.to_frame('w'), right_index=True, left_on=1)['w'])\n",
    " .pipe(lambda df: df.sample(300, weights=df['w']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.572"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(b_t[1].astype(str), b_t[0].astype(str), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2470896529818153"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(b_t[1].astype(str), np.random.choice(['0', '1', '-1'], size=300), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(b_t[1].astype(str).tolist(), np.random.choice(['0', '1', '-1'], size=300), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3478260869565218"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(b_t[1].astype(str).tolist(), ['1'] * 300, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('../../controlled-sequence-gen/data/sentence-edits__refactor-labels.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['refactor_down', 'refactor_unchanged'], dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df[0].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
