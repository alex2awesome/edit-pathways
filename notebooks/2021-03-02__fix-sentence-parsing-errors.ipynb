{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.util_newssniffer_parsing' from '../util/util_newssniffer_parsing.py'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import sqlite3\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import util.util_newssniffer_parsing as up\n",
    "from importlib import reload\n",
    "reload(up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_db = '../data/diffengine-diffs/db/newssniffer-washpo.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [ 730191,  731484,  732087,  735246,  843942, 1076587, 1080957,\n",
    "       1081053, 1081818, 1091741, 1091955, 1092021, 1100479, 1101573,\n",
    "       1101902, 1101955, 1104207, 1109364, 1113377, 1114871, 1115432,\n",
    "       1115718, 1116335, 1116399, 1117664, 1117922, 1120228, 1120722,\n",
    "       1121980, 1128428, 1128734, 1133104, 1135071, 1135145, 1136507,\n",
    "       1136631, 1141170, 1202305, 1284977,  762853,  865873,  868525,\n",
    "        880828,  882871,  903899,  911263,  920160, 1872191, 1881606,\n",
    "       1883065, 1884758, 1885654, 1885680, 1927378, 1942888, 1948425,\n",
    "        740674,  747168,  749023,  753067,  754562,  769174,  774870,\n",
    "        779731,  789463,  790171,  834229,  839990,  856934,  858664,\n",
    "        859288,  866942,  895970,  900597,  930642,  931222,  867921,\n",
    "       1304580, 1371027, 1442681, 1075864, 1076324, 1076900, 1077101,\n",
    "       1077275, 1078681, 1079508, 1083873, 1086413, 1088978, 1089376,\n",
    "       1093861, 1094174, 1099403, 1107274, 1108900, 1110844, 1131649,\n",
    "       1913831, 1947487]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[790171, 834229, 839990, 856934, 858664]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[65:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(wp_db)\n",
    "select_sql = \"SELECT * from entryversion\"\n",
    "limit_line = \"\"\"\n",
    "WHERE entry_id IN (\n",
    "    SELECT DISTINCT entry_id from entryversion WHERE num_versions < 40 ORDER BY RANDOM() LIMIT %s\n",
    ")\"\"\" % 100\n",
    "\n",
    "limit_line = 'WHERE entry_id IN (%s)' % ', '.join(list(map(str, ids[65:70])))\n",
    "wp_df = pd.read_sql(select_sql + '\\n' + limit_line, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.util_newssniffer_parsing' from '../util/util_newssniffer_parsing.py'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd6fd51e2d146efafe7f9468abe5f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wp_df\n",
    "sentence_stats_df, words_stats_df = up.get_sentence_diff_stats(\n",
    "    wp_df,\n",
    "    get_word_diff=True,\n",
    "    get_sentence_vars=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = up.get_sentence_diff_stats(\n",
    "    wp_df,\n",
    "    get_word_diff=True,\n",
    "    get_sentence_vars=True,\n",
    "    output_type='iter'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in t:\n",
    "    i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_added_sents</th>\n",
       "      <th>len_new_doc</th>\n",
       "      <th>num_removed_sents</th>\n",
       "      <th>len_old_doc</th>\n",
       "      <th>num_changed_sents</th>\n",
       "      <th>version_nums</th>\n",
       "      <th>a_id</th>\n",
       "      <th>vars_old</th>\n",
       "      <th>vars_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>834229</td>\n",
       "      <td>({'text': 'ROME—The Dutch Safety Board release...</td>\n",
       "      <td>({'text': 'ROME—The Dutch Safety Board release...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_added_sents  len_new_doc  num_removed_sents  len_old_doc  \\\n",
       "0                7           23                  3           19   \n",
       "\n",
       "   num_changed_sents version_nums    a_id  \\\n",
       "0                  6       (0, 1)  834229   \n",
       "\n",
       "                                            vars_old  \\\n",
       "0  ({'text': 'ROME—The Dutch Safety Board release...   \n",
       "\n",
       "                                            vars_new  \n",
       "0  ({'text': 'ROME—The Dutch Safety Board release...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_removed_words</th>\n",
       "      <th>num_added_words</th>\n",
       "      <th>len_old_sent</th>\n",
       "      <th>len_new_sent</th>\n",
       "      <th>version_nums</th>\n",
       "      <th>s_old</th>\n",
       "      <th>s_new</th>\n",
       "      <th>a_id</th>\n",
       "      <th>s_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>[{'text': 'The', 'tag': ' '}, {'text': 'victim...</td>\n",
       "      <td>[{'text': 'The', 'tag': ' '}, {'text': 'victim...</td>\n",
       "      <td>834229</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_removed_words  num_added_words  len_old_sent  len_new_sent  \\\n",
       "0                  6                5            34            33   \n",
       "\n",
       "  version_nums                                              s_old  \\\n",
       "0       (0, 1)  [{'text': 'The', 'tag': ' '}, {'text': 'victim...   \n",
       "\n",
       "                                               s_new    a_id  s_idx  \n",
       "0  [{'text': 'The', 'tag': ' '}, {'text': 'victim...  834229     19  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sentence Diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_ids = nytimes_article_diffs['article_id'].drop_duplicates().sample(2500)\n",
    "# sample_diffs = nytimes_article_diffs.loc[lambda df: df['article_id'].isin(sample_ids)]\n",
    "nyt_conn = sqlite3.connect('../data/diffengine-diffs/db/newssniffer-nytimes.db')\n",
    "sample_diffs_by_article = pd.read_sql(\"\"\"\n",
    "    SELECT * from entryversion \n",
    "    WHERE entry_id IN (SELECT DISTINCT entry_id from entryversion ORDER BY RANDOM() LIMIT 2500)\n",
    "\"\"\", con=nyt_conn)\n",
    "\n",
    "sample_ids = sample_diffs_by_article['entry_id'].unique()\n",
    "sample_diffs_by_article = sample_diffs_by_article.set_index('entry_id')\n",
    "\n",
    "article_diffs = sample_diffs_by_article.loc[sample_ids[0]].sort_values('version')\n",
    "version_pairs = article_diffs['version'].pipe(lambda s: list(zip(s[:-1], s[1:])))\n",
    "sentence_stats, word_stats = [], []\n",
    "##\n",
    "for a_id in tqdm(sample_ids):\n",
    "    a = sample_diffs_by_article.loc[a_id]\n",
    "    vs = a['version']\n",
    "    a_by_version = a.set_index('version')\n",
    "\n",
    "    for v_old, v_new in list(zip(vs[:-1], vs[1:])):\n",
    "        vars_old, vars_new = up.get_sentence_diff(\n",
    "            a_by_version.loc[v_old]['summary'],\n",
    "            a_by_version.loc[v_new]['summary']\n",
    "        )\n",
    "        \n",
    "        doc_changes = up.get_changes(vars_old, vars_new)\n",
    "        sent_change_pairs = doc_changes['sentences']['changed_sent_pairs']\n",
    "\n",
    "        sentence_stats.append({\n",
    "            'num_added_sents': len(doc_changes['sentences']['added_sents']),\n",
    "            'len_new_doc': len(doc_changes['docs']['new_doc']),\n",
    "            'num_removed_sents': len(doc_changes['sentences']['removed_sents']),\n",
    "            'len_old_doc':len(doc_changes['docs']['old_doc']),\n",
    "            'num_changed_sents': len(doc_changes['sentences']['changed_sent_pairs']),\n",
    "            'version_nums': (v_old, v_new),\n",
    "            'vars_old': vars_old,\n",
    "            'vars_new': vars_new,\n",
    "            'a_id': a_id,\n",
    "        })\n",
    "        \n",
    "        for sent_pair in doc_changes['sentences']['changed_sent_pairs']:\n",
    "            s_old, s_new = up.get_word_diffs(*sent_pair)\n",
    "            word_stats.append({\n",
    "                'num_words_removed': sum(map(lambda x: x['tag'] == '-', s_old)),\n",
    "                'num_words_added': sum(map(lambda x: x['tag'] == '+', s_new)),\n",
    "                'len_old_sent': len(list(filter(lambda x: x['text'] != '' , s_old))),\n",
    "                'len_new_sent': len(list(filter(lambda x: x['text'] != '', s_new))),\n",
    "                'version_nums': (v_old, v_new),\n",
    "                's_old': s_old,\n",
    "                's_new': s_new,\n",
    "                'sent_par': sent_pair,\n",
    "                'a_id': a_id\n",
    "            })\n",
    "\n",
    "sentence_stats_df = pd.DataFrame(sentence_stats)\n",
    "word_stats_df = pd.DataFrame(word_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrections\n",
    "# contributor lines\n",
    "vo, vn = (\n",
    "    sentence_stats_df\n",
    "          .loc[lambda df: df['num_added_sents'] == 10]\n",
    "          .iloc[2]\n",
    "          [['vars_old', 'vars_new']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## possible to-do: explicit positional encoding to spot sentences that were moved\n",
    "\n",
    "display(HTML(up.html_compare_articles(vo, vn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot = copy.deepcopy(vo)\n",
    "vnt = copy.deepcopy(vn)\n",
    "\n",
    "v1o, v1n = up.merge_all_clusters(vot, vnt, slack=.5)\n",
    "display(HTML(up.html_compare_articles(v1o, v1n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved Spot Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = 'However , her meeting with Mr. Xi was canceled Wednesday morning .'\n",
    "a2 = 'United States officials said Mr. Xi had cancelled other meetings scheduled for the day so it did not appear that any slight was intended.'\n",
    "b  = 'The meeting with Mr. Xi was canceled Wednesday morning , although United States officials said they did not think it was intended as a slight because Mr. Xi had also canceled other Wednesday appointments .'\n",
    "\n",
    "\n",
    "a = 'WASHINGTON – For President Obama, the first test of his second term will come quickly this week when Chuck Hagel and John Kerry, his nominees for the two biggest national-security posts, take critical steps toward winning Senate confirmation.'\n",
    "b = 'For President Obama, the first test of his second term passed peacefully on Tuesday as his nominee for defense secretary, Chuck Hagel, sat down with the Republican who poses one of his biggest potential hurdles to Senate confirmation, Senator John McCain of Arizona.'\n",
    "\n",
    "a = 'As Mr. Hagel’s prospects have improved, some analysts say the nominee to watch is Mr. Brennan, the White House counterterrorism adviser Mr. Obama has chosen for the C.I.A..'\n",
    "b = 'With Mr. Hagel’s prospects improving, some analysts say the nominee to watch is Mr. Brennan, whom Mr. Obama has chosen as a permanent replacement for David H. Petraeus at the C.I.A., who resigned in November after admitting to an extramarital affair.'\n",
    "\n",
    "a = 'The report did not identify those countries .' \n",
    "b = 'Choe Sang - Hun reported from Seoul , and Mark Landler from Washington .'\n",
    "\n",
    "up.check_subset(b, a, slack=.5)\n",
    "\n",
    "s1 = a\n",
    "s2 = b\n",
    "# lemmatize and get stopwords\n",
    "s1_lemmas, s2_lemmas = up.get_lemmas(s1), up.get_lemmas(s2)\n",
    "s1_lemmas, s2_lemmas = up.filter_stopword_lemmas(s1_lemmas), up.filter_stopword_lemmas(s2_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot = copy.deepcopy(vo)\n",
    "vnt = copy.deepcopy(vn)\n",
    "cs = up.cluster_edits(vot, vnt)\n",
    "c = cs[0]\n",
    "c = [\n",
    "    (\n",
    "        {'text': 'WASHINGTON – For President Obama, the first test of his second term will come quickly this week when Chuck Hagel and John Kerry, his nominees for the two biggest national-security posts, take critical steps toward winning Senate confirmation.', 'tag': '-'},\n",
    "        {'text': '', 'tag': ' '}\n",
    "    ),\n",
    "    (\n",
    "        {'text': 'They are likely to get very different receptions.', 'tag': '-'},\n",
    "        {'text': '', 'tag': ' '}\n",
    "    ),\n",
    "    (\n",
    "        {'text': '', 'tag': ' '}, {'text': 'WASHINGTON', 'tag': '+'}\n",
    "    ),\n",
    "    (\n",
    "        {'text': '', 'tag': ' '},\n",
    "        {'text': 'For President Obama, the first test of his second term passed peacefully on Tuesday as his nominee for defense secretary, Chuck Hagel, sat down with the Republican who poses one of his biggest potential hurdles to Senate confirmation, Senator John McCain of Arizona.', 'tag': '+'}\n",
    "    ),\n",
    "    (\n",
    "        {'text': '', 'tag': ' '},\n",
    "        {'text': 'By all accounts, the 45-minute one-on-one meeting went well enough for the White House to feel that it has finally turned the tide in favor of Mr. Hagel, whose positions on Israel and Iran have drawn heavy fire from conservatives, pro-Israel groups and other critics.', 'tag': '+'}\n",
    "    ),\n",
    "    (\n",
    "        {'text': '', 'tag': ' '},\n",
    "        {'text': 'While Mr. McCain did not say how he would vote on Mr. Hagel, he told reporters that he would reserve judgment until after Mr. Hagel’s confirmation hearing on Jan. 31.', 'tag': '+'}\n",
    "    ),\n",
    "]\n",
    "\n",
    "t = up.merge_cluster(c, slack=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [\n",
    "    (\n",
    "        {\n",
    "            'text': 'Breaking a deadlock over the location and timing of new talks on its disputed nuclear program, Iran reached agreement on Tuesday with world powers to resume the stuttering dialogue later this month in Kazakhstan, according to the official IRNA news agency.', \n",
    "            'tag': '-'\n",
    "        }, \n",
    "        {\n",
    "            'text': 'Breaking a deadlock over the location and timing of new talks on its disputed nuclear program, Iran said Tuesday it had reached agreement with world powers to resume the stuttering dialogue later this month in Kazakhstan.', \n",
    "            'tag': '+'\n",
    "        }\n",
    "    ), (\n",
    "        {\n",
    "            'text': 'The agreement to meet there on Feb. 26 came in a telephone conversation between senior officials of Iran’s National Security Council and the European Union, representing the outside powers involved in the talks, IRNA said.', \n",
    "            'tag': '-'\n",
    "        }, \n",
    "        {\n",
    "            'text': 'The agreement to meet there on Feb. 26 came in a telephone conversation between senior officials of Iran’s National Security Council and the European Union, representing the outside powers involved in the talks, Iran’s official Islamic Republic News Agency said.', \n",
    "            'tag': '+'\n",
    "        }\n",
    "    ), \n",
    "    (\n",
    "        {'text': '', 'tag': ' '}, \n",
    "        {'text': '.', 'tag': '+'}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up.merge_cluster(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "\n",
    "s1 = 'In Japan , the transport ministry said it would ground the Dreamliners indefinitely , and in India , the aviation regulator said it had grounded the six aircraft operated by the state - owned carrier Air India , Reuters reported .'\n",
    "s2 = 'In India , the aviation regulator grounded all six of the 787s operated by the state - owned carrier Air India .'\n",
    "s3 = 'In Japan the transport ministry issued a formal order to ground all 787s indefinitely, until concerns over the aircraft’s battery systems are resolved.'\n",
    "up.check_subset(s1, s3)\n",
    "up.check_subset(b, a)\n",
    "\n",
    "#############################\n",
    "slack = .3\n",
    "s1 = up.merge_sents_list(s1) if isinstance(s1, list) else s1\n",
    "s2 = up.merge_sents_list(s2) if isinstance(s2, list) else s2\n",
    "# lemmatize and get stopwords\n",
    "s1_lemmas, s2_lemmas = up.get_lemmas(s1), up.get_lemmas(s2)\n",
    "s1_lemmas, s2_lemmas = up.filter_stopword_lemmas(s1_lemmas), up.filter_stopword_lemmas(s2_lemmas)\n",
    "### check match.\n",
    "matches = sum(map(lambda word: word in s1_lemmas, s2_lemmas))\n",
    "matches >= (len(s2_lemmas) * (1 - slack))\n",
    "\n",
    "(len(s2_lemmas) * (1 - slack))\n",
    "\n",
    "sum(map(lambda word: word in s1_lemmas, s2_lemmas))\n",
    "\n",
    "sum(map(lambda word: word in s2_lemmas, s1_lemmas))\n",
    "\n",
    "(len(s2_lemmas) * (1 - slack))\n",
    "\n",
    "(len(s1_lemmas) * (1 - slack))\n",
    "\n",
    "############################\n",
    "a = 'North Korea said on Tuesday that it will both restart its old nuclear reactor, which had provided plutonium fuel for its nuclear weapons until it was mothballed in 2007, and rev up its uranium enrichment.'\n",
    "b = 'North Korea said on Tuesday that it will put all its nuclear facilities — including its operational uranium-enrichment program and its reactors mothballed or under construction — to use in expanding its nuclear weapons arsenal, raising the stakes in the escalating standoff with the United States and its allies.'\n",
    "\n",
    "### get all text (might be a list).\n",
    "s1 = merge_sents_list(a) if isinstance(a, list) else a\n",
    "s2 = merge_sents_list(b) if isinstance(b, list) else b\n",
    "s1, s2 = s2, s1\n",
    "# lemmatize and get stopwords\n",
    "s1_lemmas, s2_lemmas = up.get_lemmas(s1), up.get_lemmas(s2)\n",
    "s1_lemmas, s2_lemmas = filter_stopword_lemmas(s1_lemmas), filter_stopword_lemmas(s2_lemmas)\n",
    "### check match.\n",
    "matches = list(map(lambda word: word in s1_lemmas, s2_lemmas))\n",
    "\n",
    "sum(matches)\n",
    "\n",
    "len(s2_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Diff Generator Ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sentence_stats_df\n",
    "          .loc[lambda df: df['num_added_sents'] == 1]\n",
    "          .iloc[24])\n",
    "\n",
    "a, b = sample_diffs_by_article.loc[593406].loc[lambda df: df['version'].isin((3,4))]['summary']\n",
    "\n",
    "reload(up)\n",
    "\n",
    "a_old_sents = up.split_sents(a)\n",
    "a_new_sents = up.split_sents(b)\n",
    "a_old_sents = list(filter(up.filter_sents, a_old_sents))\n",
    "a_new_sents = list(filter(up.filter_sents, a_new_sents))\n",
    "\n",
    "vo, vn = (sentence_stats_df\n",
    "          .loc[lambda df: df['num_added_sents'] == 1]\n",
    "          .iloc[21]\n",
    "          [['vars_old', 'vars_new']]\n",
    "         )\n",
    "\n",
    "(sentence_stats_df\n",
    "          .loc[lambda df: df['num_added_sents'] == 1]\n",
    "          .iloc[21])\n",
    "\n",
    "a, b = sample_diffs_by_article.loc[592103].loc[lambda df: df['version'].isin((3, 4))]['summary']\n",
    "\n",
    "a_old_sents = up.split_sents(a)\n",
    "a_new_sents = up.split_sents(b)\n",
    "a_old_sents = list(filter(up.filter_sents, a_old_sents))\n",
    "a_new_sents = list(filter(up.filter_sents, a_new_sents))\n",
    "# get_list_diff(a_old_sents, a_new_sents)\n",
    "\n",
    "reload(up)\n",
    "\n",
    "vo, vn = up.get_list_diff(a_old_sents, a_new_sents)\n",
    "\n",
    "display(HTML(up.html_compare_articles(vo, vn)))\n",
    "\n",
    "vot = copy.deepcopy(vo)\n",
    "vnt = copy.deepcopy(vn)\n",
    "\n",
    "display(HTML(up.html_compare_articles(*merge_all_clusters(vo, vn))))\n",
    "\n",
    "\n",
    "\n",
    "(sentence_stats_df\n",
    "          .loc[lambda df: df['num_added_sents'] == 1]\n",
    "          .iloc[4]\n",
    ")\n",
    "a_old, a_new = sample_diffs_by_article.loc[564771].loc[lambda df: df['version'].isin((4,5))]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"ner\"])  # just the parser\n",
    "\n",
    "def get_all_glove_vecs():\n",
    "    glove = open('../data/glove.6B/glove.6B.300d.txt').read()\n",
    "    glove_lines = glove.split('\\n')\n",
    "    glove_lines = list(map(lambda x: x.split(), glove_lines))\n",
    "    glove_words = list(map(lambda x: x[0], glove_lines[:-1]))\n",
    "    glove_vecs = list(map(lambda x: np.array(list(map(float, x[1:]))), glove_lines[:-1]))\n",
    "    return pd.Series(glove_vecs, index=glove_words)\n",
    "\n",
    "def get_sentence_glove_vec(sent):\n",
    "    sent_vec = []\n",
    "    for word in nlp(sent):\n",
    "        word = word.text.lower()\n",
    "        if word in glove:\n",
    "            sent_vec.append(glove[word])\n",
    "    return np.array(sent_vec).mean(axis=0)\n",
    "\n",
    "glove = get_all_glove_vecs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao = 'An earlier version of a picture caption with this article incorrectly described a ceremony being performed by a Navy chaplain for an Air Force sergeant and his partner at a military base in New Jersey.'\n",
    "an = 'A picture caption on Thursday with an article about gay, lesbian and bisexual members of the military service described incorrectly a ceremony being performed by a Navy chaplain for an Air Force sergeant and his partner at a military base in New Jersey.'\n",
    "print(ao)\n",
    "print()\n",
    "print(an)\n",
    "print('ao subset an? %s.' % check_subset(ao, an))\n",
    "print('an subset ao? %s.' % check_subset(an, ao))\n",
    "print('------------------------------------------')\n",
    "\n",
    "ao = 'In a microblog post on Friday, Ran Yunfei, a sharp-tongued writer persecuted for his pro-democracy writings, said he now hoped that Mr. Mo would stand up more boldly for those who have dared to speak truth to power.'\n",
    "an = 'Ran Yunfei, a sharp-tongued writer persecuted for his pro-democracy views, said he was heartened by Mr. Mo’s comments but doubted that he would become a crusader for human rights and free expression.'\n",
    "print(ao)\n",
    "print()\n",
    "print(an)\n",
    "print('ao subset an? %s.' % check_subset(ao, an))\n",
    "print('an subset ao? %s.' % check_subset(an, ao))\n",
    "print('--------------------------------------------')\n",
    "\n",
    "ao = 'He relished his work on the Judiciary Committee.'\n",
    "an = 'He relished the decades he spent on the Judiciary Committee.'\n",
    "print(ao)\n",
    "print()\n",
    "print(an)\n",
    "print('ao subset an? %s.' % check_subset(ao, an))\n",
    "print('an subset ao? %s.' % check_subset(an, ao))\n",
    "print('------------------------------------------')\n",
    "\n",
    "ao = 'Mr. Samaha’s arrest was widely viewed as evidence of a Syrian plot to spread sectarian mayhem in Lebanon.'\n",
    "an = 'Mr. Samaha’s arrest was widely seen as part of Lebanese government efforts to prevent the spread of sectarian mayhem in the country.'\n",
    "print(ao)\n",
    "print()\n",
    "print(an)\n",
    "print('ao subset an? %s.' % check_subset(ao, an))\n",
    "print('an subset ao? %s.' % check_subset(an, ao))\n",
    "print('------------------------------------------')\n",
    "\n",
    "ao = 'An earlier version of this article misstated the distance between Alpha Centauri A and Alpha Centauri B, the two main stars in the triple-star Alpha Centauri system.\t'\n",
    "an = 'An article on Wednesday about a new planet discovered in the Alpha Centauri system misstated the distance between Alpha Centauri A and Alpha Centauri B, the two main stars in the triple-star system.'\n",
    "print(ao)\n",
    "print()\n",
    "print(an)\n",
    "print('ao subset an? %s.' % check_subset(ao, an))\n",
    "print('an subset ao? %s.' % check_subset(an, ao))\n",
    "print('------------------------------------------')\n",
    "\n",
    "ao = 'On Tuesday night, they were here in Charlotte without being here.'\n",
    "an = 'On Thursday night, they appeared in a video and in person before and after their father’s speech, but on Tuesday night, they were here in Charlotte without being here.'\n",
    "print(ao)\n",
    "print()\n",
    "print(an)\n",
    "print('ao subset an? %s.' % check_subset(ao, an))\n",
    "print('an subset ao? %s.' % check_subset(an, ao))\n",
    "print('------------------------------------------')\n",
    "\n",
    "ao = 'President Obama’s first postelection overseas trip will be this month to Asia, where he is to make a historic visit to Myanmar as it moves toward democracy and reinforce his desire to reorient American foreign policy more toward the Pacific during his second term.'\n",
    "an = 'President Obama will make Asia his first overseas destination since his re-election, with a trip this month that is to include a historic visit to Myanmar and underscore his desire to reorient American foreign policy more toward the Pacific during his second term.'\n",
    "print(ao)\n",
    "print()\n",
    "print(an)\n",
    "print('ao subset an? %s.' % check_subset(ao, an))\n",
    "print('an subset ao? %s.' % check_subset(an, ao))\n",
    "print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao_vec, an_vec = get_sentence_glove_vec(ao), get_sentence_glove_vec(an)\n",
    "cosine(ao_vec, an_vec)\n",
    "\n",
    "ao_vec, an_vec = get_sentence_glove_vec(ao), get_sentence_glove_vec(an)\n",
    "cosine(ao_vec, an_vec)\n",
    "\n",
    "a_rand_1 = '“I get in front of the Marines as often as I can, as long as I can get away from Washington, and I’ll be honest with you, I don’t even get a question,” the Marine commandant, James F. Amos, said at the National Press Club last month.'\n",
    "a_rand_2 = \"Aubrey Sarvis, an Army veteran and the executive director of the Servicemembers Legal Defense Network, said in an interview that after the female officers contacted his organization, the Pentagon investigated and the squadron commander and the sergeant major were relieved of their jobs and forced to retire.\"\n",
    "\n",
    "ar_1_vec, ar_2_vec = get_sentence_glove_vec(a_rand_1), get_sentence_glove_vec(a_rand_2)\n",
    "cosine(ar_1_vec, ar_2_vec)\n",
    "\n",
    "print('ao subset an? %s.' % check_subset(a_rand_1, a_rand_2))\n",
    "print('an subset ao? %s.' % check_subset(a_rand_2, a_rand_1))\n",
    "\n",
    "## cases where added sentence is a subset of removed words of other sentences\n",
    "## cases where added sentence is semantically equivalent to removed sentence\n",
    "sentence_stats_df.loc[lambda df: df['num_added_sents'] == 1].iloc[0][['version_nums', 'a_id']]\n",
    "list(filter(lambda x: x['tag'] == '+', vn))\n",
    "list(map(lambda x: x['text'], vo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put version numbers in all of the auxiliary databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "select_sql = \"SELECT * from entryversion\"\n",
    "\n",
    "for db in tqdm(list(filter(lambda x: 'newssniffer' not in x, dbs))):\n",
    "    db_path, db_name = os.path.dirname(db), os.path.basename(db)\n",
    "    con = sqlite3.connect(db)\n",
    "    df = pd.read_sql(select_sql, con=con)\n",
    "    df = (df\n",
    "     .pipe(lambda df: \n",
    "           pd.concat([df,\n",
    "                      df.sort_values(['entry_id', 'id'])\n",
    "                         .groupby('entry_id')['id']\n",
    "                         .rank(method='dense')\n",
    "                         .pipe(lambda s: s-1)\n",
    "                         .to_frame('version')\n",
    "                     ], axis=1)\n",
    "           )\n",
    "    )\n",
    "    df.to_sql('entryversion_v2', con, if_exists='replace', index=False)\n",
    "\n",
    "# pd.read_sql('select * from entryversion_v2 limit 100 ', con)['title'] == pd.read_sql('select * from entryversion limit 100 ', con)['title']\n",
    "\n",
    "for db in tqdm(list(filter(lambda x: 'newssniffer' not in x, dbs))[11:]):\n",
    "    con = sqlite3.connect(db)\n",
    "    con.execute('DROP TABLE IF EXISTS entryversion')\n",
    "    con.execute('ALTER TABLE entryversion_v2 RENAME TO entryversion;')\n",
    "\n",
    "for db in tqdm(list(filter(lambda x: 'newssniffer' not in x, dbs))):\n",
    "    db_path, db_name = os.path.dirname(db), os.path.basename(db)\n",
    "    con = sqlite3.connect(db)\n",
    "\n",
    "con = sqlite3.connect('../data/diffengine-diffs/db/ap.db')\n",
    "\n",
    "(dfs['ap.db']\n",
    " .pipe(lambda df: \n",
    "       pd.concat([df,\n",
    "                  df.sort_values(['entry_id', 'id'])\n",
    "                     .groupby('entry_id')['id']\n",
    "                     .rank(method='dense')\n",
    "                     .pipe(lambda s: s-1)\n",
    "                     .to_frame('version')\n",
    "                 ], axis=1)\n",
    "       )\n",
    " .drop('id', axis=1)\n",
    ").head(2)\n",
    "\n",
    "\n",
    "dfs['ap.db'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Running containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211d09e82c0d4235a5f31f96767cd19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "all_running_docker_programs = []\n",
    "for i in tqdm([1, 2, 3, 4, 5, 6]):\n",
    "    a = ! gcloud compute ssh --zone \"us-central1-a\" \"edit-parser-1-$i\" --project \"usc-research\" --command \"docker ps --no-trunc\"\n",
    "    all_running_docker_programs += a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_of_interest = list(filter(lambda x: \n",
    "                               'us.gcr.io/usc-research/edit-parser' in x or\n",
    "                               'python3 parsing_script.py' in x, all_running_docker_programs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs_still_running = pd.DataFrame(list(map(lambda x: x.split(), jobs_of_interest)))[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_db_list = [\n",
    "    'ap',\n",
    "    'bbc-1',\n",
    "    'bbc-2',\n",
    "#     'calgaryherald',\n",
    "#     'canadaland',\n",
    "    'cbc',\n",
    "    'cnn',\n",
    "    'dailymail',\n",
    "#     'fox',\n",
    "#     'globemail',\n",
    "    'guardian',\n",
    "    'independent',\n",
    "#     'lapresse',\n",
    "#     'nationalpost',\n",
    "    'nyt',\n",
    "    'reuters',\n",
    "#     'telegraph',\n",
    "#     'therebel',\n",
    "    'torontostar',\n",
    "#     'torontosun',\n",
    "#     'whitehouse',\n",
    "#     'wp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           bbc-2\n",
       "1         reuters\n",
       "2        guardian\n",
       "3             ago\n",
       "4             nyt\n",
       "5             nyt\n",
       "6             cbc\n",
       "7             cnn\n",
       "8     independent\n",
       "9        guardian\n",
       "10      dailymail\n",
       "11    torontostar\n",
       "12          bbc-2\n",
       "13          bbc-2\n",
       "14          bbc-2\n",
       "15          bbc-2\n",
       "16            nyt\n",
       "17            nyt\n",
       "18            nyt\n",
       "19             ap\n",
       "20          bbc-2\n",
       "21          bbc-2\n",
       "22          bbc-2\n",
       "23          bbc-2\n",
       "24            ago\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbs_still_running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbc-1'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(full_db_list) - set(dbs_still_running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import datastore\n",
    "##\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/alex/.google-cloud/usc-research-data-access.json'\n",
    "ds_client = datastore.Client()\n",
    "##\n",
    "q = (ds_client\n",
    "     .query(kind='edit-paths-sentence-stats')\n",
    "     .add_filter('source', '=', 'bbc-1'))\n",
    "r = list(q.fetch())\n",
    "a_ids = list(set(map(lambda x: str(x['a_id']), r)))\n",
    "to_add = \"AND entry_id not in (%s)\" % ', '.join(a_ids)\n",
    "to_add += \"AND summary != ''\"\n",
    "\n",
    "select_sql = \"SELECT * from entryversion\"\n",
    "limit_line = \"WHERE num_versions < %s AND num_versions > 1 %s\" % (40, to_add)\n",
    "select_sql += '\\n' + limit_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99082"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"\"\"select count(1) from entryversion\"\"\", con=con).iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>summary</th>\n",
       "      <th>created</th>\n",
       "      <th>archive_url</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>num_versions</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>Obama commutes Chelsea Manning sentence - BBC ...</td>\n",
       "      <td>http://www.bbc.co.uk/news/world-us-canada-3865...</td>\n",
       "      <td>\\n        \\n            \\n                \\n  ...</td>\n",
       "      <td>2017-01-18 00:30:03.671672</td>\n",
       "      <td>https://wayback.archive.org/web/20170118003022...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>Obama commutes Chelsea Manning sentence - BBC ...</td>\n",
       "      <td>http://www.bbc.co.uk/news/world-us-canada-3865...</td>\n",
       "      <td>\\n        \\n            \\n                \\n  ...</td>\n",
       "      <td>2017-01-18 02:00:03.848093</td>\n",
       "      <td>https://wayback.archive.org/web/20170118020022...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>Obama commutes Chelsea Manning sentence - BBC ...</td>\n",
       "      <td>http://www.bbc.co.uk/news/world-us-canada-3865...</td>\n",
       "      <td>\\n        \\n            \\n                \\n  ...</td>\n",
       "      <td>2017-01-18 03:00:03.726020</td>\n",
       "      <td>https://wayback.archive.org/web/20170118030022...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>Obama commutes Chelsea Manning sentence - BBC ...</td>\n",
       "      <td>http://www.bbc.co.uk/news/world-us-canada-3865...</td>\n",
       "      <td>\\n        \\n            \\n                \\n  ...</td>\n",
       "      <td>2017-01-18 07:00:04.058084</td>\n",
       "      <td>https://wayback.archive.org/web/20170118070023...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>Obama commutes Chelsea Manning sentence - BBC ...</td>\n",
       "      <td>http://www.bbc.co.uk/news/world-us-canada-3865...</td>\n",
       "      <td>\\n        \\n            \\n                \\n  ...</td>\n",
       "      <td>2017-01-18 09:00:03.482641</td>\n",
       "      <td>https://wayback.archive.org/web/20170118090023...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   id                                              title  \\\n",
       "0     61   62  Obama commutes Chelsea Manning sentence - BBC ...   \n",
       "1     69   70  Obama commutes Chelsea Manning sentence - BBC ...   \n",
       "2     78   79  Obama commutes Chelsea Manning sentence - BBC ...   \n",
       "3    100  101  Obama commutes Chelsea Manning sentence - BBC ...   \n",
       "4    119  120  Obama commutes Chelsea Manning sentence - BBC ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.bbc.co.uk/news/world-us-canada-3865...   \n",
       "1  http://www.bbc.co.uk/news/world-us-canada-3865...   \n",
       "2  http://www.bbc.co.uk/news/world-us-canada-3865...   \n",
       "3  http://www.bbc.co.uk/news/world-us-canada-3865...   \n",
       "4  http://www.bbc.co.uk/news/world-us-canada-3865...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  \\n        \\n            \\n                \\n  ...   \n",
       "1  \\n        \\n            \\n                \\n  ...   \n",
       "2  \\n        \\n            \\n                \\n  ...   \n",
       "3  \\n        \\n            \\n                \\n  ...   \n",
       "4  \\n        \\n            \\n                \\n  ...   \n",
       "\n",
       "                      created  \\\n",
       "0  2017-01-18 00:30:03.671672   \n",
       "1  2017-01-18 02:00:03.848093   \n",
       "2  2017-01-18 03:00:03.726020   \n",
       "3  2017-01-18 07:00:04.058084   \n",
       "4  2017-01-18 09:00:03.482641   \n",
       "\n",
       "                                         archive_url  entry_id  num_versions  \\\n",
       "0  https://wayback.archive.org/web/20170118003022...         1             9   \n",
       "1  https://wayback.archive.org/web/20170118020022...         1             9   \n",
       "2  https://wayback.archive.org/web/20170118030022...         1             9   \n",
       "3  https://wayback.archive.org/web/20170118070023...         1             9   \n",
       "4  https://wayback.archive.org/web/20170118090023...         1             9   \n",
       "\n",
       "   version  \n",
       "0      2.0  \n",
       "1      3.0  \n",
       "2      4.0  \n",
       "3      5.0  \n",
       "4      6.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"\"\"\n",
    "SELECT * from entryversion\n",
    "WHERE num_versions < 40 AND num_versions > 1\n",
    "order by entry_id \n",
    "LIMIT 5 OFFSET 2\n",
    "\"\"\", con= con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
