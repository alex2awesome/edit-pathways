{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import sys\n",
    "sys.path.append('../util')\n",
    "import util_data_access as da\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import pandas as pd \n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import spark_processing_scripts.util_spark as sus\n",
    "import spark_processing_scripts.util_general as sug\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': 'http://s3.dev.obdc.bcs.bloomberg.com'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'nyt'\n",
    "if not os.path.exists('%s_output' % db_name):\n",
    "     os.makedirs('%s_output' % db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm(fs.ls('aspangher/edit-pathways/spark_processing_scripts-output/%s/' % db_name)):\n",
    "    fs.get(f, '%s_output/%s' % (db_name, os.path.basename(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## why does this not work?\n",
    "fs.get('aspangher/edit-pathways/spark_processing_scripts-output/%s/' % db_name, '%s_output' % db_name, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da.download_file('guardian.db', 'edit-pathways/dbs/newssniffer-guardian.db.gz')\n",
    "# ! gunzip guardian.db.gz\n",
    "# fs.ls('aspangher/edit-pathways/spark_processing_scripts-output_sentences/nyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d90c59dc4e746b09d13bea2a5604c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/826 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "for f in tqdm(glob.glob('%s_output/*' % db_name)):\n",
    "    df = pd.read_csv(f, compression=None, index_col=0)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_diffs_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278826, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_diffs_df[['entry_id', 'version_x', 'version_y']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1348675</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1350005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1351256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1348265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1351613</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entry_id version_x version_y  sent_idx_x  sent_idx_y  \\\n",
       "0  1348675         0         1         1.0         1.0   \n",
       "1  1350005         0         1        21.0        21.0   \n",
       "2  1351256         0         1        37.0        37.0   \n",
       "3  1348265         0         1         9.0        15.0   \n",
       "4  1351613         2         3        91.0        91.0   \n",
       "\n",
       "   avg_sentence_distance_x  avg_sentence_distance_y  \n",
       "0                      0.0                      0.0  \n",
       "1                      0.0                      0.0  \n",
       "2                      0.0                      0.0  \n",
       "3                      0.0                      0.0  \n",
       "4                      0.0                      0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_diffs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15674824\n",
       "Name: c, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_diffs_df\n",
    " .assign(c=1)\n",
    " .groupby(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['c']\n",
    " .sum()\n",
    " .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Against Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: wp.db already exists; do you wish to overwrite (y or n)? ^C\n"
     ]
    }
   ],
   "source": [
    "remote_name = sug.conn_mapper_dict[db_name]\n",
    "da.download_file('%s.db.gz' % db_name, 'edit-pathways/dbs/%s.db.gz' % remote_name)\n",
    "! gunzip $db_name\\.db\\.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('%s.db' % db_name)\n",
    "# full_df = pd.read_sql('select * from entryversion where num_versions > 1 and num_versions < 40 ', con=con)\n",
    "eligible_ids = pd.read_sql('select entry_id, version from entryversion where num_versions > 1 and num_versions < 40 ', con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = []\n",
    "for entry_id, versions in (\n",
    "    eligible_ids\n",
    "        .groupby('entry_id')\n",
    "        .aggregate(list)['version']\n",
    "        .iteritems()\n",
    "):\n",
    "    for version_pair in zip(versions[:-1], versions[1:]):\n",
    "        expected.append({'entry_id': entry_id, 'version_pair': version_pair})\n",
    "\n",
    "expected_df = pd.DataFrame(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48650, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48238, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_diffs_df\n",
    " [['entry_id', 'version_x', 'version_y']]\n",
    " .drop_duplicates()\n",
    " .shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18997, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_diffs_df\n",
    " [['entry_id']]\n",
    " .drop_duplicates()\n",
    " .shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19176,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_df['entry_id'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea81f492fbd449ca1dddc8488e0e31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_dfs = []\n",
    "for f in tqdm(glob.glob('%s_pqs/*' % db_name)):\n",
    "    df = pd.read_parquet(f)\n",
    "    all_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_full_diffs_df = full_diffs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_full_diffs_df = (full_diffs_df\n",
    " .fillna('nan')\n",
    " .drop_duplicates(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])\n",
    " .replace(to_replace='nan', value=np.nan)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1265845</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1343259</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1317302</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361393</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1291614</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  version_x  version_y  sent_idx_x  sent_idx_y  \\\n",
       "0   1265845          0          1        44.0        44.0   \n",
       "1   1343259          0          1        25.0        25.0   \n",
       "2   1317302          1          2         3.0         3.0   \n",
       "3   1361393          0          1        37.0        37.0   \n",
       "4   1291614          0          1        46.0        45.0   \n",
       "\n",
       "   avg_sentence_distance_x  avg_sentence_distance_y  \n",
       "0                    0.000                    0.000  \n",
       "1                    0.000                    0.000  \n",
       "2                    0.000                    0.000  \n",
       "3                    0.000                    0.000  \n",
       "4                    0.125                    0.125  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_full_diffs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## final files\n",
    "import sqlite3\n",
    "with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "    output_full_diffs_df.to_sql('matched_sentences', con=con, index=False, chunksize=10000, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.upload_file('2021-05-19__partial-nyt-output.pkl', 'edit-pathways/output_for_sheena/2021-05-25__partial-nyt-matched-output.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## intermediate files\n",
    "fname = '2021-05-26__newssniffer-bbc-diffs-output.pkl'\n",
    "output_full_diffs_df.to_pickle(fname, compression='gzip', chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.upload_file(fname, 'edit-pathways/output_for_sheena/%s' % fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.upload_file('nyt_sent_output/df_nyt__start_0__end_20000__num_1.pkl', 'edit-pathways/output_for_sheena/df_nyt__start_0__end_20000__num_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import os \n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': 'http://s3.dev.obdc.bcs.bloomberg.com'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentences\n",
    "db_name = 'nyt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('%s_sent_output' % db_name):\n",
    "    os.makedirs('%s_sent_output' % db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137e955ae634d87a0ccc05b724624f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for f in tqdm(fs.ls('aspangher/edit-pathways/spark_processing_scripts-output_sentences/%s' % db_name)):\n",
    "    fname = f.split('/')[-1]\n",
    "    fs.get(f, '%s_sent_output/%s' % (db_name, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ab2cbf82d440cb9cf9a21b95dc2079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## check if expected entry_ids are there before dumping to SQLite\n",
    "import glob\n",
    "import pandas as pd \n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "all_entry_ids = []\n",
    "for f in tqdm(glob.glob('%s_sent_output/*' % db_name)):\n",
    "    entry_ids = pd.read_pickle(f, compression='gzip')['entry_id'].drop_duplicates()\n",
    "    all_entry_ids.append(entry_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19176,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(all_entry_ids).drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "    con.execute('DROP TABLE IF EXISTS split_sentences;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecf43ef4d444e45aeeeaa1bb837df67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sent_dfs = []\n",
    "sent_file_list = glob.glob('%s_sent_output/*' % db_name)\n",
    "\n",
    "# if db_name == 'guardian':\n",
    "#     sent_file_list = list(filter(lambda x: int(re.search('end_(\\d+)', x)[1]) - int(re.search('start_(\\d+)', x)[1]) == 5000, sent_file_list))\n",
    "#     sent_file_list = sorted(sent_file_list, key=lambda x: int(re.search('num_(\\d+)', x)[1]))\n",
    "\n",
    "for f in tqdm(sent_file_list):\n",
    "    sent_df = pd.read_pickle(f, compression='gzip')\n",
    "    ## final files\n",
    "    import sqlite3\n",
    "    with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "        sent_df.to_sql('split_sentences', con=con, index=False, chunksize=5000, if_exists='append')\n",
    "#     break\n",
    "#     sent_dfs.append(sent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(distinct entry_id)\n",
      "0                     19176\n",
      "   count(distinct entry_id)\n",
      "0                     18997\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "    print(pd.read_sql('SELECT count(distinct entry_id) from split_sentences', con=con))\n",
    "    print(pd.read_sql('SELECT count(distinct entry_id) from matched_sentences', con=con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "    con.execute('''\n",
    "        DELETE   FROM split_sentences\n",
    "        WHERE    rowid not in\n",
    "                 (\n",
    "                 select  min(rowid)\n",
    "                 from split_sentences\n",
    "                 group by\n",
    "                     entry_id,\n",
    "                     version,\n",
    "                     sent_idx\n",
    "                 )\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gzip $db_name-matched-sentences\\.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'spark_output_final'\n",
    "# dir_name = 'output_for_sheena'\n",
    "fs.put(\n",
    "    '%s-matched-sentences.db.gz' % db_name, \n",
    "    'aspangher/edit-pathways/%s/%s-matched-sentences.db.gz' % (dir_name, db_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! aws s3api put-object-acl --bucket aspangher --key edit-pathways/spark_output_final/nyt-matched-sentences.db.gz --acl public-read --endpoint http://s3.dev.obdc.bcs.bloomberg.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_entry_versions = (full_diffs_df\n",
    " .set_index('entry_id')[['version_x', 'version_y']]\n",
    " .unstack()\n",
    " .to_frame('version')\n",
    " .reset_index()\n",
    " .drop('level_0', axis=1)\n",
    " .drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79292, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df[['entry_id', 'version']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71073, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sent_df[['entry_id','version']]\n",
    " .drop_duplicates()\n",
    " .merge(\n",
    "     calc_entry_versions, \n",
    "     right_on=['entry_id', 'version'], \n",
    "     left_on=['entry_id', 'version'], \n",
    "     how='inner'\n",
    " ).shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at fetching operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../spark_processing_scripts')\n",
    "import util_general as sug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = sug.s3_output_dir_main if not True else sug.s3_output_dir_sentences\n",
    "file_count = len(sug.get_files(s3_path, db_name, sug.csv_pat)) if not True else len(sug.get_files(s3_path, db_name, sug.pkl_pat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'wp'\n",
    "t = sug.download_prefetched_data(db_name, format='csv', split_sentences=False, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefetched_file_idx, last_one, to_fetch_df = sug.download_pq_to_df(db_name, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'newssniffer-washpo-\\d+.pq', re.UNICODE)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_progress' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-cda12bb5bbb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'show_progress' is not defined"
     ]
    }
   ],
   "source": [
    "prefetched_entry_id_list = []\n",
    "fname = ug.conn_mapper_dict[db_name]\n",
    "file_list = ug.get_fs().ls(ug.s3_pq_dir)\n",
    "file_pattern = re.compile(r'%s-\\d+.pq' % fname)\n",
    "file_list = list(enumerate(filter(lambda x: re.search(file_pattern, x), file_list)))\n",
    "file_list = file_list[0:]\n",
    "if show_progress:\n",
    "    file_list = tqdm(file_list)\n",
    "for f_idx, fname in file_list:\n",
    "    with get_fs().open(fname) as f:\n",
    "        full_df = pd.read_parquet(f)\n",
    "    full_df = full_df.loc[lambda df: ~df['entry_id'].isin(prefetched_entry_id_list)]\n",
    "    if len(full_df['entry_id'].drop_duplicates()) > 50:\n",
    "        last_one = f_idx < (len(file_list) - 1)\n",
    "        return f_idx, last_one, full_df\n",
    "if len(file_list) == 0:\n",
    "    f_idx = 0\n",
    "last_one = f_idx < (len(file_list) - 1)\n",
    "return f_idx, last_one, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fetch_df = ug.download_pq_to_df(db_name, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "db_name = 'guardian'\n",
    "prefetched_entry_id_list = t.values\n",
    "fname = ug.conn_mapper_dict[db_name]\n",
    "file_list = ug.get_fs().ls(ug.s3_pq_dir)\n",
    "file_pattern = re.compile(r'%s-\\d+.pq' % fname)\n",
    "file_list = list(filter(lambda x: re.search(file_pattern, x), file_list))\n",
    "\n",
    "if False:\n",
    "    all_full_dfs = []\n",
    "    for f_idx, fname in enumerate(file_list):\n",
    "        with ug.get_fs().open(fname) as f:\n",
    "            full_df = pd.read_parquet(f)\n",
    "\n",
    "        print(f_idx)\n",
    "        print('pre-filtering')\n",
    "        print(full_df.shape)\n",
    "        print(full_df['entry_id'].drop_duplicates().shape)\n",
    "        all_full_dfs.append(full_df.copy())\n",
    "        full_df = full_df.loc[lambda df: ~df['entry_id'].isin(prefetched_entry_id_list)]\n",
    "        print('post-filtering')\n",
    "        print(full_df.shape)\n",
    "        print(full_df['entry_id'].drop_duplicates().shape)\n",
    "        if len(full_df['entry_id'].drop_duplicates()) > 50:\n",
    "            print('here')#full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat(all_full_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714873, 12)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['entry_id'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'independent'\n",
    "remote_name = sug.conn_mapper_dict[db_name]\n",
    "\n",
    "# da.download_file('newssniffer-washpo.db.gz', 'edit-pathways/dbs/newssniffer-washpo.db.gz')\n",
    "if not (os.path.exists('%s.db.gz' % db_name) or os.path.exists('%s.db' % db_name)):\n",
    "    fs.get('aspangher/edit-pathways/dbs/%s.db.gz' % remote_name, '%s.db.gz' % db_name)\n",
    "    ! gunzip $db_name\\.db\\.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "with sqlite3.connect('%s.db' % db_name) as con:\n",
    "    entry_ids = pd.read_sql('select DISTINCT entry_id from entryversion', con=con)['entry_id']\n",
    "#     full_df = pd.read_sql('select * from entryversion', chunksize=5000, con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55009,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('%s_pqs' % db_name):\n",
    "    os.makedirs('%s_pqs' % db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d3cc4a85034dc2a4ad65ed6eb74c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunk_size = 20000\n",
    "for chunk_idx, (s_idx, e_idx) in tqdm(enumerate(\n",
    "    zip(\n",
    "        range(0, len(entry_ids), chunk_size), \n",
    "        range(chunk_size, len(entry_ids) + chunk_size, chunk_size)\n",
    "    )\n",
    ")):\n",
    "    chunk_ids = entry_ids[s_idx: e_idx].values.tolist()\n",
    "    with sqlite3.connect('%s.db' % db_name) as con:\n",
    "        chunk_df = pd.read_sql('''\n",
    "                                SELECT * FROM entryversion\n",
    "                                WHERE entry_id IN (%s)\n",
    "        ''' % ', '.join(list(map(str, chunk_ids))), con=con)\n",
    "\n",
    "    (chunk_df\n",
    "     .to_parquet('%(db_name)s_pqs/%(db_name)s-%(num)s.pq' % ({'db_name': db_name, 'num': chunk_idx + 1}))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8490097f6c489089bfba98d543f164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "for f in tqdm(glob.glob('%s_pqs/*' % db_name)):\n",
    "    remote_fname = os.path.basename(f).replace(db_name, remote_name)\n",
    "    da.upload_file(f, 'edit-pathways/pqs/' + remote_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newssniffer-independent-3.pq'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress\n",
    "                                edits       sentences\n",
    "ap.db                           in-prog\n",
    "bbc.db                          ~~~~~ \n",
    "calgaryherald.db              \n",
    "canadaland.db\n",
    "cbc.db\n",
    "cnn.db\n",
    "dailymail.db\n",
    "fox.db\n",
    "globemail.db\n",
    "lapresse.db\n",
    "nationalpost.db\n",
    "newssniffer-bbc.db.gz          in-prog             \n",
    "newssniffer-guardian.db.gz     in-prog\n",
    "newssniffer-independent.db\n",
    "newssniffer-nytimes.db.gz      x           x \n",
    "newssniffer-washpo.db          in-prog\n",
    "reuters.db.gz                  x \n",
    "telegraph.db \n",
    "therebel.db\n",
    "torontostar.db\n",
    "torontosun.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
