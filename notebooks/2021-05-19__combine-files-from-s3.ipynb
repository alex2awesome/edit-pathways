{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import sys\n",
    "sys.path.append('../util')\n",
    "import util_data_access as da\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import pandas as pd \n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import spark_processing_scripts.util_spark as sus\n",
    "import spark_processing_scripts.util_general as sug\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': 'http://s3.dev.obdc.bcs.bloomberg.com'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'cnn'\n",
    "if not os.path.exists('%s_output' % db_name):\n",
    "     os.makedirs('%s_output' % db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e22c0358b5442aaa7fa50a63a471b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for f in tqdm(fs.ls('aspangher/edit-pathways/spark_processing_scripts-output/%s/' % db_name)):\n",
    "    fs.get(f, '%s_output/%s' % (db_name, os.path.basename(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da.download_file('guardian.db', 'edit-pathways/dbs/newssniffer-guardian.db.gz')\n",
    "# ! gunzip guardian.db.gz\n",
    "# fs.ls('aspangher/edit-pathways/spark_processing_scripts-output_sentences/nyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18aa10b38dad4851a9aab50714c1ce02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "for f in tqdm(glob.glob('%s_output/*' % db_name)):\n",
    "    df = pd.read_csv(f, compression=None, index_col=0)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_diffs_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35858, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_diffs_df[['entry_id', 'version_x', 'version_y']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2550</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2594</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2584</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  version_x  version_y  sent_idx_x  sent_idx_y  \\\n",
       "0      2550          2          3        28.0        28.0   \n",
       "1      3265          0          1         NaN         0.0   \n",
       "2      2594          0          1        55.0        55.0   \n",
       "3      2584          0          1        18.0         NaN   \n",
       "4      2951          0          1        37.0        36.0   \n",
       "\n",
       "   avg_sentence_distance_x  avg_sentence_distance_y  \n",
       "0                      0.0                      0.0  \n",
       "1                      NaN                      NaN  \n",
       "2                      0.0                      0.0  \n",
       "3                      NaN                      NaN  \n",
       "4                      0.0                      NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_diffs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1797573\n",
       "Name: c, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_diffs_df\n",
    " .assign(c=1)\n",
    " .groupby(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])['c']\n",
    " .sum()\n",
    " .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Against Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: cnn.db already exists; do you wish to overwrite (y or n)? ^C\n"
     ]
    }
   ],
   "source": [
    "remote_name = sug.conn_mapper_dict[db_name]\n",
    "da.download_file('%s.db.gz' % db_name, 'edit-pathways/dbs/%s.db.gz' % remote_name)\n",
    "! gunzip $db_name\\.db\\.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('%s.db' % db_name)\n",
    "# full_df = pd.read_sql('select * from entryversion where num_versions > 1 and num_versions < 40 ', con=con)\n",
    "eligible_ids = pd.read_sql('select entry_id, version from entryversion where num_versions > 1 and num_versions < 40 ', con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "summs = pd.read_sql('select entry_id, version, summary from entryversion where num_versions > 1 and num_versions < 40 ', con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1555      1463\n",
       "8697     11512\n",
       "11066    11512\n",
       "11276    15393\n",
       "11308    15511\n",
       "11507    15794\n",
       "13431    11512\n",
       "13695    11512\n",
       "13990    18357\n",
       "14704    19084\n",
       "15093    19419\n",
       "16337    19084\n",
       "16510    19084\n",
       "16601    20494\n",
       "16942    21019\n",
       "18717     9299\n",
       "18718     9298\n",
       "18719     9297\n",
       "18724     9292\n",
       "18725     9290\n",
       "18730     9285\n",
       "18733     9241\n",
       "18736     9163\n",
       "18737     9160\n",
       "18738     9157\n",
       "18740     9131\n",
       "18741     9130\n",
       "18742     9128\n",
       "18744     9126\n",
       "18746     9111\n",
       "         ...  \n",
       "29003    26041\n",
       "29004    26038\n",
       "29005    26037\n",
       "29008    26082\n",
       "29009    26077\n",
       "29010    26075\n",
       "29011    26073\n",
       "29018    26097\n",
       "29019    26096\n",
       "29021    26094\n",
       "34943    20494\n",
       "35181    18357\n",
       "35419    15794\n",
       "39581    27218\n",
       "39831    27693\n",
       "42107    26717\n",
       "49519    15794\n",
       "50456     1463\n",
       "51772    15511\n",
       "53399    15393\n",
       "54513    27693\n",
       "54559    27218\n",
       "55257    20494\n",
       "55474    18357\n",
       "58724    26717\n",
       "59634    35762\n",
       "62602    29379\n",
       "62742    20011\n",
       "64948    57979\n",
       "64950    57979\n",
       "Name: entry_id, Length: 6041, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summs.loc[lambda df: df['summary'] == '']['entry_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = []\n",
    "for entry_id, versions in (\n",
    "    eligible_ids\n",
    "        .groupby('entry_id')\n",
    "        .aggregate(list)['version']\n",
    "        .iteritems()\n",
    "):\n",
    "    for version_pair in zip(versions[:-1], versions[1:]):\n",
    "        expected.append({'entry_id': entry_id, 'version_pair': version_pair})\n",
    "\n",
    "expected_df = pd.DataFrame(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45902, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35858, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_diffs_df\n",
    " [['entry_id', 'version_x', 'version_y']]\n",
    " .drop_duplicates()\n",
    " .shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18135, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_diffs_df\n",
    " [['entry_id']]\n",
    " .drop_duplicates()\n",
    " .shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19965,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_df['entry_id'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_full_diffs_df = full_diffs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_full_diffs_df = (full_diffs_df\n",
    " .fillna('nan')\n",
    " .drop_duplicates(['entry_id', 'version_x', 'version_y', 'sent_idx_x', 'sent_idx_y'])\n",
    " .replace(to_replace='nan', value=np.nan)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>version_x</th>\n",
       "      <th>version_y</th>\n",
       "      <th>sent_idx_x</th>\n",
       "      <th>sent_idx_y</th>\n",
       "      <th>avg_sentence_distance_x</th>\n",
       "      <th>avg_sentence_distance_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30458</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.396817</td>\n",
       "      <td>0.398281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29404</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28893</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29426</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.230220</td>\n",
       "      <td>0.230220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29439</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  version_x  version_y  sent_idx_x  sent_idx_y  \\\n",
       "0     30458          0          1        17.0        19.0   \n",
       "1     29404          0          1         8.0         8.0   \n",
       "2     28893          0          1        12.0        12.0   \n",
       "3     29426          0          1         4.0         4.0   \n",
       "4     29439          0          1         NaN         9.0   \n",
       "\n",
       "   avg_sentence_distance_x  avg_sentence_distance_y  \n",
       "0                 0.396817                 0.398281  \n",
       "1                 0.000000                 0.000000  \n",
       "2                 0.000000                 0.000000  \n",
       "3                 0.230220                 0.230220  \n",
       "4                      NaN                      NaN  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_full_diffs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## final files\n",
    "import sqlite3\n",
    "with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "    output_full_diffs_df.to_sql('matched_sentences', con=con, index=False, chunksize=10000, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.upload_file('2021-05-19__partial-nyt-output.pkl', 'edit-pathways/output_for_sheena/2021-05-25__partial-nyt-matched-output.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## intermediate files\n",
    "fname = '2021-05-26__newssniffer-bbc-diffs-output.pkl'\n",
    "output_full_diffs_df.to_pickle(fname, compression='gzip', chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.upload_file(fname, 'edit-pathways/output_for_sheena/%s' % fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.upload_file('nyt_sent_output/df_nyt__start_0__end_20000__num_1.pkl', 'edit-pathways/output_for_sheena/df_nyt__start_0__end_20000__num_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import os \n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': 'http://s3.dev.obdc.bcs.bloomberg.com'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentences\n",
    "db_name = 'cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('%s_sent_output' % db_name):\n",
    "    os.makedirs('%s_sent_output' % db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5621d7e5c52144cdbf13e62470daebb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for f in tqdm(fs.ls('aspangher/edit-pathways/spark_processing_scripts-output_sentences/%s' % db_name)):\n",
    "    fname = f.split('/')[-1]\n",
    "    fs.get(f, '%s_sent_output/%s' % (db_name, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807efbc6f9254681afa56b4c469f9319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## check if expected entry_ids are there before dumping to SQLite\n",
    "import glob\n",
    "import pandas as pd \n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "all_entry_ids = []\n",
    "for f in tqdm(glob.glob('%s_sent_output/*' % db_name)):\n",
    "    entry_ids = pd.read_pickle(f, compression='gzip')['entry_id'].drop_duplicates()\n",
    "    all_entry_ids.append(entry_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19957,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(all_entry_ids).drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "    con.execute('DROP TABLE IF EXISTS split_sentences;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bebd719f9b42999ee5fc7766c29b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sent_dfs = []\n",
    "sent_file_list = glob.glob('%s_sent_output/*' % db_name)\n",
    "\n",
    "# if db_name == 'guardian':\n",
    "#     sent_file_list = list(filter(lambda x: int(re.search('end_(\\d+)', x)[1]) - int(re.search('start_(\\d+)', x)[1]) == 5000, sent_file_list))\n",
    "#     sent_file_list = sorted(sent_file_list, key=lambda x: int(re.search('num_(\\d+)', x)[1]))\n",
    "\n",
    "for f in tqdm(sent_file_list):\n",
    "    sent_df = pd.read_pickle(f, compression='gzip')\n",
    "    ## final files\n",
    "    import sqlite3\n",
    "    with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "        sent_df.to_sql('split_sentences', con=con, index=False, chunksize=5000, if_exists='append')\n",
    "#     break\n",
    "#     sent_dfs.append(sent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(distinct entry_id)\n",
      "0                     26530\n",
      "   count(distinct entry_id)\n",
      "0                     26529\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "    print(pd.read_sql('SELECT count(distinct entry_id) from split_sentences', con=con))\n",
    "    print(pd.read_sql('SELECT count(distinct entry_id) from matched_sentences', con=con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('%s-matched-sentences.db' % db_name) as con:\n",
    "    con.execute('''\n",
    "        DELETE   FROM split_sentences\n",
    "        WHERE    rowid not in\n",
    "                 (\n",
    "                 select  min(rowid)\n",
    "                 from split_sentences\n",
    "                 group by\n",
    "                     entry_id,\n",
    "                     version,\n",
    "                     sent_idx\n",
    "                 )\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gzip $db_name-matched-sentences\\.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'spark_output_final'\n",
    "# dir_name = 'output_for_sheena'\n",
    "fs.put(\n",
    "    '%s-matched-sentences.db.gz' % db_name, \n",
    "    'aspangher/edit-pathways/%s/%s-matched-sentences.db.gz' % (dir_name, db_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! aws s3api put-object-acl --bucket aspangher --key edit-pathways/spark_output_final/nyt-matched-sentences.db.gz --acl public-read --endpoint http://s3.dev.obdc.bcs.bloomberg.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_entry_versions = (full_diffs_df\n",
    " .set_index('entry_id')[['version_x', 'version_y']]\n",
    " .unstack()\n",
    " .to_frame('version')\n",
    " .reset_index()\n",
    " .drop('level_0', axis=1)\n",
    " .drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79292, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df[['entry_id', 'version']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71073, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sent_df[['entry_id','version']]\n",
    " .drop_duplicates()\n",
    " .merge(\n",
    "     calc_entry_versions, \n",
    "     right_on=['entry_id', 'version'], \n",
    "     left_on=['entry_id', 'version'], \n",
    "     how='inner'\n",
    " ).shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check PQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pqs = fs.ls('aspangher/edit-pathways/pqs')\n",
    "pqs = list(filter(lambda x: db_name in x, all_pqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir pqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pq in pqs:\n",
    "    fs.get(pq, os.path.join('pqs', os.path.basename(pq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat(\n",
    "    list(map(lambda x: pd.read_parquet(x), glob.glob('pqs/*')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58569,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['entry_id'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = []\n",
    "for entry_id, versions in (\n",
    "    all_data\n",
    "        .loc[lambda df: df['num_versions'] > 1]\n",
    "        .loc[lambda df: df['num_versions'] < 40]\n",
    "        .groupby('entry_id')\n",
    "        .aggregate(list)['version']\n",
    "        .iteritems()\n",
    "):\n",
    "    for version_pair in zip(versions[:-1], versions[1:]):\n",
    "        expected.append({'entry_id': entry_id, 'version_pair': version_pair})\n",
    "\n",
    "expected_df = pd.DataFrame(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45902, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at fetching operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../spark_processing_scripts')\n",
    "import util_general as sug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'cnn'\n",
    "s3_path = sug.s3_output_dir_main if not True else sug.s3_output_dir_sentences\n",
    "file_count = len(sug.get_files(s3_path, db_name, sug.csv_pat)) if not True else len(sug.get_files(s3_path, db_name, sug.pkl_pat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca5b41c17284978b70e2104b119015e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db_name = 'cnn'\n",
    "t = sug.download_prefetched_data(db_name, format='csv', split_sentences=False, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefetched_file_idx, last_one, to_fetch_df = sug.download_pq_to_df(db_name, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefetched_file_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22884, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fetch_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(output_df): 1824\n",
      "len(to_get_df): 500\n",
      "len(left_to_process_df): 1324\n"
     ]
    }
   ],
   "source": [
    "to_fetch_this_round_df, left_to_fetch_df = sug.get_rows_to_process_df(\n",
    "    500, 0, to_fetch_df, t\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       <p>But that is effectively what he had to do t...\n",
       "33168                                                     \n",
       "59493    <p>But that is effectively what he had to do t...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fetch_this_round_df.loc[lambda df: df['entry_id'] == 11]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fetch_this_round_df.loc[lambda df: df['summary'].str.strip() == ''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefetched_entry_id_list = []\n",
    "fname = sug.conn_mapper_dict[db_name]\n",
    "file_list = sug.get_fs().ls(sug.s3_pq_dir)\n",
    "file_pattern = re.compile(r'%s-\\d+.pq' % fname)\n",
    "file_list = list(enumerate(filter(lambda x: re.search(file_pattern, x), file_list)))\n",
    "file_list = file_list[0:]\n",
    "# if show_progress:\n",
    "#     file_list = tqdm(file_list)\n",
    "for f_idx, fname in file_list:\n",
    "    with fs.open(fname) as f:\n",
    "        full_df = pd.read_parquet(f)\n",
    "    full_df = full_df.loc[lambda df: ~df['entry_id'].isin(prefetched_entry_id_list)]\n",
    "    if len(full_df['entry_id'].drop_duplicates()) > 50:\n",
    "        last_one = f_idx < (len(file_list) - 1)\n",
    "#         return f_idx, last_one, full_df\n",
    "if len(file_list) == 0:\n",
    "    f_idx = 0\n",
    "last_one = f_idx < (len(file_list) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fetch_df = ug.download_pq_to_df(db_name, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-f2a1af88baff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdb_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cnn'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprefetched_entry_id_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn_mapper_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdb_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3_pq_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfile_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'%s-\\d+.pq'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ug' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "db_name = 'cnn'\n",
    "prefetched_entry_id_list = t.values\n",
    "fname = ug.conn_mapper_dict[db_name]\n",
    "file_list = ug.get_fs().ls(ug.s3_pq_dir)\n",
    "file_pattern = re.compile(r'%s-\\d+.pq' % fname)\n",
    "file_list = list(filter(lambda x: re.search(file_pattern, x), file_list))\n",
    "\n",
    "if False:\n",
    "    all_full_dfs = []\n",
    "    for f_idx, fname in enumerate(file_list):\n",
    "        with ug.get_fs().open(fname) as f:\n",
    "            full_df = pd.read_parquet(f)\n",
    "\n",
    "        print(f_idx)\n",
    "        print('pre-filtering')\n",
    "        print(full_df.shape)\n",
    "        print(full_df['entry_id'].drop_duplicates().shape)\n",
    "        all_full_dfs.append(full_df.copy())\n",
    "        full_df = full_df.loc[lambda df: ~df['entry_id'].isin(prefetched_entry_id_list)]\n",
    "        print('post-filtering')\n",
    "        print(full_df.shape)\n",
    "        print(full_df['entry_id'].drop_duplicates().shape)\n",
    "        if len(full_df['entry_id'].drop_duplicates()) > 50:\n",
    "            print('here')#full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat(all_full_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714873, 12)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['entry_id'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'independent'\n",
    "remote_name = sug.conn_mapper_dict[db_name]\n",
    "\n",
    "# da.download_file('newssniffer-washpo.db.gz', 'edit-pathways/dbs/newssniffer-washpo.db.gz')\n",
    "if not (os.path.exists('%s.db.gz' % db_name) or os.path.exists('%s.db' % db_name)):\n",
    "    fs.get('aspangher/edit-pathways/dbs/%s.db.gz' % remote_name, '%s.db.gz' % db_name)\n",
    "    ! gunzip $db_name\\.db\\.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "with sqlite3.connect('%s.db' % db_name) as con:\n",
    "    entry_ids = pd.read_sql('select DISTINCT entry_id from entryversion', con=con)['entry_id']\n",
    "#     full_df = pd.read_sql('select * from entryversion', chunksize=5000, con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55009,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('%s_pqs' % db_name):\n",
    "    os.makedirs('%s_pqs' % db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d3cc4a85034dc2a4ad65ed6eb74c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunk_size = 20000\n",
    "for chunk_idx, (s_idx, e_idx) in tqdm(enumerate(\n",
    "    zip(\n",
    "        range(0, len(entry_ids), chunk_size), \n",
    "        range(chunk_size, len(entry_ids) + chunk_size, chunk_size)\n",
    "    )\n",
    ")):\n",
    "    chunk_ids = entry_ids[s_idx: e_idx].values.tolist()\n",
    "    with sqlite3.connect('%s.db' % db_name) as con:\n",
    "        chunk_df = pd.read_sql('''\n",
    "                                SELECT * FROM entryversion\n",
    "                                WHERE entry_id IN (%s)\n",
    "        ''' % ', '.join(list(map(str, chunk_ids))), con=con)\n",
    "\n",
    "    (chunk_df\n",
    "     .to_parquet('%(db_name)s_pqs/%(db_name)s-%(num)s.pq' % ({'db_name': db_name, 'num': chunk_idx + 1}))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8490097f6c489089bfba98d543f164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "for f in tqdm(glob.glob('%s_pqs/*' % db_name)):\n",
    "    remote_fname = os.path.basename(f).replace(db_name, remote_name)\n",
    "    da.upload_file(f, 'edit-pathways/pqs/' + remote_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newssniffer-independent-3.pq'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress\n",
    "                               edits       sentences\n",
    "ap.db                          x           x\n",
    "bbc.db                          ~~~~~ \n",
    "calgaryherald.db               \n",
    "canadaland.db\n",
    "cbc.db\n",
    "cnn.db                         x           x\n",
    "dailymail.db\n",
    "fox.db\n",
    "globemail.db\n",
    "lapresse.db\n",
    "nationalpost.db\n",
    "newssniffer-bbc.db.gz          x           x  \n",
    "newssniffer-guardian.db.gz     x           x\n",
    "newssniffer-independent.db     x           x \n",
    "newssniffer-nytimes.db.gz      x           x \n",
    "newssniffer-washpo.db          x           x\n",
    "reuters.db.gz                  x           x \n",
    "telegraph.db \n",
    "therebel.db\n",
    "torontostar.db\n",
    "torontosun.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aspangher/edit-pathways/spark_processing_scripts-output/db_nyt__start_0__end_50__num_1.csv.gz',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/db_nyt__start_1000__end_1500__num_2.csv.gz',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/db_nyt__start_50__end_100__num_2.csv.gz',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/df_nyt__0_500.csv',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/df_nyt__start_0__end_500__num_1.csv.gz',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/ap',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/bbc-2',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/cnn',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/db_nyt__start_0__end_500',\n",
       " \"aspangher/edit-pathways/spark_processing_scripts-output/db_nyt__start_0__end_500__num_['aspangher\",\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/guardian',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/independent',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/nyt',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/reuters',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output/wp']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls('aspangher/edit-pathways/spark_processing_scripts-output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aspangher/edit-pathways/spark_processing_scripts-output_sentences/ap',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output_sentences/bbc-2',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output_sentences/guardian',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output_sentences/independent',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output_sentences/nyt',\n",
       " 'aspangher/edit-pathways/spark_processing_scripts-output_sentences/wp']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls('aspangher/edit-pathways/spark_processing_scripts-output_sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
